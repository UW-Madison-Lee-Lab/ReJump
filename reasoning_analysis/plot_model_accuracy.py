#!/usr/bin/env python3
"""
Plot model accuracy/MSE from model evaluation tables in visualization JSON files.

This script analyzes JSON files generated by the visualize.py script, extracts model
evaluation table data from each sample, normalizes the order values, and creates a
scatter plot showing accuracy (for classification) or MSE (for regression) vs normalized 
order across all samples.

The script supports both classification and regression data types:
- For classification: plots accuracy values (higher is better)
- For regression: plots MSE values (lower is better)

The script excludes any data points where the order value cannot be parsed as a number
(e.g., if the order is a non-numeric string without any digits). Only data points
with valid numeric order values are included in the plot.
"""

import json
import argparse
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import re
import seaborn as sns

def convert_to_numeric(order):
    """Convert an order value to a numeric value."""
    if isinstance(order, (int, float)):
        return float(order)
    if isinstance(order, str):
        if order.isdigit():
            return float(order)
        match = re.search(r'(\d+)', order)
        return float(match.group(1)) if match else float('inf')
    return float('inf')

def normalize_orders(orders):
    """Normalize a list of order values to the range [0, 1].
    
    Raises:
        ValueError: If any order value is infinity or cannot be converted to a finite number.
    """
    numeric_orders = [convert_to_numeric(order) for order in orders]
    
    # Check for infinity values
    if any(o == float('inf') for o in numeric_orders):
        raise ValueError("Cannot normalize orders containing infinity values")
    
    # Handle special cases
    if len(set(numeric_orders)) <= 1:
        return [0.5] * len(numeric_orders)
        
    min_order = min(numeric_orders)
    max_order = max(numeric_orders)
    
    if min_order == max_order:
        return [0.5] * len(numeric_orders)
    
    return [(o - min_order) / (max_order - min_order) for o in numeric_orders]

def extract_model_accuracy_data(json_file):
    """Extract model accuracy data from the JSON file for classification tasks."""
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    all_data = []
    total_filtered = 0
    
    for sample_idx, sample in enumerate(data['samples']):
        if 'model_evaluation_table' not in sample:
            continue
        
        model_table = sample['model_evaluation_table']
        valid_rows = [
            (row['order'], float(row['accuracy']))
            for row in model_table
            if not row.get('has_error', False)
            and row.get('order') is not None
            and row.get('accuracy') is not None
        ]
        
        if not valid_rows:
            continue
            
        orders, accuracies = zip(*valid_rows)
        numeric_orders = [convert_to_numeric(order) for order in orders]
        
        # Filter out invalid orders
        valid_data = [
            (order, accuracy)
            for order, accuracy, num_order in zip(orders, accuracies, numeric_orders)
            if num_order != float('inf')
        ]
        
        if not valid_data:
            continue
            
        filtered_orders, filtered_accuracies = zip(*valid_data)
        total_filtered += len(orders) - len(filtered_orders)
        
        normalized_orders = normalize_orders(filtered_orders)
        all_data.extend((norm_order, accuracy, sample_idx)
                       for norm_order, accuracy in zip(normalized_orders, filtered_accuracies))
    
    return all_data, total_filtered

def extract_model_mse_data(json_file):
    """Extract model MSE data from the JSON file for regression tasks."""
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    all_data = []
    total_filtered = 0
    
    for sample_idx, sample in enumerate(data['samples']):
        if 'model_evaluation_table' not in sample:
            continue
        
        model_table = sample['model_evaluation_table']
        valid_rows = [
            (row['order'], float(row['mse']))
            for row in model_table
            if not row.get('has_error', False)
            and row.get('order') is not None
            and row.get('mse') is not None
        ]
        
        if not valid_rows:
            continue
            
        orders, mse_values = zip(*valid_rows)
        numeric_orders = [convert_to_numeric(order) for order in orders]
        
        # Filter out invalid orders
        valid_data = [
            (order, mse)
            for order, mse, num_order in zip(orders, mse_values, numeric_orders)
            if num_order != float('inf')
        ]
        
        if not valid_data:
            continue
            
        filtered_orders, filtered_mse = zip(*valid_data)
        total_filtered += len(orders) - len(filtered_orders)
        
        normalized_orders = normalize_orders(filtered_orders)
        all_data.extend((norm_order, mse, sample_idx)
                       for norm_order, mse in zip(normalized_orders, filtered_mse))
    
    return all_data, total_filtered

def clear_existing_plots():
    """清除matplotlib中所有现有的图表内容，防止遗留的图形元素影响新图表"""
    plt.close('all')
    plt.figure(figsize=(12, 8))
    return

def plot_model_accuracy(data, output_file=None, title=None, exclude_outliner=False):
    """Create a scatter plot of model accuracy vs normalized order."""
    clear_existing_plots()
    
    norm_orders, accuracies, sample_indices = zip(*data)
    unique_samples = set(sample_indices)
    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_samples)))
    
    # Convert to numpy arrays for easier manipulation
    x = np.array(norm_orders)
    y = np.array(accuracies)
    
    # Filter nan values and infinities
    valid_mask = ~np.isnan(x) & ~np.isnan(y) & np.isfinite(x) & np.isfinite(y)
    x_valid = x[valid_mask]
    y_valid = y[valid_mask]
    valid_indices = np.array(sample_indices)[valid_mask]
    
    # Detect outliers if exclude_outliner is True
    outliers_mask = np.zeros_like(x_valid, dtype=bool)
    if exclude_outliner and len(x_valid) > 4:
        # Using IQR method to detect outliers in accuracy values
        q1 = np.percentile(y_valid, 25)
        q3 = np.percentile(y_valid, 75)
        iqr = q3 - q1
        outlier_threshold = 1.5 * iqr
        outliers_mask = (y_valid < q1 - outlier_threshold) | (y_valid > q3 + outlier_threshold)
        print(f"Detected {np.sum(outliers_mask)} outliers out of {len(x_valid)} valid points")
    
    # Separate outliers and non-outliers
    x_outliers = x_valid[outliers_mask]
    y_outliers = y_valid[outliers_mask]
    outlier_indices = valid_indices[outliers_mask]
    
    x_clean = x_valid[~outliers_mask]
    y_clean = y_valid[~outliers_mask]
    clean_indices = valid_indices[~outliers_mask]
    
    # Plot individual points (excluding outliers)
    for i, sample_idx in enumerate(unique_samples):
        # Regular points
        points = [(x, y) for x, y, s in zip(x_clean, y_clean, clean_indices) if s == sample_idx]
        if points:
            sample_orders, sample_accuracies = zip(*points)
            plt.scatter(sample_orders, sample_accuracies, 
                       color=colors[i], alpha=0.7, label=f"Sample {sample_idx}")
    
    # Plot outliers in black if any
    if exclude_outliner and np.any(outliers_mask):
        plt.scatter(x_outliers, y_outliers, color='black', marker='x', alpha=0.7, 
                   label='Outliers (excluded from fit)')
    
    # Use either clean data or all valid data for fitting based on exclude_outliner
    fit_x = x_clean if exclude_outliner else x_valid
    fit_y = y_clean if exclude_outliner else y_valid
    
    # Add trend line
    if len(fit_x) >= 3:  # At least 3 points for quadratic fit
        # Try both linear and quadratic fits
        linear_coeffs = np.polyfit(fit_x, fit_y, 1)
        quadratic_coeffs = np.polyfit(fit_x, fit_y, 2)
        
        # Calculate R² for both fits
        linear_pred = np.polyval(linear_coeffs, fit_x)
        quadratic_pred = np.polyval(quadratic_coeffs, fit_x)
        
        # Calculate R² with protection measures
        denominator = np.sum((fit_y - np.mean(fit_y)) ** 2)
        if denominator > 0:
            linear_r2 = 1 - (np.sum((fit_y - linear_pred) ** 2) / denominator)
            quadratic_r2 = 1 - (np.sum((fit_y - quadratic_pred) ** 2) / denominator)
        else:
            # Denominator is 0 means all y values are identical
            print("Warning: All accuracy values are identical, R² calculation is not meaningful")
            linear_r2 = 0
            quadratic_r2 = 0
        
        # Choose the better fit based on R²
        if quadratic_r2 > linear_r2:
            coeffs = quadratic_coeffs
            r2 = quadratic_r2
            fit_type = "Quadratic"
        else:
            coeffs = linear_coeffs
            r2 = linear_r2
            fit_type = "Linear"
        
        # Plot the trend line
        x_fit = np.linspace(min(fit_x), max(fit_x), 100)
        y_fit = np.polyval(coeffs, x_fit)
        plt.plot(x_fit, y_fit, 'r-', linewidth=2, 
                 label=f"{fit_type} Fit (R² = {r2:.3f})")
    else:
        print(f"Warning: Too few valid data points for fitting ({len(fit_x)} points)")
        
    plt.axhline(y=100, color='r', linestyle='--', alpha=0.3)
    plt.xlabel('Normalized Model Order')
    plt.ylabel('Accuracy (%)')
    plt.title(title or 'Model Accuracy vs Normalized Order Across Samples')
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.ylim(50, 90)
    
    # if len(unique_samples) <= 20:
    #     plt.legend(loc='lower right')
    # else:
    #     plt.legend(loc='lower right', bbox_to_anchor=(1.0, 0.0))
    
    plt.tight_layout()
    
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Plot saved to: {output_file}")
    else:
        plt.show()

def plot_model_accuracy_with_ci(data, output_file=None, title=None):
    """Create a scatter plot with mean line and confidence intervals using seaborn."""
    clear_existing_plots()
    
    # Convert data to DataFrame format for seaborn
    norm_orders, accuracies, sample_indices = zip(*data)
    import pandas as pd
    df = pd.DataFrame({
        'Normalized Order': norm_orders,
        'Accuracy': accuracies,
        'Sample': sample_indices
    })
    
    # Create scatter plot with mean line and confidence intervals
    sns.lineplot(data=df, x='Normalized Order', y='Accuracy', 
                ci=95,  # 95% confidence interval
                estimator='mean',
                label='Mean with 95% CI')
    
    # Add individual points
    # sns.scatterplot(data=df, x='Normalized Order', y='Accuracy',
    #                hue='Sample', palette='viridis', alpha=0.7,
    #                legend=False)
    
    plt.axhline(y=100, color='r', linestyle='--', alpha=0.3)
    plt.xlabel('Normalized Model Order')
    plt.ylabel('Accuracy (%)')
    plt.title(title or 'Model Accuracy vs Normalized Order with Confidence Intervals')
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.ylim(-5, 105)
    
    plt.tight_layout()
    
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Plot saved to: {output_file}")
    else:
        plt.show()

def plot_model_mse(data, output_file=None, title=None, exclude_outliner=True):
    """Create a scatter plot of model MSE vs normalized order."""
    clear_existing_plots()
    
    norm_orders, mse_values, sample_indices = zip(*data)
    unique_samples = set(sample_indices)
    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_samples)))
    
    # Convert to numpy arrays for easier manipulation
    x = np.array(norm_orders)
    y = np.array(mse_values)
    
    # Filter nan values and infinities
    valid_mask = ~np.isnan(x) & ~np.isnan(y) & np.isfinite(x) & np.isfinite(y)
    x_valid = x[valid_mask]
    y_valid = y[valid_mask]
    valid_indices = np.array(sample_indices)[valid_mask]
    
    # Detect outliers if exclude_outliner is True
    outliers_mask = np.zeros_like(x_valid, dtype=bool)
    if exclude_outliner and len(x_valid) > 4:
        # Using IQR method to detect outliers in MSE values
        q1 = np.percentile(y_valid, 25)
        q3 = np.percentile(y_valid, 75)
        iqr = q3 - q1
        outlier_threshold = 100 * iqr
        outliers_mask = (y_valid < q1 - outlier_threshold) | (y_valid > q3 + outlier_threshold)
        print(f"Detected {np.sum(outliers_mask)} outliers out of {len(x_valid)} valid points")
    
    # Separate outliers and non-outliers
    x_outliers = x_valid[outliers_mask]
    y_outliers = y_valid[outliers_mask]
    outlier_indices = valid_indices[outliers_mask]
    
    x_clean = x_valid[~outliers_mask]
    y_clean = y_valid[~outliers_mask]
    clean_indices = valid_indices[~outliers_mask]
    
    # Plot individual points (excluding outliers)
    for i, sample_idx in enumerate(unique_samples):
        # Regular points
        points = [(x, y) for x, y, s in zip(x_clean, y_clean, clean_indices) if s == sample_idx]
        if points:
            sample_orders, sample_mse = zip(*points)
            plt.scatter(sample_orders, sample_mse, 
                       color=colors[i], alpha=0.7, label=f"Sample {sample_idx}" if i == 0 else "")
    
    # Plot outliers in black if any
    if exclude_outliner and np.any(outliers_mask):
        plt.scatter(x_outliers, y_outliers, color='black', marker='x', alpha=0.7, 
                   label='Outliers (excluded from fit)')
    
    print(f"Original data points: {len(x)}, Valid data points after filtering: {len(x_valid)}")
    
    # Use either clean data or all valid data for fitting based on exclude_outliner
    fit_x = x_clean if exclude_outliner else x_valid
    fit_y = y_clean if exclude_outliner else y_valid
    
    # 确保有足够的数据点进行拟合
    if len(fit_x) >= 3:  # 至少需要3个点进行二次拟合
        try:
            # Try both linear and quadratic fits
            linear_coeffs = np.polyfit(fit_x, fit_y, 1)
            quadratic_coeffs = np.polyfit(fit_x, fit_y, 2)
            
            # Calculate R² for both fits
            linear_pred = np.polyval(linear_coeffs, fit_x)
            quadratic_pred = np.polyval(quadratic_coeffs, fit_x)
            
            # 计算R²，添加防护措施
            denominator = np.sum((fit_y - np.mean(fit_y)) ** 2)
            if denominator > 0:
                linear_r2 = 1 - (np.sum((fit_y - linear_pred) ** 2) / denominator)
                quadratic_r2 = 1 - (np.sum((fit_y - quadratic_pred) ** 2) / denominator)
            else:
                # 分母为0意味着所有y值都相同
                print("Warning: All y values are identical, R² calculation is not meaningful")
                linear_r2 = 0
                quadratic_r2 = 0
            
            # Choose the better fit based on R²
            if quadratic_r2 > linear_r2:
                coeffs = quadratic_coeffs
                r2 = quadratic_r2
                fit_type = "Quadratic"
            else:
                coeffs = linear_coeffs
                r2 = linear_r2
                fit_type = "Linear"
            
            # Plot the trend line
            x_fit = np.linspace(min(fit_x), max(fit_x), 100)
            y_fit = np.polyval(coeffs, x_fit)
            
            plt.plot(x_fit, y_fit, 'r-', linewidth=3, 
                     label=f"{fit_type} Fit (R² = {r2:.3f})")
            
            print(f"Fit coefficients: {coeffs}")
            print(f"R² value: {r2}")
            
        except Exception as e:
            print(f"Error during curve fitting: {e}")
            coeffs = None
            r2 = 0
    else:
        print(f"Warning: Too few valid data points for fitting ({len(fit_x)} points)")
        coeffs = None
        r2 = 0
    
    plt.xlabel('Normalized Model Order')
    plt.ylabel('Mean Squared Error (MSE)')
    plt.title(title or 'Model MSE vs Normalized Order Across Samples')
    plt.grid(True, linestyle='--', alpha=0.6)
    
    # 检查是否有非正值，如果有则使用线性尺度
    if np.any(np.array(mse_values) <= 0):
        print("Warning: Data contains zero or negative values, using linear scale")
        plt.yscale('linear')
    else:
        # Set y-axis to be logarithmic for better visualization of MSE values
        plt.yscale('log')
    
    # 添加图例
    # plt.legend(loc='best')
    
    plt.tight_layout()
    
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Plot saved to: {output_file}")
    else:
        plt.show()

def plot_model_mse_with_ci(data, output_file=None, title=None):
    """Create a scatter plot with mean line and confidence intervals for MSE using seaborn."""
    clear_existing_plots()
    
    # Convert data to DataFrame format for seaborn
    norm_orders, mse_values, sample_indices = zip(*data)
    import pandas as pd
    
    # 创建原始数据框
    df_original = pd.DataFrame({
        'Normalized Order': norm_orders,
        'MSE': mse_values,
        'Sample': sample_indices
    })
    
    # 过滤nan值和无穷大值
    df = df_original.copy()
    df = df[df['MSE'].notna() & np.isfinite(df['MSE']) & 
            df['Normalized Order'].notna() & np.isfinite(df['Normalized Order'])]
    
    print(f"Original data points: {len(df_original)}, Valid data points after filtering: {len(df)}")
    
    if len(df) < 3:
        print("Warning: Too few valid data points for confidence interval plotting")
        # 创建一个简单的散点图
        plt.scatter(norm_orders, mse_values, alpha=0.7)
        plt.xlabel('Normalized Model Order')
        plt.ylabel('Mean Squared Error (MSE)')
        plt.title(title or 'Model MSE vs Normalized Order (Insufficient Data for CI)')
        plt.grid(True, linestyle='--', alpha=0.6)
    else:
        try:
            # Create scatter plot with mean line and confidence intervals
            sns.lineplot(data=df, x='Normalized Order', y='MSE', 
                        ci=95,  # 95% confidence interval
                        estimator='mean',
                        label='Mean with 95% CI')
            
            plt.xlabel('Normalized Model Order')
            plt.ylabel('Mean Squared Error (MSE)')
            plt.title(title or 'Model MSE vs Normalized Order with Confidence Intervals')
            plt.grid(True, linestyle='--', alpha=0.6)
        except Exception as e:
            print(f"Error during confidence interval plotting: {e}")
            # 创建一个简单的散点图作为后备
            plt.scatter(df['Normalized Order'], df['MSE'], alpha=0.7)
            plt.xlabel('Normalized Model Order')
            plt.ylabel('Mean Squared Error (MSE)')
            plt.title(title or 'Model MSE vs Normalized Order (Error in CI Calculation)')
            plt.grid(True, linestyle='--', alpha=0.6)
    
    # 检查是否有非正值，如果有则使用线性尺度
    if np.any(np.array(mse_values) <= 0):
        print("Warning: Data contains zero or negative values, using linear scale")
        plt.yscale('linear')
    else:
        # Set y-axis to be logarithmic for better visualization of MSE values
        plt.yscale('log')
    
    plt.tight_layout()
    
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Plot saved to: {output_file}")
    else:
        plt.show()

def main():
    parser = argparse.ArgumentParser(description='Plot model accuracy/MSE from visualization JSON files')
    parser.add_argument('--input', type=str, help='Path to the visualization JSON file')
    parser.add_argument('--output', '-o', type=str, default=None, 
                        help='Base path to save the plots (if not specified, save in input file directory)')
    parser.add_argument('--title', '-t', type=str, default=None,
                        help='Custom title for the plots')
    parser.add_argument('--plot-type', choices=['trend', 'ci', 'both'], default='both',
                        help='Type of plot to generate: trend (with fitted line), ci (with confidence intervals), or both')
    parser.add_argument('--data_type', choices=['classification', 'regression'], default='classification',
                        help='Type of data to analyze: classification (accuracy) or regression (MSE)')
    
    args = parser.parse_args()
    
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"Error: File '{args.input}' not found")
        return 1
    
    print(f"Extracting model data from: {args.input}")
    
    # Check JSON file to determine data type if not specified
    if args.data_type == 'classification':
        print("Extracting classification model accuracy data...")
        data, filtered_count = extract_model_accuracy_data(args.input)
        metric_name = "accuracy"
    elif args.data_type == 'regression':
        print("Extracting regression model MSE data...")
        data, filtered_count = extract_model_mse_data(args.input)
        metric_name = "MSE"
    else:
        raise NotImplementedError(f"Data type '{args.data_type}' not implemented")
    
    if not data:
        print(f"No model evaluation {metric_name} data found in the JSON file")
        return 1
    
    print(f"Plotting {len(data)} {metric_name} data points from {len(set(d[2] for d in data))} samples")
    if filtered_count > 0:
        print(f"Filtered out {filtered_count} data points with non-numeric order values")
    
    input_stem = input_path.stem
    output_dir = input_path.parent
    
    if args.plot_type in ['trend', 'both']:
        if args.output is None:
            trend_output = output_dir / f"{input_stem}_{args.data_type}_trend_plot.png"
        else:
            trend_output = args.output
        print(f"\nGenerating {args.data_type} trend plot...")
        
        if args.data_type == 'classification':
            plot_model_accuracy(data, trend_output, args.title)
        else:
            plot_model_mse(data, trend_output, args.title)
    
    if args.plot_type in ['ci', 'both']:
        if args.output is None:
            ci_output = output_dir / f"{input_stem}_{args.data_type}_ci_plot.png"
        else:
            ci_output = args.output
        print(f"\nGenerating {args.data_type} confidence interval plot...")
        
        if args.data_type == 'classification':
            plot_model_accuracy_with_ci(data, ci_output, args.title)
        else:
            plot_model_mse_with_ci(data, ci_output, args.title)
    
    return 0

if __name__ == "__main__":
    exit(main()) 