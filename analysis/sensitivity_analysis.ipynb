{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa567d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d09e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openrouter-qwen-qwq-32b\"\n",
    "api_name = \"reasoning_api\"\n",
    "# model_name = \"openrouter-microsoft-phi-4-reasoning-plus\"\n",
    "# api_name = \"standard_api\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Only consider these columns (1-6) from gemini_acc.ipynb context\n",
    "METRICS_COLS = [\n",
    "    \"average_solution_count\",\n",
    "    \"filtered_ajd\",\n",
    "    \"success_rates\",\n",
    "    \"average_verification_rates\",\n",
    "    \"overthinking_rates\",\n",
    "    \"forgetting_rates\",\n",
    "]\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        # Only keep the relevant columns if they exist\n",
    "        existing = [c for c in METRICS_COLS if c in df.columns]\n",
    "        return df[existing]\n",
    "    else:\n",
    "        print(f\"File not found, skipping: {path}\")\n",
    "        return None\n",
    "\n",
    "def get_results(model_name, api_name):\n",
    "    paths = {\n",
    "        \"default_0\": f\"/home/zengyuchen/ReJump/results/{model_name}/game24_0_shot_1_query_{api_name}_reslen_404_nsamples_100_noise_None_flip_rate_0.0_mode_default/temperature_1.00/replicate_0/global_step_0/tree_vis_google/gemini-2.5-pro-preview-03-25/metric_df.csv\",\n",
    "        \"default_1\": f\"/home/zengyuchen/ReJump/results/{model_name}/game24_0_shot_1_query_{api_name}_reslen_404_nsamples_100_noise_None_flip_rate_0.0_mode_default/temperature_1.00/replicate_0/global_step_0/tree_vis_google/gemini-2.5-pro-preview-03-25_1/metric_df.csv\",\n",
    "        \"default_2\": f\"/home/zengyuchen/ReJump/results/{model_name}/game24_0_shot_1_query_{api_name}_reslen_404_nsamples_100_noise_None_flip_rate_0.0_mode_default/temperature_1.00/replicate_0/global_step_0/tree_vis_google/gemini-2.5-pro-preview-03-25_2/metric_df.csv\",\n",
    "        \"shuffle\":   f\"/home/zengyuchen/ReJump/results/{model_name}/game24_0_shot_1_query_{api_name}_reslen_404_nsamples_100_noise_None_flip_rate_0.0_mode_default/temperature_1.00/replicate_0/global_step_0/tree_vis_google/gemini-2.5-pro-preview-03-25_shuffle/metric_df.csv\",\n",
    "        \"rephrase\":  f\"/home/zengyuchen/ReJump/results/{model_name}/game24_0_shot_1_query_{api_name}_reslen_404_nsamples_100_noise_None_flip_rate_0.0_mode_default/temperature_1.00/replicate_0/global_step_0/tree_vis_google/gemini-2.5-pro-preview-03-25_rephrase/metric_df.csv\"\n",
    "    }\n",
    "    dfs = {k: safe_read_csv(v) for k, v in paths.items()}\n",
    "\n",
    "    # Only include non-None DataFrames\n",
    "    seed = [dfs[\"default_0\"], dfs[\"default_1\"], dfs[\"default_2\"]]\n",
    "    seed = [df for df in seed if df is not None]\n",
    "    prompt = [dfs[\"default_0\"], dfs[\"shuffle\"], dfs[\"rephrase\"]]\n",
    "    prompt = [df for df in prompt if df is not None]\n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"prompt\": prompt,\n",
    "    }\n",
    "\n",
    "def average_std_across_rows(dfs):\n",
    "    \"\"\"\n",
    "    Given N dataframes (with same columns), match their indexes,\n",
    "    remove rows that do not exist in all dfs, and then compute the per-cell std-dev across runs,\n",
    "    finally average std-dev for each column.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Average standard deviation for each column (across all matched rows).\n",
    "    \"\"\"\n",
    "    if not dfs:\n",
    "        return pd.Series(dtype=float)\n",
    "    # Defensive: force type to float and align columns explicitly\n",
    "    cols = [c for c in METRICS_COLS if c in dfs[0].columns]\n",
    "    # Find common indices\n",
    "    common_index = dfs[0].index\n",
    "    for df in dfs[1:]:\n",
    "        common_index = common_index.intersection(df.index)\n",
    "    if len(common_index) == 0:\n",
    "        print(\"No overlapping indices across all dataframes.\")\n",
    "        return pd.Series(dtype=float)\n",
    "    # Align all dfs to common index and keep only the relevant columns\n",
    "    aligned_dfs = [df.loc[common_index, cols].astype(float) for df in dfs]\n",
    "    arr = np.stack([df.values for df in aligned_dfs])\n",
    "    per_cell_std = np.std(arr, axis=0)\n",
    "    avg_std_per_col = per_cell_std.mean(axis=0)\n",
    "    std_of_std_per_col = per_cell_std.std(axis=0)\n",
    "    return pd.DataFrame({\n",
    "        \"avg_std\": avg_std_per_col,\n",
    "        \"std_of_std\": std_of_std_per_col\n",
    "    }, index=cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df358ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "avg_std\n",
      "average_solution_count        1.451181\n",
      "filtered_ajd                  1.445590\n",
      "success_rates                 1.342598\n",
      "average_verification_rates    1.395387\n",
      "overthinking_rates            1.207379\n",
      "forgetting_rates              1.651613\n",
      "Name: avg_std, dtype: float64\n",
      "--------------------------------\n",
      "std_of_std\n",
      "average_solution_count        0.929559\n",
      "filtered_ajd                  1.039391\n",
      "success_rates                 1.083406\n",
      "average_verification_rates    0.907450\n",
      "overthinking_rates            0.950614\n",
      "forgetting_rates              0.985263\n",
      "Name: std_of_std, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results = get_results(model_name, api_name)\n",
    "prompt_result = average_std_across_rows(results[\"prompt\"])\n",
    "seed_result = average_std_across_rows(results[\"seed\"])\n",
    "\n",
    "for metric in \"avg_std\", \"std_of_std\":\n",
    "    print(\"--------------------------------\")\n",
    "    print(metric)\n",
    "    print(prompt_result[metric]/seed_result[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff35a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596f728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
