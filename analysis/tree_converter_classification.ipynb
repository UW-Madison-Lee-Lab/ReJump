{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Tuple\n",
    "from google import genai \n",
    "from environment import GEMINI_API_KEY\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from constants import get_result_dir, supported_datasets\n",
    "import pandas as pd\n",
    "from utils import load_json\n",
    "from sklearn.metrics import accuracy_score\n",
    "import graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"circles\"\n",
    "\n",
    "result_dir = get_result_dir(\n",
    "    dataset_name = dataset,\n",
    "    model_name = \"claude/claude-3-7-sonnet-20250219-thinking\",\n",
    "    shot = 50,\n",
    "    template_type = \"reasoning_api\",\n",
    "    response_length = 3520,\n",
    "    num_samples = 500,\n",
    "    feature_noise = supported_datasets[dataset][\"feature_noise\"],\n",
    "    label_noise = supported_datasets[dataset][\"label_noise\"],\n",
    "    data_mode = \"default\",\n",
    "    n_query = 10,\n",
    ")\n",
    "results = pd.read_parquet(f\"{result_dir}/test_default.parquet\")\n",
    "model_funcs = load_json(f\"{result_dir}/test_default_gemini_analysis_llm_analysis.json\")\n",
    "model_text = pd.read_parquet(f\"{result_dir}/test_default_gemini_analysis.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_types_prompt(model_function_list_str):\n",
    "    # model_function_list_str is a string representation of a list of function definition strings.\n",
    "    # E.g., \"['def model1(x,y,data): ...', 'def model2(x,y,data): ...']\"\n",
    "    return f\"\"\"\n",
    "        You are given a list of Python function definitions, where each function represents a model used for classification.\n",
    "        Your task is to classify **each function independently** and return a **JSON list** containing the classification results. Each element in the output list corresponds to the function at the same index in the input list.\n",
    "\n",
    "        For **each function** in the input list, determine its **type of classifier** based on its structure and logic.\n",
    "\n",
    "        There are **four possible classifier categories** for an individual function: `generalized_linear`, `decision_tree`, `KNN`, `unknown`.\n",
    "\n",
    "        The output **must** be a JSON list, where each item is a JSON object following the format specified below for the corresponding function's category:\n",
    "\n",
    "        **Output Format:** A JSON List `[ <classification_object_1>, <classification_object_2>, ... ]`\n",
    "\n",
    "        **Format for each `<classification_object>`:**\n",
    "\n",
    "        - For **generalized linear models**, the object is:\n",
    "            ```json\n",
    "            {{\n",
    "            \"category\": \"generalized_linear\",\n",
    "            \"detail\": {{\n",
    "                \"linear_link\": <true or false>,\n",
    "                \"linear_basis\": <true or false>\n",
    "            }}\n",
    "            }}\n",
    "            ```\n",
    "        - For **decision tree models**, the object is:\n",
    "            ```json\n",
    "            {{\n",
    "            \"category\": \"decision_tree\",\n",
    "            \"detail\": {{\n",
    "                \"depth_val\": <integer value of depth>\n",
    "            }}\n",
    "            }}\n",
    "            ```\n",
    "        - For **KNN models**, the object is:\n",
    "            ```json\n",
    "            {{\n",
    "            \"category\": \"KNN\",\n",
    "            \"detail\": {{\n",
    "                \"K_val\": <integer value of K>\n",
    "            }}\n",
    "            }}\n",
    "            ```\n",
    "        - If the function **does not clearly belong to any of the first three categories**, classify it as `\"unknown\"` and the object is:\n",
    "            ```json\n",
    "            {{\n",
    "            \"category\": \"unknown\",\n",
    "            \"detail\": {{\n",
    "                \"inline_func\": \"<inline function or null if not applicable>\"\n",
    "            }}\n",
    "            }}\n",
    "            ```\n",
    "\n",
    "        ---\n",
    "        ### âš ï¸ Important Notes & Rules for Classifying EACH Function:\n",
    "        * **Process Each Function:** Apply the following rules to every function string provided in the input list.\n",
    "        * **Output List:** Ensure the final output is a single JSON list containing the classification objects for all processed functions, in the original order.\n",
    "        * **Inline Func:** For `inline_func` (in GLM and Unknown), write the exact expression with concrete numeric coefficients (e.g., write `2*x + 3*y > 0`, not `ax + by > 0`). If no expression is sensible (e.g., complex code, non-returning function), use `null`.\n",
    "        * **Generalized Linear Model (GLM):**\n",
    "            * Identified if the function returns a direct mathematical expression of inputs `x`, `y` (potentially involving constants or data access, but not KNN logic or primary branching logic like a DT).\n",
    "            * `linear_link = true` if the output is not wrapped in a final nonlinearity (e.g., `x + y`). False if wrapped (e.g., `(x + y)**.5 > 0.5`).\n",
    "            * `linear_basis = true` if the input terms are linear in `x` and `y` (e.g., `ax + by + c`). False if terms involve powers, products, or nonlinear functions of inputs (e.g., `x**2`, `x*y`, `cos(x)`).\n",
    "            * Functions involving `min`, `max`, `abs`, `cos`, `sin` applied to inputs often result in `linear_link: true`, `linear_basis: false` unless the *final* output is transformed non-linearly.\n",
    "        * **Decision Tree (DT):**\n",
    "            * Identified if the prediction logic primarily uses nested `if/else` statements that branch based on input features (`x`, `y`) to return a value.\n",
    "            * `depth_val`: Represents the maximum number of feature-based conditions checked along any path from the root to a leaf (return statement). A simple `if/else` is depth 1.\n",
    "        * **K-Nearest Neighbors (KNN):**\n",
    "            * Identified if the prediction logic involves calculating distances between the input point `(x, y)` and points in a `data` set, selecting the `k` nearest neighbors, and aggregating their target values (e.g., averaging, weighted averaging).\n",
    "            * `K_val`: The integer value of `k` used in the neighbor selection.\n",
    "        * **Unknown:** Use this category if a function doesn't clearly fit GLM, DT, or KNN patterns (e.g., complex imperative code, external calls without clear mathematical/logical structure, helper functions not returning predictions, non-functional code).\n",
    "\n",
    "        ---\n",
    "        ### ðŸ”§ Examples\n",
    "\n",
    "        #### Example 1: Mixed Types\n",
    "        Input List String: `[\"def model_A(x, y, data): return 0.7 * x**2 + 0.3 * y**2\", \"def model_B(x, y, data):\\\\n    if y > 0.5:\\\\n        return y\\\\n    else:\\\\n        return x\"]`\n",
    "        Output JSON List:\n",
    "        ```json\n",
    "        [\n",
    "          {{\n",
    "            \"category\": \"generalized_linear\",\n",
    "            \"detail\": {{\n",
    "              \"inline_func\": \"0.7 * x**2 + 0.3 * y**2 > 0.5\",\n",
    "              \"linear_link\": true,\n",
    "              \"linear_basis\": false\n",
    "            }}\n",
    "          }},\n",
    "          {{\n",
    "            \"category\": \"decision_tree\",\n",
    "            \"detail\": {{\n",
    "              \"depth_val\": 1\n",
    "            }}\n",
    "          }}\n",
    "        ]\n",
    "        ```\n",
    "\n",
    "        #### Example 2: KNN and Unknown\n",
    "        Input List String: `[\"def find_neighbors(x, y, data):\\\\n    import math\\\\n    k = 5\\\\n    distances = sorted([(math.sqrt((x - xi)**2 + (y - yi)**2), target) for xi, yi, target in data])\\\\n    # ... logic to average top k ...\\\\n    return sum(target for dist, target in distances[:k]) / k\", \"def helper_func(a, b):\\\\n    # Not a regression model function\\\\n    print('Helper')\"]`\n",
    "        Output JSON List:\n",
    "        ```json\n",
    "        [\n",
    "          {{\n",
    "            \"category\": \"KNN\",\n",
    "            \"detail\": {{\n",
    "              \"K_val\": 5\n",
    "            }}\n",
    "          }},\n",
    "          {{\n",
    "            \"category\": \"unknown\",\n",
    "            \"detail\": {{\n",
    "              \"inline_func\": null\n",
    "            }}\n",
    "          }}\n",
    "        ]\n",
    "        ```\n",
    "        \n",
    "        #### Example 3: List with one function\n",
    "        Input List String: `[\"def model(x, y, data): return x + y\"]`\n",
    "        Output JSON List:\n",
    "        ```json\n",
    "        [\n",
    "          {{\n",
    "            \"category\": \"generalized_linear\",\n",
    "            \"detail\": {{\n",
    "              \"inline_func\": \"x + y > 0\",\n",
    "              \"linear_link\": true,\n",
    "              \"linear_basis\": true\n",
    "            }}\n",
    "          }}\n",
    "        ]\n",
    "        ```\n",
    "\n",
    "        ----- FUNCTION LIST -----\n",
    "        {model_function_list_str}\n",
    "        ----- END FUNCTION LIST -----\n",
    "        \"\"\"\n",
    "\n",
    "def parse_json(json_prompt):\n",
    "    \"\"\"Parse JSON content from a prompt string.\n",
    "    \n",
    "    Args:\n",
    "        json_prompt: A string containing JSON data between ```json and ``` markers\n",
    "        \n",
    "    Returns:\n",
    "        The parsed JSON data as a Python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find content between ```json and ``` markers\n",
    "    json_match = re.search(r'```json\\s*(.*?)\\s*```', json_prompt, re.DOTALL)\n",
    "    \n",
    "    if not json_match:\n",
    "        return {}\n",
    "    \n",
    "    json_content = json_match.group(1)\n",
    "    \n",
    "    # Parse the JSON content\n",
    "    data = json.loads(json_content)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "def call_gemini(prompt, model_name = \"gemini-2.5-pro-preview-03-25\"):\n",
    "    response = client.models.generate_content(\n",
    "        model=model_name,\n",
    "        contents=[prompt],\n",
    "    )\n",
    "    return response.candidates[0].content.parts[0].text\n",
    "\n",
    "def get_models(idx):\n",
    "    n_models = len(model_funcs[\"samples\"][idx][\"model_evaluation_table\"])\n",
    "    model_codes = []\n",
    "    for i in range(n_models):\n",
    "        model_codes.append(model_funcs[\"samples\"][idx][\"model_evaluation_table\"][i][\"model_code\"])\n",
    "    return model_codes\n",
    "\n",
    "def get_icl_samples(idx):\n",
    "    samples = results[\"reward_model\"].iloc[idx][\"ground_truth\"][\"in_context_samples\"]\n",
    "    df_samples = []\n",
    "    for sample in samples:\n",
    "        df_samples.append({\"x1\": sample[\"features\"][0], \"x2\": sample[\"features\"][1], \"y\": sample[\"label\"]})\n",
    "    df_samples = pd.DataFrame(df_samples)\n",
    "    return df_samples\n",
    "\n",
    "def compute_acc(model_type_dict, samples):\n",
    "    X = samples[[\"x1\", \"x2\"]].values\n",
    "    y_true = samples[\"y\"].values\n",
    "    \n",
    "    if model_type_dict[\"category\"] in [\"decision_tree\", \"KNN\"]:\n",
    "        if model_type_dict[\"category\"] == \"decision_tree\":\n",
    "            model = DecisionTreeClassifier(max_depth=model_type_dict[\"detail\"][\"depth_val\"])\n",
    "        else:\n",
    "            model = KNeighborsClassifier(n_neighbors=model_type_dict[\"detail\"][\"K_val\"])\n",
    "        model.fit(X, y_true)\n",
    "        y_pred = model.predict(X)\n",
    "    else:\n",
    "        model_code = model_type_dict[\"detail\"][\"inline_func\"]\n",
    "        generated_func = lambda x, y: eval(model_code, {\"__builtins__\": {}}, {\"x\": x, \"y\": y, \"math\": math, \"max\": max, \"min\": min})\n",
    "        y_pred = np.apply_along_axis(lambda row: generated_func(row[0], row[1]), 1, X)\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)  \n",
    "\n",
    "  \n",
    "class MLModelNode:\n",
    "    def __init__(self, id, label, node_type=None):\n",
    "        self.id = id\n",
    "        self.label = label\n",
    "        self.node_type = node_type  # Can be 'root', 'category', 'subcategory', 'basis', 'activation', etc.\n",
    "        self.children = []\n",
    "    \n",
    "    def add_child(self, child_node):\n",
    "        \"\"\"Add a child node to this node\"\"\"\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "class MLModelGraph:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}  # Dictionary of all nodes: {id: node_object}\n",
    "        self.root = None\n",
    "    \n",
    "    def add_node(self, id, label, node_type=None, parent_id=None):\n",
    "        \"\"\"Add a node to the graph, optionally as a child of parent_id\"\"\"\n",
    "        node = MLModelNode(id, label, node_type)\n",
    "        self.nodes[id] = node\n",
    "        \n",
    "        if parent_id is None and self.root is None:\n",
    "            self.root = node\n",
    "        elif parent_id is not None and parent_id in self.nodes:\n",
    "            self.nodes[parent_id].add_child(node)\n",
    "        else:\n",
    "            raise ValueError(f\"Parent node with ID '{parent_id}' not found\")\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def add_node_to_empty(self, id, label, node_type=None, parent_id=None, position=None):\n",
    "        \"\"\"\n",
    "        Add a node to an empty slot in the hierarchy\n",
    "        \n",
    "        Parameters:\n",
    "        - id: Unique identifier for the new node\n",
    "        - label: Display label for the node\n",
    "        - node_type: Type of node (optional)\n",
    "        - parent_id: ID of the parent node\n",
    "        - position: Position to add the node if specific (optional)\n",
    "        \n",
    "        Returns:\n",
    "        - The newly created node\n",
    "        \"\"\"\n",
    "        if parent_id not in self.nodes:\n",
    "            raise ValueError(f\"Parent node with ID '{parent_id}' not found\")\n",
    "        \n",
    "        parent = self.nodes[parent_id]\n",
    "        \n",
    "        # Create the new node\n",
    "        node = MLModelNode(id, label, node_type)\n",
    "        self.nodes[id] = node\n",
    "        \n",
    "        # Add to parent's children at specified position or at the end\n",
    "        if position is not None and position <= len(parent.children):\n",
    "            parent.children.insert(position, node)\n",
    "        else:\n",
    "            parent.children.append(node)\n",
    "            \n",
    "        return node\n",
    "    \n",
    "    def prune_node(self):\n",
    "        \"\"\"\n",
    "        Prune nodes without children recursively, except for nodes with names starting with 'model_'\n",
    "        or if all nodes have children.\n",
    "        \n",
    "        Returns:\n",
    "        - Number of nodes pruned\n",
    "        \"\"\"\n",
    "        nodes_to_prune = []\n",
    "        \n",
    "        # Find nodes without children that don't start with 'model_'\n",
    "        for node_id, node in self.nodes.items():\n",
    "            if not node.children and not node_id.startswith('model_'):\n",
    "                nodes_to_prune.append(node_id)\n",
    "        \n",
    "        # If no nodes to prune, return 0\n",
    "        if not nodes_to_prune:\n",
    "            return 0\n",
    "        \n",
    "        # Remove nodes from their parents' children lists\n",
    "        for node_id in nodes_to_prune:\n",
    "            # Find the parent of this node\n",
    "            for parent_id, parent in self.nodes.items():\n",
    "                parent.children = [child for child in parent.children if child.id != node_id]\n",
    "            \n",
    "            # Remove the node from the nodes dictionary\n",
    "            del self.nodes[node_id]\n",
    "        \n",
    "        # Recursively prune more nodes\n",
    "        additional_pruned = self.prune_node()\n",
    "        \n",
    "        return len(nodes_to_prune) + additional_pruned\n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"Visualize the graph using Graphviz\"\"\"\n",
    "        dot = graphviz.Digraph(comment='ML Model Hierarchy')\n",
    "        dot.attr('node', shape='ellipse')\n",
    "        \n",
    "        # Define node styles based on type\n",
    "        node_styles = {\n",
    "            'root': {'shape': 'ellipse', 'style': 'filled', 'fillcolor': 'lightblue'},\n",
    "            'category': {'shape': 'ellipse', 'style': 'filled', 'fillcolor': 'lightgreen'},\n",
    "            'subcategory': {'shape': 'ellipse', 'style': 'filled', 'fillcolor': 'lightyellow'},\n",
    "            'model': {'shape': 'ellipse'},\n",
    "        }\n",
    "        \n",
    "        # Add all nodes to the visualization\n",
    "        for node_id, node in self.nodes.items():\n",
    "            node_attr = node_styles.get(node.node_type, {})\n",
    "            dot.node(node_id, node.label, **node_attr)\n",
    "        \n",
    "        # Add all edges\n",
    "        for node_id, node in self.nodes.items():\n",
    "            for child in node.children:\n",
    "                dot.edge(node_id, child.id)\n",
    "        \n",
    "        return dot\n",
    "\n",
    "# Example usage\n",
    "def create_ml_model_hierarchy():\n",
    "    graph = MLModelGraph()\n",
    "    \n",
    "    # Create root\n",
    "    graph.add_node(\"root\", \"root\", \"root\")\n",
    "    \n",
    "    # Create main categories\n",
    "    graph.add_node(\"glm\", \"GLM\", \"category\", \"root\")\n",
    "    graph.add_node(\"decision_tree\", \"Decision tree\", \"category\", \"root\")\n",
    "    graph.add_node(\"knn\", \"KNN\", \"category\", \"root\")\n",
    "    graph.add_node(\"unknown\", \"Unknown\", \"category\", \"root\")\n",
    "    \n",
    "    # GLM subcategories\n",
    "    graph.add_node(\"linear\", \"Linear\", \"subcategory\", \"glm\")\n",
    "    graph.add_node(\"nonlinear\", \"Non-linear\", \"subcategory\", \"glm\")\n",
    "    \n",
    "    graph.add_node(\"linear1\", \"Low-Performance Linear\", \"subcategory\", \"linear\")\n",
    "    graph.add_node(\"linear2\", \"Medium-Performance Linear\", \"subcategory\", \"linear1\")\n",
    "    graph.add_node(\"linear3\", \"High-Performance Linear\", \"subcategory\", \"linear2\")\n",
    "    \n",
    "    graph.add_node(\"nonlinear1\", \"Low-Performance Non-linear\", \"subcategory\", \"nonlinear\")\n",
    "    graph.add_node(\"nonlinear2\", \"Medium-Performance Non-linear\", \"subcategory\", \"nonlinear1\")\n",
    "    graph.add_node(\"nonlinear3\", \"High-Performance Non-linear\", \"subcategory\", \"nonlinear2\")\n",
    "    \n",
    "    # Decision tree depths\n",
    "    graph.add_node(\"depth1\", \"depth=1\", \"subcategory\", \"decision_tree\")\n",
    "    graph.add_node(\"depth2\", \"depth=2\", \"subcategory\", \"depth1\")\n",
    "    graph.add_node(\"depth3\", \"depth=3\", \"subcategory\", \"depth2\")\n",
    "    \n",
    "    graph.add_node(\"depth11\", \"Low-Performance depth=1\", \"subcategory\", \"depth1\")\n",
    "    graph.add_node(\"depth21\", \"Low-Performance depth=2\", \"subcategory\", \"depth2\")\n",
    "    graph.add_node(\"depth31\", \"Low-Performance depth=3\", \"subcategory\", \"depth3\")\n",
    "    \n",
    "    graph.add_node(\"depth12\", \"Medium-Performance depth=1\", \"subcategory\", \"depth11\")\n",
    "    graph.add_node(\"depth22\", \"Medium-Performance depth=2\", \"subcategory\", \"depth21\")\n",
    "    graph.add_node(\"depth32\", \"Medium-Performance depth=3\", \"subcategory\", \"depth31\")\n",
    "    \n",
    "    graph.add_node(\"depth13\", \"High-Performance depth=1\", \"subcategory\", \"depth12\")\n",
    "    graph.add_node(\"depth23\", \"High-Performance depth=2\", \"subcategory\", \"depth22\")\n",
    "    graph.add_node(\"depth33\", \"High-Performance depth=3\", \"subcategory\", \"depth32\")\n",
    "    \n",
    "    # KNN k values\n",
    "    graph.add_node(\"k1\", \"k=1\", \"subcategory\", \"knn\")\n",
    "    graph.add_node(\"k3\", \"k=3\", \"subcategory\", \"knn\")\n",
    "    graph.add_node(\"k5\", \"k=5\", \"subcategory\", \"knn\")\n",
    "    \n",
    "    graph.add_node(\"k11\", \"Low-Performance k=1\", \"subcategory\", \"k1\")\n",
    "    graph.add_node(\"k31\", \"Low-Performance k=3\", \"subcategory\", \"k3\")\n",
    "    graph.add_node(\"k51\", \"Low-Performance k=5\", \"subcategory\", \"k5\")\n",
    "    \n",
    "    graph.add_node(\"k12\", \"Medium-Performance k=1\", \"subcategory\", \"k11\")\n",
    "    graph.add_node(\"k32\", \"Medium-Performance k=3\", \"subcategory\", \"k31\")\n",
    "    graph.add_node(\"k52\", \"Medium-Performance k=5\", \"subcategory\", \"k51\")\n",
    "    \n",
    "    graph.add_node(\"k13\", \"High-Performance k=1\", \"subcategory\", \"k12\")\n",
    "    graph.add_node(\"k33\", \"High-Performance k=3\", \"subcategory\", \"k32\")\n",
    "    graph.add_node(\"k53\", \"High-Performance k=5\", \"subcategory\", \"k52\")\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def get_parent_node(model_type_dict):\n",
    "    acc = model_type_dict[\"acc\"]\n",
    "    interval = [.5, .9]\n",
    "    if model_type_dict[\"category\"] == \"generalized_linear\":\n",
    "        if model_type_dict[\"detail\"][\"linear_link\"] and model_type_dict[\"detail\"][\"linear_basis\"]:\n",
    "            if acc < interval[0]:\n",
    "                return \"linear1\"\n",
    "            elif acc < interval[1]:\n",
    "                return \"linear2\"\n",
    "            else:\n",
    "                return \"linear3\"\n",
    "        else:\n",
    "            acc = model_type_dict[\"acc\"]\n",
    "            if acc < interval[0]:\n",
    "                return \"nonlinear1\"\n",
    "            elif acc < interval[1]:\n",
    "                return \"nonlinear2\"\n",
    "            else:\n",
    "                return \"nonlinear3\"\n",
    "    elif model_type_dict[\"category\"] == \"decision_tree\":\n",
    "        if \"depth\" in model_type_dict[\"detail\"]:\n",
    "            prefix = f\"depth{model_type_dict['detail']['depth']}\"\n",
    "            if acc < interval[0]:\n",
    "                return f\"{prefix}1\"\n",
    "            elif acc < interval[1]:\n",
    "                return f\"{prefix}2\"\n",
    "            else:\n",
    "                return f\"{prefix}3\"\n",
    "        else:\n",
    "            prefix = f\"depth{model_type_dict['detail']['depth_val']}\"\n",
    "            if acc < interval[0]:\n",
    "                return f\"{prefix}1\"\n",
    "            elif acc < interval[1]:\n",
    "                return f\"{prefix}2\"\n",
    "            else:\n",
    "                return f\"{prefix}3\"\n",
    "    elif model_type_dict[\"category\"] == \"KNN\":\n",
    "        if \"K_val\" in model_type_dict[\"detail\"]:\n",
    "            prefix = f\"k{model_type_dict['detail']['K_val']}\"\n",
    "            if acc < interval[0]:\n",
    "                return f\"{prefix}1\"\n",
    "            elif acc < interval[1]:\n",
    "                return f\"{prefix}2\"\n",
    "            else:\n",
    "                return f\"{prefix}3\"\n",
    "        else:\n",
    "            prefix = f\"k{model_type_dict['detail']['K_val']}\"\n",
    "            if acc < interval[0]:\n",
    "                return f\"{prefix}1\"\n",
    "            elif acc < interval[1]:\n",
    "                return f\"{prefix}2\"\n",
    "            else:\n",
    "                return f\"{prefix}3\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "    \n",
    "def get_upper_bound(samples):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(samples[[\"x1\", \"x2\"]], samples[\"y\"])\n",
    "    return model.score(samples[[\"x1\", \"x2\"]], samples[\"y\"])\n",
    "    \n",
    "def add_highlighted_path(graph, path_nodes, color='red', penwidth='2.0'):\n",
    "    \"\"\"\n",
    "    Adds a highlighted path (sequence of edges) to a graphviz graph object.\n",
    "\n",
    "    This version attempts to create a smoother appearance by removing arrowheads\n",
    "    and relying on the graph's spline settings (e.g., setting graph.attr(splines='curved')).\n",
    "    It also highlights the node boundaries in the path with the same color.\n",
    "    The start node is filled with green and the end node is filled with red.\n",
    "\n",
    "    Args:\n",
    "      graph: The graphviz.Graph or graphviz.Digraph object to modify.\n",
    "             This object is modified in place.\n",
    "      path_nodes: A list or tuple of node names (strings) representing the\n",
    "                  ordered sequence of nodes in the desired path.\n",
    "      color: The color to use for the highlighted path edges and node boundaries (default: 'red').\n",
    "      penwidth: The thickness of the highlighted path edges (default: '2.0').\n",
    "    \"\"\"\n",
    "    # Check if the path has at least two nodes to form an edge\n",
    "    if not path_nodes or len(path_nodes) < 2:\n",
    "        print(\"Warning: Path sequence is too short. Needs at least two nodes to draw an edge.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Adding highlighted path (no arrows): {' -> '.join(path_nodes)}\")\n",
    "\n",
    "    # Highlight all nodes in the path (just the boundary, not filled)\n",
    "    for i, node in enumerate(path_nodes):\n",
    "        if i == 0:  # Start node\n",
    "            graph.node(node, style='filled', fillcolor='green', penwidth=str(penwidth))\n",
    "        elif i == len(path_nodes) - 1:  # End node\n",
    "            graph.node(node, style='filled', fillcolor='red', penwidth=str(penwidth))\n",
    "        else:  # Middle nodes\n",
    "            graph.node(node, color=color, penwidth=str(penwidth))\n",
    "\n",
    "    # Iterate through the path sequence to add edges between consecutive nodes\n",
    "    for i in range(len(path_nodes) - 1):\n",
    "        u = path_nodes[i]\n",
    "        v = path_nodes[i+1]\n",
    "\n",
    "        # Add the edge with styling, constraint=false, and no arrowhead\n",
    "        graph.edge(u, v,\n",
    "                   color=color,\n",
    "                   penwidth=str(penwidth),\n",
    "                   constraint='false',\n",
    "                   arrowhead='none') # *** Added to remove arrowheads ***\n",
    "    return graph\n",
    "\n",
    "def normalize(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def get_model_text(idx, model_type_json):\n",
    "    llm_extracted_json = json.loads(model_text[\"llm_analysis_extracted_json\"].iloc[idx])\n",
    "    full_reasoning = normalize(model_text[\"responses\"].iloc[idx][0])\n",
    "    \n",
    "    for i in range(1, len(llm_extracted_json)):\n",
    "        model_parsed_txt = normalize(llm_extracted_json[i][\"rule_original_text\"].split(\"...\")[0])\n",
    "        try:\n",
    "            p1, p2 = full_reasoning.split(model_parsed_txt)\n",
    "            model_type_json[i-1][\"text\"] = p1\n",
    "            full_reasoning = model_parsed_txt + p2\n",
    "        except ValueError:\n",
    "            model_type_json[i-1][\"text\"] = \"\"\n",
    "        except IndexError:\n",
    "            print(idx, i, len(llm_extracted_json), len(model_type_json))\n",
    "            print(\"Skip this one.\")\n",
    "\n",
    "    return model_type_json\n",
    "\n",
    "def count_tokens(text):\n",
    "    try:\n",
    "        # Using cl100k_base tokenizer (similar to what Qwen uses)\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        return len(encoding.encode(text))\n",
    "    except:\n",
    "        # Fallback: approximate token count if tiktoken is not available\n",
    "        return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "samples = get_icl_samples(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_prompt = get_model_types_prompt(f\"{get_models(idx)}\")\n",
    "model_type = call_gemini(model_type_prompt)\n",
    "model_type_json = parse_json(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_type_json)):\n",
    "    model_type_json[i][\"acc\"] = compute_acc(model_type_json[i], get_icl_samples(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1512pt\" height=\"548pt\"\n",
       " viewBox=\"0.00 0.00 1512.23 548.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 544)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-544 1508.23,-544 1508.23,4 -4,4\"/>\n",
       "<!-- root -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>root</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"855.64\" cy=\"-522\" rx=\"29.8\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- glm -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>glm</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"633.64\" cy=\"-450\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"633.64\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">GLM</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;glm -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>root&#45;&gt;glm</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M829.74,-512.83C790.71,-500.53 716.61,-477.16 671.52,-462.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"672.4,-459.55 661.81,-459.88 670.3,-466.23 672.4,-459.55\"/>\n",
       "</g>\n",
       "<!-- decision_tree -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>decision_tree</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"855.64\" cy=\"-450\" rx=\"72.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Decision tree</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;decision_tree -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>root&#45;&gt;decision_tree</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M855.64,-503.7C855.64,-495.98 855.64,-486.71 855.64,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"859.14,-478.1 855.64,-468.1 852.14,-478.1 859.14,-478.1\"/>\n",
       "</g>\n",
       "<!-- knn -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>knn</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"993.64\" cy=\"-450\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"993.64\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">KNN</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;knn -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>root&#45;&gt;knn</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M877.81,-509.75C900.34,-498.33 935.48,-480.5 961.15,-467.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"962.8,-470.57 970.13,-462.92 959.63,-464.32 962.8,-470.57\"/>\n",
       "</g>\n",
       "<!-- linear -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>linear</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"431.64\" cy=\"-378\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Linear</text>\n",
       "</g>\n",
       "<!-- glm&#45;&gt;linear -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>glm&#45;&gt;linear</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M606.39,-439.56C571.85,-427.59 511.98,-406.84 472.09,-393.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"473,-389.63 462.41,-389.66 470.71,-396.24 473,-389.63\"/>\n",
       "</g>\n",
       "<!-- nonlinear -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>nonlinear</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"633.64\" cy=\"-378\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"633.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- glm&#45;&gt;nonlinear -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>glm&#45;&gt;nonlinear</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M633.64,-431.7C633.64,-423.98 633.64,-414.71 633.64,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"637.14,-406.1 633.64,-396.1 630.14,-406.1 637.14,-406.1\"/>\n",
       "</g>\n",
       "<!-- depth1 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>depth1</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"855.64\" cy=\"-378\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">depth=1</text>\n",
       "</g>\n",
       "<!-- decision_tree&#45;&gt;depth1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>decision_tree&#45;&gt;depth1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M855.64,-431.7C855.64,-423.98 855.64,-414.71 855.64,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"859.14,-406.1 855.64,-396.1 852.14,-406.1 859.14,-406.1\"/>\n",
       "</g>\n",
       "<!-- k3 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>k3</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1023.64\" cy=\"-378\" rx=\"29.8\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1023.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">k=3</text>\n",
       "</g>\n",
       "<!-- knn&#45;&gt;k3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>knn&#45;&gt;k3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1000.75,-432.41C1004.21,-424.34 1008.45,-414.43 1012.34,-405.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1015.65,-406.53 1016.37,-395.96 1009.21,-403.77 1015.65,-406.53\"/>\n",
       "</g>\n",
       "<!-- linear1 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>linear1</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"347.64\" cy=\"-306\" rx=\"124.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance Linear</text>\n",
       "</g>\n",
       "<!-- linear&#45;&gt;linear1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>linear&#45;&gt;linear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M413.41,-361.81C402.41,-352.64 388.16,-340.77 375.74,-330.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"377.81,-327.59 367.89,-323.88 373.33,-332.97 377.81,-327.59\"/>\n",
       "</g>\n",
       "<!-- nonlinear1 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>nonlinear1</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"633.64\" cy=\"-306\" rx=\"143.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"633.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- nonlinear&#45;&gt;nonlinear1 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>nonlinear&#45;&gt;nonlinear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M633.64,-359.7C633.64,-351.98 633.64,-342.71 633.64,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"637.14,-334.1 633.64,-324.1 630.14,-334.1 637.14,-334.1\"/>\n",
       "</g>\n",
       "<!-- linear2 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>linear2</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"143.64\" cy=\"-234\" rx=\"143.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance Linear</text>\n",
       "</g>\n",
       "<!-- linear1&#45;&gt;linear2 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>linear1&#45;&gt;linear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.6,-289.2C271.57,-278.9 232.16,-265.38 200.22,-254.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201.16,-251.04 190.57,-251.1 198.89,-257.66 201.16,-251.04\"/>\n",
       "</g>\n",
       "<!-- model_3 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>model_3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"353.64\" cy=\"-234\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"353.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 3</text>\n",
       "</g>\n",
       "<!-- linear1&#45;&gt;model_3 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>linear1&#45;&gt;model_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M349.12,-287.7C349.78,-279.98 350.58,-270.71 351.31,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.8,-262.37 352.17,-252.1 347.83,-261.77 354.8,-262.37\"/>\n",
       "</g>\n",
       "<!-- model_2 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>model_2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"143.64\" cy=\"-162\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 2</text>\n",
       "</g>\n",
       "<!-- linear2&#45;&gt;model_2 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>linear2&#45;&gt;model_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M143.64,-215.7C143.64,-207.98 143.64,-198.71 143.64,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147.14,-190.1 143.64,-180.1 140.14,-190.1 147.14,-190.1\"/>\n",
       "</g>\n",
       "<!-- nonlinear2 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>nonlinear2</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"605.64\" cy=\"-234\" rx=\"162.47\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"605.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- nonlinear1&#45;&gt;nonlinear2 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>nonlinear1&#45;&gt;nonlinear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M626.72,-287.7C623.56,-279.81 619.76,-270.3 616.26,-261.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"619.44,-260.09 612.48,-252.1 612.94,-262.69 619.44,-260.09\"/>\n",
       "</g>\n",
       "<!-- nonlinear3 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>nonlinear3</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"543.64\" cy=\"-162\" rx=\"146.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"543.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">High&#45;Performance Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- nonlinear2&#45;&gt;nonlinear3 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>nonlinear2&#45;&gt;nonlinear3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M590.63,-216.05C583.13,-207.58 573.9,-197.17 565.62,-187.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"568.19,-185.44 558.94,-180.28 562.95,-190.08 568.19,-185.44\"/>\n",
       "</g>\n",
       "<!-- model_1 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>model_1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"543.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"543.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 1</text>\n",
       "</g>\n",
       "<!-- nonlinear3&#45;&gt;model_1 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>nonlinear3&#45;&gt;model_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M543.64,-143.7C543.64,-135.98 543.64,-126.71 543.64,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"547.14,-118.1 543.64,-108.1 540.14,-118.1 547.14,-118.1\"/>\n",
       "</g>\n",
       "<!-- depth2 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>depth2</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"855.64\" cy=\"-306\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">depth=2</text>\n",
       "</g>\n",
       "<!-- depth1&#45;&gt;depth2 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>depth1&#45;&gt;depth2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M855.64,-359.7C855.64,-351.98 855.64,-342.71 855.64,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"859.14,-334.1 855.64,-324.1 852.14,-334.1 859.14,-334.1\"/>\n",
       "</g>\n",
       "<!-- depth3 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>depth3</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"849.64\" cy=\"-234\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"849.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">depth=3</text>\n",
       "</g>\n",
       "<!-- depth2&#45;&gt;depth3 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>depth2&#45;&gt;depth3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M854.15,-287.7C853.49,-279.98 852.7,-270.71 851.96,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"855.44,-261.77 851.1,-252.1 848.47,-262.37 855.44,-261.77\"/>\n",
       "</g>\n",
       "<!-- depth21 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>depth21</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1075.64\" cy=\"-234\" rx=\"135.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1075.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance depth=2</text>\n",
       "</g>\n",
       "<!-- depth2&#45;&gt;depth21 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>depth2&#45;&gt;depth21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M892.46,-293.28C926.18,-282.56 976.68,-266.49 1016.12,-253.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1017.43,-257.19 1025.9,-250.83 1015.31,-250.52 1017.43,-257.19\"/>\n",
       "</g>\n",
       "<!-- depth31 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>depth31</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"843.64\" cy=\"-162\" rx=\"135.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"843.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance depth=3</text>\n",
       "</g>\n",
       "<!-- depth3&#45;&gt;depth31 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>depth3&#45;&gt;depth31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M848.15,-215.7C847.49,-207.98 846.7,-198.71 845.96,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"849.44,-189.77 845.1,-180.1 842.47,-190.37 849.44,-189.77\"/>\n",
       "</g>\n",
       "<!-- depth22 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>depth22</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1150.64\" cy=\"-162\" rx=\"154.07\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1150.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance depth=2</text>\n",
       "</g>\n",
       "<!-- depth21&#45;&gt;depth22 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>depth21&#45;&gt;depth22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1093.79,-216.05C1103.12,-207.35 1114.65,-196.59 1124.88,-187.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1127.47,-189.41 1132.39,-180.03 1122.69,-184.3 1127.47,-189.41\"/>\n",
       "</g>\n",
       "<!-- depth32 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>depth32</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"829.64\" cy=\"-90\" rx=\"154.07\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"829.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance depth=3</text>\n",
       "</g>\n",
       "<!-- depth31&#45;&gt;depth32 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>depth31&#45;&gt;depth32</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M840.18,-143.7C838.63,-135.98 836.78,-126.71 835.06,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"838.45,-117.22 833.06,-108.1 831.59,-118.6 838.45,-117.22\"/>\n",
       "</g>\n",
       "<!-- model_0 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>model_0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1049.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1049.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 0</text>\n",
       "</g>\n",
       "<!-- depth22&#45;&gt;model_0 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>depth22&#45;&gt;model_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1126.19,-144.05C1112.23,-134.38 1094.62,-122.17 1079.8,-111.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1081.67,-108.94 1071.46,-106.12 1077.68,-114.69 1081.67,-108.94\"/>\n",
       "</g>\n",
       "<!-- model_4 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>model_4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1163.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1163.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 4</text>\n",
       "</g>\n",
       "<!-- depth22&#45;&gt;model_4 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>depth22&#45;&gt;model_4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1153.85,-143.7C1155.28,-135.98 1157,-126.71 1158.6,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1162.08,-118.58 1160.46,-108.1 1155.19,-117.3 1162.08,-118.58\"/>\n",
       "</g>\n",
       "<!-- model_5 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>model_5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1277.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1277.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 5</text>\n",
       "</g>\n",
       "<!-- depth22&#45;&gt;model_5 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>depth22&#45;&gt;model_5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1181.06,-144.23C1199.68,-133.97 1223.57,-120.8 1242.94,-110.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1244.69,-113.16 1251.75,-105.27 1241.31,-107.03 1244.69,-113.16\"/>\n",
       "</g>\n",
       "<!-- model_6 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>model_6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"487.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"487.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 6</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_6 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M741.82,-75.14C685.21,-65.6 610.19,-51.82 544.64,-36 540.79,-35.07 536.83,-34.04 532.86,-32.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"533.63,-29.54 523.05,-30.2 531.73,-36.28 533.63,-29.54\"/>\n",
       "</g>\n",
       "<!-- model_7 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>model_7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"601.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"601.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 7</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_7 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M777.62,-73.03C738.4,-60.99 685.14,-44.64 647.51,-33.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"648.41,-29.7 637.82,-30.11 646.35,-36.39 648.41,-29.7\"/>\n",
       "</g>\n",
       "<!-- model_8 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>model_8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"715.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"715.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 8</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_8 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M802.33,-72.23C786.06,-62.24 765.32,-49.51 748.2,-39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"749.98,-35.98 739.63,-33.73 746.32,-41.94 749.98,-35.98\"/>\n",
       "</g>\n",
       "<!-- model_9 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>model_9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"829.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"829.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 9</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_9 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M829.64,-71.7C829.64,-63.98 829.64,-54.71 829.64,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"833.14,-46.1 829.64,-36.1 826.14,-46.1 833.14,-46.1\"/>\n",
       "</g>\n",
       "<!-- model_10 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>model_10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"949.64\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"949.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 10</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_10 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M858.38,-72.23C875.39,-62.31 897.04,-49.68 914.98,-39.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"917.11,-42.03 923.99,-33.96 913.58,-35.98 917.11,-42.03\"/>\n",
       "</g>\n",
       "<!-- model_11 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>model_11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1075.64\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1075.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 11</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_11 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M885.15,-73.2C927.57,-61.13 985.49,-44.65 1026.3,-33.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1027.36,-36.38 1036.02,-30.27 1025.45,-29.64 1027.36,-36.38\"/>\n",
       "</g>\n",
       "<!-- model_12 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>model_12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1201.64\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1201.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 12</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_12 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M921.68,-75.53C983.35,-65.93 1066.21,-51.95 1138.64,-36 1143.05,-35.03 1147.62,-33.95 1152.18,-32.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1153.3,-36.14 1162.12,-30.27 1151.56,-29.36 1153.3,-36.14\"/>\n",
       "</g>\n",
       "<!-- k31 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>k31</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1192.64\" cy=\"-306\" rx=\"113.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1192.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance k=3</text>\n",
       "</g>\n",
       "<!-- k3&#45;&gt;k31 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>k3&#45;&gt;k31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1047.49,-367.12C1072.56,-356.74 1112.67,-340.12 1144.39,-326.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1146.03,-330.09 1153.93,-323.03 1143.35,-323.63 1146.03,-330.09\"/>\n",
       "</g>\n",
       "<!-- k32 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>k32</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1371.64\" cy=\"-234\" rx=\"132.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance k=3</text>\n",
       "</g>\n",
       "<!-- k31&#45;&gt;k32 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>k31&#45;&gt;k32</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1233.26,-289.12C1259.18,-278.98 1293.01,-265.75 1320.72,-254.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1322.21,-258.09 1330.25,-251.19 1319.66,-251.57 1322.21,-258.09\"/>\n",
       "</g>\n",
       "<!-- model_13 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>model_13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1376.64\" cy=\"-162\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1376.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 13</text>\n",
       "</g>\n",
       "<!-- k32&#45;&gt;model_13 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>k32&#45;&gt;model_13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1372.87,-215.7C1373.42,-207.98 1374.09,-198.71 1374.7,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1378.19,-190.33 1375.42,-180.1 1371.21,-189.83 1378.19,-190.33\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f5e301d7a30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the graph\n",
    "ml_graph = create_ml_model_hierarchy()\n",
    "\n",
    "for i in range(len(model_type_json)):\n",
    "    parent_node = get_parent_node(model_type_json[i])\n",
    "    ml_graph.add_node(f\"model_{i}\", f\"Model {i}\", \"model\", parent_node)\n",
    "        \n",
    "ml_graph.prune_node()\n",
    "# Visualize\n",
    "ml_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding highlighted path (no arrows): model_0 -> model_1 -> model_2 -> model_3 -> model_4 -> model_5 -> model_6 -> model_7 -> model_8 -> model_9 -> model_10 -> model_11 -> model_12 -> model_13\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1496pt\" height=\"548pt\"\n",
       " viewBox=\"0.00 0.00 1496.23 548.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 544)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-544 1492.23,-544 1492.23,4 -4,4\"/>\n",
       "<!-- root -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>root</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"855.64\" cy=\"-522\" rx=\"29.8\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">root</text>\n",
       "</g>\n",
       "<!-- glm -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>glm</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"633.64\" cy=\"-450\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"633.64\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">GLM</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;glm -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>root&#45;&gt;glm</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M829.74,-512.83C790.71,-500.53 716.61,-477.16 671.52,-462.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"672.4,-459.55 661.81,-459.88 670.3,-466.23 672.4,-459.55\"/>\n",
       "</g>\n",
       "<!-- decision_tree -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>decision_tree</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"855.64\" cy=\"-450\" rx=\"72.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Decision tree</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;decision_tree -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>root&#45;&gt;decision_tree</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M855.64,-503.7C855.64,-495.98 855.64,-486.71 855.64,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"859.14,-478.1 855.64,-468.1 852.14,-478.1 859.14,-478.1\"/>\n",
       "</g>\n",
       "<!-- knn -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>knn</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"993.64\" cy=\"-450\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"993.64\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">KNN</text>\n",
       "</g>\n",
       "<!-- root&#45;&gt;knn -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>root&#45;&gt;knn</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M877.81,-509.75C900.34,-498.33 935.48,-480.5 961.15,-467.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"962.8,-470.57 970.13,-462.92 959.63,-464.32 962.8,-470.57\"/>\n",
       "</g>\n",
       "<!-- linear -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>linear</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"431.64\" cy=\"-378\" rx=\"40.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Linear</text>\n",
       "</g>\n",
       "<!-- glm&#45;&gt;linear -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>glm&#45;&gt;linear</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M606.39,-439.56C571.85,-427.59 511.98,-406.84 472.09,-393.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"473,-389.63 462.41,-389.66 470.71,-396.24 473,-389.63\"/>\n",
       "</g>\n",
       "<!-- nonlinear -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>nonlinear</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"633.64\" cy=\"-378\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"633.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- glm&#45;&gt;nonlinear -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>glm&#45;&gt;nonlinear</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M633.64,-431.7C633.64,-423.98 633.64,-414.71 633.64,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"637.14,-406.1 633.64,-396.1 630.14,-406.1 637.14,-406.1\"/>\n",
       "</g>\n",
       "<!-- depth1 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>depth1</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"855.64\" cy=\"-378\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">depth=1</text>\n",
       "</g>\n",
       "<!-- decision_tree&#45;&gt;depth1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>decision_tree&#45;&gt;depth1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M855.64,-431.7C855.64,-423.98 855.64,-414.71 855.64,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"859.14,-406.1 855.64,-396.1 852.14,-406.1 859.14,-406.1\"/>\n",
       "</g>\n",
       "<!-- k3 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>k3</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1023.64\" cy=\"-378\" rx=\"29.8\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1023.64\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">k=3</text>\n",
       "</g>\n",
       "<!-- knn&#45;&gt;k3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>knn&#45;&gt;k3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1000.75,-432.41C1004.21,-424.34 1008.45,-414.43 1012.34,-405.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1015.65,-406.53 1016.37,-395.96 1009.21,-403.77 1015.65,-406.53\"/>\n",
       "</g>\n",
       "<!-- linear1 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>linear1</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"347.64\" cy=\"-306\" rx=\"124.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance Linear</text>\n",
       "</g>\n",
       "<!-- linear&#45;&gt;linear1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>linear&#45;&gt;linear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M413.41,-361.81C402.41,-352.64 388.16,-340.77 375.74,-330.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"377.81,-327.59 367.89,-323.88 373.33,-332.97 377.81,-327.59\"/>\n",
       "</g>\n",
       "<!-- nonlinear1 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>nonlinear1</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"633.64\" cy=\"-306\" rx=\"143.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"633.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- nonlinear&#45;&gt;nonlinear1 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>nonlinear&#45;&gt;nonlinear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M633.64,-359.7C633.64,-351.98 633.64,-342.71 633.64,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"637.14,-334.1 633.64,-324.1 630.14,-334.1 637.14,-334.1\"/>\n",
       "</g>\n",
       "<!-- linear2 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>linear2</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"143.64\" cy=\"-234\" rx=\"143.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance Linear</text>\n",
       "</g>\n",
       "<!-- linear1&#45;&gt;linear2 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>linear1&#45;&gt;linear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.6,-289.2C271.57,-278.9 232.16,-265.38 200.22,-254.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201.16,-251.04 190.57,-251.1 198.89,-257.66 201.16,-251.04\"/>\n",
       "</g>\n",
       "<!-- model_3 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>model_3</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"353.64\" cy=\"-234\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"353.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 3</text>\n",
       "</g>\n",
       "<!-- linear1&#45;&gt;model_3 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>linear1&#45;&gt;model_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M349.12,-287.7C349.78,-279.98 350.58,-270.71 351.31,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.8,-262.37 352.17,-252.1 347.83,-261.77 354.8,-262.37\"/>\n",
       "</g>\n",
       "<!-- model_2 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>model_2</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"143.64\" cy=\"-162\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 2</text>\n",
       "</g>\n",
       "<!-- linear2&#45;&gt;model_2 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>linear2&#45;&gt;model_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M143.64,-215.7C143.64,-207.98 143.64,-198.71 143.64,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147.14,-190.1 143.64,-180.1 140.14,-190.1 147.14,-190.1\"/>\n",
       "</g>\n",
       "<!-- nonlinear2 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>nonlinear2</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"605.64\" cy=\"-234\" rx=\"162.47\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"605.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- nonlinear1&#45;&gt;nonlinear2 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>nonlinear1&#45;&gt;nonlinear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M626.72,-287.7C623.56,-279.81 619.76,-270.3 616.26,-261.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"619.44,-260.09 612.48,-252.1 612.94,-262.69 619.44,-260.09\"/>\n",
       "</g>\n",
       "<!-- nonlinear3 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>nonlinear3</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"535.64\" cy=\"-162\" rx=\"146.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"535.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">High&#45;Performance Non&#45;linear</text>\n",
       "</g>\n",
       "<!-- nonlinear2&#45;&gt;nonlinear3 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>nonlinear2&#45;&gt;nonlinear3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M588.69,-216.05C580.14,-207.5 569.6,-196.96 560.17,-187.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"562.46,-184.87 552.91,-180.28 557.51,-189.82 562.46,-184.87\"/>\n",
       "</g>\n",
       "<!-- model_1 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>model_1</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"535.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"535.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 1</text>\n",
       "</g>\n",
       "<!-- nonlinear3&#45;&gt;model_1 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>nonlinear3&#45;&gt;model_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535.64,-143.7C535.64,-135.98 535.64,-126.71 535.64,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"539.14,-118.1 535.64,-108.1 532.14,-118.1 539.14,-118.1\"/>\n",
       "</g>\n",
       "<!-- depth2 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>depth2</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"855.64\" cy=\"-306\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"855.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">depth=2</text>\n",
       "</g>\n",
       "<!-- depth1&#45;&gt;depth2 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>depth1&#45;&gt;depth2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M855.64,-359.7C855.64,-351.98 855.64,-342.71 855.64,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"859.14,-334.1 855.64,-324.1 852.14,-334.1 859.14,-334.1\"/>\n",
       "</g>\n",
       "<!-- depth3 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>depth3</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"849.64\" cy=\"-234\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"849.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">depth=3</text>\n",
       "</g>\n",
       "<!-- depth2&#45;&gt;depth3 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>depth2&#45;&gt;depth3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M854.15,-287.7C853.49,-279.98 852.7,-270.71 851.96,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"855.44,-261.77 851.1,-252.1 848.47,-262.37 855.44,-261.77\"/>\n",
       "</g>\n",
       "<!-- depth21 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>depth21</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1064.64\" cy=\"-234\" rx=\"135.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1064.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance depth=2</text>\n",
       "</g>\n",
       "<!-- depth2&#45;&gt;depth21 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>depth2&#45;&gt;depth21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M891.57,-292.97C923.39,-282.31 970.39,-266.57 1007.39,-254.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1008.68,-257.43 1017.05,-250.94 1006.46,-250.8 1008.68,-257.43\"/>\n",
       "</g>\n",
       "<!-- depth31 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>depth31</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"835.64\" cy=\"-162\" rx=\"135.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"835.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance depth=3</text>\n",
       "</g>\n",
       "<!-- depth3&#45;&gt;depth31 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>depth3&#45;&gt;depth31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M846.18,-215.7C844.63,-207.98 842.78,-198.71 841.06,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"844.45,-189.22 839.06,-180.1 837.59,-190.6 844.45,-189.22\"/>\n",
       "</g>\n",
       "<!-- depth22 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>depth22</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1142.64\" cy=\"-162\" rx=\"154.07\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1142.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance depth=2</text>\n",
       "</g>\n",
       "<!-- depth21&#45;&gt;depth22 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>depth21&#45;&gt;depth22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1083.52,-216.05C1093.31,-207.26 1105.44,-196.38 1116.16,-186.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1118.55,-189.32 1123.66,-180.03 1113.88,-184.11 1118.55,-189.32\"/>\n",
       "</g>\n",
       "<!-- depth32 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>depth32</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"817.64\" cy=\"-90\" rx=\"154.07\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"817.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance depth=3</text>\n",
       "</g>\n",
       "<!-- depth31&#45;&gt;depth32 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>depth31&#45;&gt;depth32</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M831.19,-143.7C829.18,-135.9 826.77,-126.51 824.54,-117.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"827.92,-116.92 822.04,-108.1 821.14,-118.66 827.92,-116.92\"/>\n",
       "</g>\n",
       "<!-- model_0 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>model_0</title>\n",
       "<ellipse fill=\"green\" stroke=\"black\" stroke-width=\"2.5\" cx=\"1151.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1151.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 0</text>\n",
       "</g>\n",
       "<!-- depth22&#45;&gt;model_0 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>depth22&#45;&gt;model_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1144.86,-143.7C1145.85,-135.98 1147.05,-126.71 1148.15,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1151.63,-118.47 1149.44,-108.1 1144.69,-117.58 1151.63,-118.47\"/>\n",
       "</g>\n",
       "<!-- model_4 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>model_4</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"1037.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1037.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 4</text>\n",
       "</g>\n",
       "<!-- depth22&#45;&gt;model_4 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>depth22&#45;&gt;model_4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1117.49,-144.23C1102.88,-134.5 1084.36,-122.15 1068.83,-111.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1070.34,-108.6 1060.08,-105.96 1066.46,-114.42 1070.34,-108.6\"/>\n",
       "</g>\n",
       "<!-- model_5 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>model_5</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"1265.64\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1265.64\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 5</text>\n",
       "</g>\n",
       "<!-- depth22&#45;&gt;model_5 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>depth22&#45;&gt;model_5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1172.1,-144.23C1189.93,-134.08 1212.75,-121.1 1231.39,-110.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1233.2,-113.49 1240.16,-105.5 1229.74,-107.4 1233.2,-113.49\"/>\n",
       "</g>\n",
       "<!-- model_6 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>model_6</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"475.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"475.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 6</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_6 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M729.82,-75.14C673.21,-65.6 598.19,-51.82 532.64,-36 528.79,-35.07 524.83,-34.04 520.86,-32.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"521.63,-29.54 511.05,-30.2 519.73,-36.28 521.63,-29.54\"/>\n",
       "</g>\n",
       "<!-- model_7 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>model_7</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"589.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"589.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 7</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_7 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M765.62,-73.03C726.4,-60.99 673.14,-44.64 635.51,-33.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"636.41,-29.7 625.82,-30.11 634.35,-36.39 636.41,-29.7\"/>\n",
       "</g>\n",
       "<!-- model_8 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>model_8</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"703.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"703.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 8</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_8 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M790.33,-72.23C774.06,-62.24 753.32,-49.51 736.2,-39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"737.98,-35.98 727.63,-33.73 734.32,-41.94 737.98,-35.98\"/>\n",
       "</g>\n",
       "<!-- model_9 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>model_9</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"817.64\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"817.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 9</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_9 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M817.64,-71.7C817.64,-63.98 817.64,-54.71 817.64,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"821.14,-46.1 817.64,-36.1 814.14,-46.1 821.14,-46.1\"/>\n",
       "</g>\n",
       "<!-- model_10 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>model_10</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"937.64\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"937.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 10</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_10 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M846.38,-72.23C863.39,-62.31 885.04,-49.68 902.98,-39.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"905.11,-42.03 911.99,-33.96 901.58,-35.98 905.11,-42.03\"/>\n",
       "</g>\n",
       "<!-- model_11 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>model_11</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"1063.64\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1063.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 11</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_11 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M873.15,-73.2C915.57,-61.13 973.49,-44.65 1014.3,-33.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1015.36,-36.38 1024.02,-30.27 1013.45,-29.64 1015.36,-36.38\"/>\n",
       "</g>\n",
       "<!-- model_12 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>model_12</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" cx=\"1189.64\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1189.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 12</text>\n",
       "</g>\n",
       "<!-- depth32&#45;&gt;model_12 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>depth32&#45;&gt;model_12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M909.68,-75.53C971.35,-65.93 1054.21,-51.95 1126.64,-36 1131.05,-35.03 1135.62,-33.95 1140.18,-32.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1141.3,-36.14 1150.12,-30.27 1139.56,-29.36 1141.3,-36.14\"/>\n",
       "</g>\n",
       "<!-- k31 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>k31</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1192.64\" cy=\"-306\" rx=\"113.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1192.64\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Low&#45;Performance k=3</text>\n",
       "</g>\n",
       "<!-- k3&#45;&gt;k31 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>k3&#45;&gt;k31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1047.49,-367.12C1072.56,-356.74 1112.67,-340.12 1144.39,-326.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1146.03,-330.09 1153.93,-323.03 1143.35,-323.63 1146.03,-330.09\"/>\n",
       "</g>\n",
       "<!-- k32 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>k32</title>\n",
       "<ellipse fill=\"lightyellow\" stroke=\"black\" cx=\"1355.64\" cy=\"-234\" rx=\"132.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1355.64\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Medium&#45;Performance k=3</text>\n",
       "</g>\n",
       "<!-- k31&#45;&gt;k32 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>k31&#45;&gt;k32</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1230.03,-288.94C1253.29,-278.95 1283.39,-266.03 1308.3,-255.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1309.76,-258.51 1317.57,-251.35 1307,-252.08 1309.76,-258.51\"/>\n",
       "</g>\n",
       "<!-- model_13 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>model_13</title>\n",
       "<ellipse fill=\"red\" stroke=\"black\" stroke-width=\"2.5\" cx=\"1368.64\" cy=\"-162\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1368.64\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Model 13</text>\n",
       "</g>\n",
       "<!-- k32&#45;&gt;model_13 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>k32&#45;&gt;model_13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1358.85,-215.7C1360.28,-207.98 1362,-198.71 1363.6,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1367.08,-190.58 1365.46,-180.1 1360.19,-189.3 1367.08,-190.58\"/>\n",
       "</g>\n",
       "<!-- model_0&#45;&gt;model_1 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>model_0&#45;&gt;model_1</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M1129,-106.03C1116.78,-113.71 1101.07,-122.07 1085.64,-126 994.77,-149.17 756.54,-138.82 663.64,-126 631.39,-121.55 595.84,-111.08 570.4,-102.57\"/>\n",
       "</g>\n",
       "<!-- model_1&#45;&gt;model_2 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>model_1&#45;&gt;model_2</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M493.19,-98.58C417.78,-112.05 261.29,-139.99 185.96,-153.44\"/>\n",
       "</g>\n",
       "<!-- model_2&#45;&gt;model_3 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>model_2&#45;&gt;model_3</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M178.37,-174.58C217.3,-187.55 280.05,-208.47 318.96,-221.44\"/>\n",
       "</g>\n",
       "<!-- model_3&#45;&gt;model_4 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>model_3&#45;&gt;model_4</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M353.22,-215.76C353.75,-195.11 358.12,-161.16 379.64,-144 431.94,-102.29 914.76,-119.64 980.64,-108 988.06,-106.69 995.89,-104.74 1003.28,-102.63\"/>\n",
       "</g>\n",
       "<!-- model_4&#45;&gt;model_5 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>model_4&#45;&gt;model_5</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M1060.27,-106.03C1072.49,-113.71 1088.21,-122.07 1103.64,-126 1144.98,-136.54 1158.29,-136.54 1199.64,-126 1215.07,-122.07 1230.78,-113.71 1243,-106.03\"/>\n",
       "</g>\n",
       "<!-- model_5&#45;&gt;model_6 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>model_5&#45;&gt;model_6</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M1231.29,-77.33C1223.89,-75.22 1216.07,-73.29 1208.64,-72 912.18,-20.65 829.09,-87.35 532.64,-36 525.21,-34.71 517.38,-32.78 509.99,-30.67\"/>\n",
       "</g>\n",
       "<!-- model_6&#45;&gt;model_7 -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>model_6&#45;&gt;model_7</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M524.18,-18C529.89,-18 535.6,-18 541.31,-18\"/>\n",
       "</g>\n",
       "<!-- model_7&#45;&gt;model_8 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>model_7&#45;&gt;model_8</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M638.18,-18C643.89,-18 649.6,-18 655.31,-18\"/>\n",
       "</g>\n",
       "<!-- model_8&#45;&gt;model_9 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>model_8&#45;&gt;model_9</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M752.18,-18C757.89,-18 763.6,-18 769.31,-18\"/>\n",
       "</g>\n",
       "<!-- model_9&#45;&gt;model_10 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>model_9&#45;&gt;model_10</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M865.92,-18C871.8,-18 877.68,-18 883.57,-18\"/>\n",
       "</g>\n",
       "<!-- model_10&#45;&gt;model_11 -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>model_10&#45;&gt;model_11</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M991.78,-18C997.67,-18 1003.57,-18 1009.46,-18\"/>\n",
       "</g>\n",
       "<!-- model_11&#45;&gt;model_12 -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>model_11&#45;&gt;model_12</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M1117.78,-18C1123.67,-18 1129.57,-18 1135.46,-18\"/>\n",
       "</g>\n",
       "<!-- model_12&#45;&gt;model_13 -->\n",
       "<g id=\"edge47\" class=\"edge\">\n",
       "<title>model_12&#45;&gt;model_13</title>\n",
       "<path fill=\"none\" stroke=\"blue\" stroke-width=\"2.5\" d=\"M1234.34,-28.31C1262.42,-36.05 1297.87,-49.54 1322.64,-72 1344.41,-91.74 1357.49,-124.21 1363.86,-143.99\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f5e301d7f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = add_highlighted_path(ml_graph.visualize(), [f\"model_{i}\" for i in range(len(model_type_json))], color='blue', penwidth='2.5')\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml_graph.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure.render(\"ml_graph\", format = \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual token counts: [1625, 763, 43, 36, 35, 1674, 1147, 1193, 880, 98, 121, 136, 89, 63, 76, 74, 57, 1951, 1067, 1143, 61, 112, 150, 1503, 1058, 2083, 857, 1017, 947, 963, 296, 215, 180, 160, 1368, 1585, 1522, 1232, 315, 628, 135, 92, 2521, 1110, 45, 2938, 1869, 0, 1334, 79, 73, 80, 79, 181, 1358, 156, 360, 651, 81, 978, 48, 49, 67, 770, 893, 890, 752, 91, 1503, 1173, 400, 369, 30, 611, 1464, 1422, 1471, 492, 691, 32, 18, 69, 1365, 1117, 1094, 1225, 355, 1006, 48, 220, 71, 2712, 1520, 1346, 1294, 232, 1002, 103, 28, 25, 23, 34, 25, 27, 25, 83, 45, 616, 525, 1074, 2146, 1585]\n",
      "Cumulative token counts: [1625, 763, 806, 842, 877, 1674, 1147, 1193, 880, 978, 1099, 1235, 1324, 1387, 1463, 1537, 1594, 1951, 1067, 1143, 1204, 1316, 1466, 1503, 1058, 2083, 857, 1017, 947, 963, 1259, 1474, 1654, 1814, 1368, 1585, 1522, 1232, 1547, 628, 763, 855, 2521, 1110, 1155, 2938, 1869, 0, 1334, 1413, 1486, 1566, 1645, 1826, 1358, 1514, 1874, 651, 732, 978, 1026, 1075, 1142, 1912, 893, 1783, 752, 843, 1503, 1173, 1573, 1942, 1972, 2583, 1464, 1422, 1471, 1963, 691, 723, 741, 810, 1365, 1117, 1094, 1225, 1580, 1006, 1054, 1274, 1345, 2712, 1520, 1346, 1294, 1526, 1002, 1105, 1133, 1158, 1181, 1215, 1240, 1267, 1292, 1375, 1420, 616, 1141, 1074, 2146, 1585]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC2jklEQVR4nOzdeXgb1b0+8HdmZNmKF9mOl8RxdgIOS0JIQqBQICVtWJoSCNAALZDS0lugNKWXSzcKoZQUaIFCWUpblnLZCi1Q+LW0kFAoFxqyOAkpCVmcAI7xbkveZc2c3x8TyVodnVj2zMjv53n0xD6W5HOsN5K+mpnvKEIIASIiIiIiIiJKO9XqCRARERERERFlKhbdRERERERERMOERTcRERERERHRMGHRTURERERERDRMWHQTERERERERDRMW3URERERERETDhEU3ERERERER0TBh0U1EREREREQ0TFh0ExEREREREQ0TFt1ERGRbiqLg5ptvlr7dvn37oCgKHnvssbTPiZxpypQp+OIXv2j1NIiIaBRi0U1ERIN67LHHoCgKFEXB22+/HfdzIQQmTpwIRVEcXdT89a9/haIoqKiogGEYVk+HYBbKoewNdnHqhyv//Oc/cd5552HcuHFwu90oKyvDkiVL8Oc//9nqqQEAuru7cfPNN+Of//yn1VMhInI0l9UTICIiZ8jJycFTTz2Fk08+OWr8zTffRG1tLbKzsy2aWXo8+eSTmDJlCvbt24e1a9di0aJFVk9p1LvnnnvQ2dkZ/v6vf/0rnn76adx9990oKSkJj3/mM5+xYnpDctNNN+GWW27BjBkz8M1vfhOTJ09GS0sL/vrXv2LZsmV48skncfHFF1s6x+7ubqxatQoAcNppp1k6FyIiJ2PRTUREKTnrrLPw3HPP4d5774XLNfDy8dRTT2Hu3Llobm62cHZD09XVhZdeegmrV6/Go48+iieffNK2RXdXVxdyc3OtnsaIWLp0adT39fX1ePrpp7F06VJMmTLFkjmlw/PPP49bbrkF559/Pp566ilkZWWFf3b99dfj73//O/r7+y2cIRERpRN3LyciopRcdNFFaGlpwWuvvRYeCwQCeP7555Nukevq6sL3vvc9TJw4EdnZ2TjiiCPwi1/8AkKIqOv19fXhu9/9LkpLS5Gfn48vfelLqK2tTXif+/fvx9e+9jWUl5cjOzsbRx11FB555JEhre2FF15AT08PLrjgAixfvhx//vOf0dvbG3e93t5e3HzzzTj88MORk5OD8ePH47zzzsOePXvC1zEMA7/61a9wzDHHICcnB6WlpTjjjDOwYcMGAIMfbx57DPvNN98MRVHwwQcf4OKLL0ZRUVF4T4OtW7fi8ssvx7Rp05CTk4Nx48bha1/7GlpaWhL+za644gpUVFQgOzsbU6dOxbe+9S0EAgHU1NRAURTcfffdcbd75513oCgKnn766YR/t4aGBrhcrvDW0EgffvghFEXBr3/9awBAf38/Vq1ahRkzZiAnJwdjx47FySefHJWnQxEMBvHTn/4U06dPR3Z2NqZMmYIf/vCH6OvrO+htH3/8cbhcLlx//fXhsXXr1uGMM86A1+vFmDFjcOqpp+L//u//om4Xelx2796Nyy+/HIWFhfB6vVixYgW6u7sP+ntvvPFGFBcX45FHHokquEMWL14cdahGY2MjrrjiCpSXlyMnJwezZ8/G448/HnWbf/7zn1AUJW5X8ER5u/zyy5GXl4f9+/dj6dKlyMvLQ2lpKf77v/8buq6Hb1daWgoAWLVqVXhX/kPpsUBENNqx6CYiopRMmTIFJ554YlQB9re//Q0+nw/Lly+Pu74QAl/60pdw991344wzzsBdd92FI444Atdffz2uu+66qOt+/etfxz333IMvfOEL+PnPf46srCycffbZcffZ0NCAE044Aa+//jquueYa/OpXv8Jhhx2GK664Avfcc88hr+3JJ5/EwoULMW7cOCxfvhwdHR14+eWXo66j6zq++MUvYtWqVZg7dy5++ctf4jvf+Q58Ph+2bdsWvt4VV1yBlStXYuLEibj99tvx/e9/Hzk5Ofj3v/99yPO74IIL0N3djdtuuw3f+MY3AACvvfYaampqsGLFCtx3331Yvnw5nnnmGZx11llRH2rU1dXh+OOPxzPPPIMvf/nLuPfee/HVr34Vb775Jrq7uzFt2jScdNJJePLJJxP+XfLz83HOOecknFd5eTlOPfVU/PGPf4z72bPPPgtN03DBBRcAMAvVVatWYeHChfj1r3+NH/3oR5g0aRI2bdp0yH8XwMzOT37yExx33HG4++67ceqpp2L16tUJMxnp4YcfxooVK/D9738fd955JwBg7dq1OOWUU+D3+3HTTTfhtttuQ3t7Oz73uc/hvffei7uPCy+8EB0dHVi9ejUuvPBCPPbYYwk/gIi0a9cu7NixA0uXLkV+fv5B19fT04PTTjsNTzzxBC655BLceeed8Hq9uPzyy/GrX/3qoLdPRtd1LF68GGPHjsUvfvELnHrqqfjlL3+Jhx9+GABQWlqKBx98EABw7rnn4oknnsATTzyB884775B/JxHRqCWIiIgG8eijjwoAYv369eLXv/61yM/PF93d3UIIIS644AKxcOFCIYQQkydPFmeffXb4di+++KIAIG699dao+zv//POFoihi9+7dQgghNm/eLACIq666Kup6F198sQAgbrrppvDYFVdcIcaPHy+am5ujrrt8+XLh9XrD89q7d68AIB599NGDrq+hoUG4XC7x29/+Njz2mc98RpxzzjlR13vkkUcEAHHXXXfF3YdhGEIIIdauXSsAiGuvvTbpdQabW+x6b7rpJgFAXHTRRXHXDa010tNPPy0AiLfeeis8dumllwpVVcX69euTzuk3v/mNACC2b98e/lkgEBAlJSXisssui7tdpNBt33///ajxI488Unzuc58Lfz979uyofByKO++8UwAQe/fuFUIMZOfrX/961PX++7//WwAQa9euDY9F5vNXv/qVUBRF/PSnPw3/3DAMMWPGDLF48eLw30UI8+88depU8fnPfz48Fnpcvva1r0X93nPPPVeMHTt20DW89NJLAoC4++67U1rzPffcIwCI//3f/w2PBQIBceKJJ4q8vDzh9/uFEEK88cYbAoB44403om6fKG+XXXaZACBuueWWqOvOmTNHzJ07N/x9U1NTXCaJiEget3QTEVHKLrzwQvT09OCVV15BR0cHXnnllaS7lv/1r3+Fpmm49tpro8a/973vQQiBv/3tb+HrAYi73sqVK6O+F0LgT3/6E5YsWQIhBJqbm8OXxYsXw+fzHdJW02eeeQaqqmLZsmXhsYsuugh/+9vf0NbWFh7705/+hJKSEnz729+Ouw9FUcLXURQFN910U9LrHIr/+q//ihvzeDzhr3t7e9Hc3IwTTjgBAMJ/B8Mw8OKLL2LJkiWYN29e0jldeOGFyMnJidra/fe//x3Nzc34yle+MujczjvvPLhcLjz77LPhsW3btuGDDz7Al7/85fBYYWEh/vOf/2DXrl2pLDkloezE7jnxve99DwDw//7f/4u7zR133IHvfOc7uP322/HjH/84PL5582bs2rULF198MVpaWsLZ6urqwumnn4633norrqt97OPy2c9+Fi0tLfD7/UnnHPpZKlu5Q2scN24cLrroovBYVlYWrr32WnR2duLNN99M6X4SSTT/mpqaQ74/IiJKjEU3ERGlrLS0FIsWLcJTTz2FP//5z9B1Heeff37C63700UeoqKiIKy5mzpwZ/nnoX1VVMX369KjrHXHEEVHfNzU1ob29HQ8//DBKS0ujLitWrABgHvsq63//939x/PHHo6WlBbt378bu3bsxZ84cBAIBPPfcc+Hr7dmzB0cccURUE7lYe/bsQUVFBYqLi6XnMZipU6fGjbW2tuI73/kOysvL4fF4UFpaGr6ez+cDYP7N/H4/jj766EHvv7CwEEuWLMFTTz0VHnvyyScxYcIEfO5znxv0tiUlJTj99NOjdjF/9tln4XK5onZFvuWWW9De3o7DDz8cxxxzDK6//nps3br14IsfRCg7hx12WNT4uHHjUFhYGM5YyJtvvokbbrgBN9xwQ9Rx3ADCHwZcdtllcfn63e9+h76+vvDfNWTSpElR3xcVFQFA1Ic1sQoKCgAAHR0dKa9xxowZUNXot2yx/49khfoNRCoqKhp07kREdGjYvZyIiKRcfPHF+MY3voH6+nqceeaZKCwsHJHfG9rK+JWvfAWXXXZZwuvMmjVL6j537dqF9evXAwBmzJgR9/Mnn3wSV155peRMB5dsi3eogVUikVu1Qy688EK88847uP7663HsscciLy8PhmHgjDPOOKTzjF966aV47rnn8M477+CYY47BX/7yF1x11VVxxV4iy5cvx4oVK7B582Yce+yx+OMf/4jTTz896rRep5xyCvbs2YOXXnoJ//jHP/C73/0Od999Nx566CF8/etfl55vpFT3IjjqqKPQ3t6OJ554At/85jejPswI/c3uvPNOHHvssQlvn5eXF/W9pmkJrydiGgVGqqqqAgC8//77Kc05VbK5SjZ3IiJKPxbdREQk5dxzz8U3v/lN/Pvf/47apTjW5MmT8frrr6OjoyNqa/eOHTvCPw/9axhGeEtyyIcffhh1f6HO5rqup+10Xk8++SSysrLwxBNPxBUhb7/9Nu699158/PHHmDRpEqZPn45169ahv78/YcdpAJg+fTr+/ve/o7W1NenW7tDW0Pb29qhxmS2WbW1tWLNmDVatWoWf/OQn4fHYXbdLS0tRUFAQ1egtmTPOOAOlpaV48sknsWDBAnR3d+OrX/1qSvNZunQpvvnNb4bzsHPnTvzgBz+Iu15xcTFWrFiBFStWoLOzE6eccgpuvvnmQy66Q9nZtWtXeMsvYDbca29vD2cspKSkBM8//zxOPvlknH766Xj77bdRUVEBAOE9LQoKCob1dHGHH344jjjiCLz00kv41a9+FVfIx5o8eTK2bt0KwzCiPgCJ/X+UjlzFGsohEURENIC7lxMRkZS8vDw8+OCDuPnmm7FkyZKk1zvrrLOg63r4lFEhd999NxRFwZlnngkA4X/vvffeqOvFdiPXNA3Lli3Dn/70p4RFZFNTk/RannzySXz2s5/Fl7/8ZZx//vlRl9Dux6Fu7cuWLUNzc3PceoCBLZvLli2DECJhB+vQdQoKClBSUoK33nor6ucPPPBAyvMOfUAQu0U19m+mqiqWLl2Kl19+OXzKskRzAgCXy4WLLroIf/zjH/HYY4/hmGOOSXnPgcLCQixevBh//OMf8cwzz8DtdsedYzv2VGZ5eXk47LDDUjq1VzJnnXUWgPh133XXXQCQsAN+ZWUlXn/9dfT09ODzn/98eF5z587F9OnT8Ytf/AKdnZ1xtzuUfCWzatUqtLS04Otf/zqCwWDcz//xj3/glVdeAWCusb6+PuoDrmAwiPvuuw95eXk49dRTAZjFt6ZpQ8pVrDFjxgCIL+SJiEgOt3QTEZG0ZLt3R1qyZAkWLlyIH/3oR9i3bx9mz56Nf/zjH3jppZewcuXK8JbFY489FhdddBEeeOAB+Hw+fOYzn8GaNWuwe/fuuPv8+c9/jjfeeAMLFizAN77xDRx55JFobW3Fpk2b8Prrr6O1tTXlNaxbtw67d+/GNddck/DnEyZMwHHHHYcnn3wSN9xwAy699FL84Q9/wHXXXYf33nsPn/3sZ9HV1YXXX38dV111Fc455xwsXLgQX/3qV3Hvvfdi165d4V29//Wvf2HhwoXh3/X1r38dP//5z/H1r38d8+bNw1tvvYWdO3emPPeCggKccsopuOOOO9Df348JEybgH//4B/bu3Rt33dtuuw3/+Mc/cOqpp+LKK6/EzJkz8emnn+K5557D22+/HXV4wKWXXop7770Xb7zxBm6//faU5wMAX/7yl/GVr3wFDzzwABYvXhx32MGRRx6J0047DXPnzkVxcTE2bNiA559/PunfPxWzZ8/GZZddhocffhjt7e049dRT8d577+Hxxx/H0qVLsXDhwoS3O+yww/CPf/wDp512GhYvXoy1a9eioKAAv/vd73DmmWfiqKOOwooVKzBhwgTs378fb7zxBgoKCuJOI3eovvzlL+P999/Hz372M1RXV+Oiiy7C5MmT0dLSgldffRVr1qwJH19/5ZVX4je/+Q0uv/xybNy4EVOmTMHzzz+P//u//8M999wT3ovE6/XiggsuwH333QdFUTB9+nS88sorh9TnIMTj8eDII4/Es88+i8MPPxzFxcU4+uijD9ojgIiIYljWN52IiBwh8pRhg4k9ZZgQQnR0dIjvfve7oqKiQmRlZYkZM2aIO++8M+qUTEII0dPTI6699loxduxYkZubK5YsWSI++eSThKcramhoEFdffbWYOHGiyMrKEuPGjROnn366ePjhh8PXSeWUYd/+9rcFALFnz56k17n55psFALFlyxYhhHn6qB/96Edi6tSp4d99/vnnR91HMBgUd955p6iqqhJut1uUlpaKM888U2zcuDF8ne7ubnHFFVcIr9cr8vPzxYUXXigaGxuTnjKsqakpbm61tbXi3HPPFYWFhcLr9YoLLrhA1NXVJfybffTRR+LSSy8VpaWlIjs7W0ybNk1cffXVoq+vL+5+jzrqKKGqqqitrU36d0nE7/cLj8cTd3qrkFtvvVUcf/zxorCwUHg8HlFVVSV+9rOfiUAgkPLviD1lmBBC9Pf3i1WrVoUfk4kTJ4of/OAHore3N+q2ifK5bt06kZ+fL0455ZTwKdiqq6vFeeedJ8aOHSuys7PF5MmTxYUXXijWrFkTvl2yxyX0fyVyfoNZs2aNOOecc0RZWZlwuVyitLRULFmyRLz00ktR12toaBArVqwQJSUlwu12i2OOOSZhtpuamsSyZcvEmDFjRFFRkfjmN78ptm3blvCUYbm5uXG3D60r0jvvvCPmzp0r3G43Tx9GRHSIFCEG6fZBREREo8qcOXNQXFyMNWvWWD0VIiKijMBjuomIiAgAsGHDBmzevBmXXnqp1VMhIiLKGNzSTURENMpt27YNGzduxC9/+Us0NzejpqYGOTk5Vk+LiIgoI3BLNxER0Sj3/PPPY8WKFejv78fTTz/NgpuIiCiNuKWbiIiIiIiIaJhwSzcRERERERHRMGHRTURERERERDRMXFZPwE4Mw0BdXR3y8/OhKIrV0yEiIiIiIiKbEkKgo6MDFRUVUNXk27NZdEeoq6vDxIkTrZ4GEREREREROcQnn3yCysrKpD9n0R0hPz8fgPlHKygosHg2yQWDQVRXV2POnDlwufgQ0sExMySLmSFZzAzJYmZIFjNDsoY7M36/HxMnTgzXkckwrRFCu5QXFBTYvujOzc1FQUEBn3AoJcwMyWJmSBYzQ7KYGZLFzJCskcrMwQ5Ntk0jtbfeegtLlixBRUUFFEXBiy++mPS6//Vf/wVFUXDPPfdEjbe2tuKSSy5BQUEBCgsLccUVV6Czs3N4J05ERERERESUhG2K7q6uLsyePRv333//oNd74YUX8O9//xsVFRVxP7vkkkvwn//8B6+99hpeeeUVvPXWW7jyyiuHa8qW0jTN6imQwzAzJIuZIVnMDMliZkgWM0Oy7JAZRQghrJ5ELEVR8MILL2Dp0qVR4/v378eCBQvw97//HWeffTZWrlyJlStXAgC2b9+OI488EuvXr8e8efMAAK+++irOOuss1NbWJizSY/n9fni9Xvh8PlvvXk5ERERERETWSrV+dMzBEIZh4Ktf/Squv/56HHXUUXE/f/fdd1FYWBguuAFg0aJFUFUV69atw7nnnht3m76+PvT19YW/9/v9AMx9/4PBIABAVVWoqgrDMGAYRvi6oXFd1xH5uUWycU3ToChK+H4jxwFA1/WUxl0uFwzDQFtbGwoKCqAoChRFgaZpcXNMNm7HNQkhosa5pvSuCTAPvwhlJhPWlImPk53WpCgK2traok6h6PQ1ZeLjZKc1aZqG9vZ25OXlhTPj9DVl4uNkpzWpqgq/34/c3Nyo4yGdvKZMfJzstCZFUdDR0YH8/PyUM2b3NWXi42SnNQkh0NXVhYKCgpQzJrOmyK8H45ii+/bbb4fL5cK1116b8Of19fUoKyuLGnO5XCguLkZ9fX3C26xevRqrVq2KG6+urkZubi4AoLS0FNOnT8fevXvR1NQUvk5lZSUqKyuxc+dO+Hy+8Pi0adNQVlaGbdu2oaenJzxeVVWFwsJCVFdXRwVh1qxZcLvd2LBhQ9Qc5s2bh0AggK1bt4bHNE3D/Pnz0dbWhvfeew+FhYVQFAUejwezZ89Gc3Mzampqwtf3er2YOXMm6urqUFtbGx6345p8Ph927NgRHuea0rumvLw8rF+/Hl6vN/zGxulrysTHyU5rmjx5MjZv3gyPxxPOjNPXlImPk53WNGfOHGzbtg0ulyucGaevKRMfJzutacaMGdi1a1f4jWwmrCkTHyc7rWns2LFoaWkJ/5sJa8rEx8lOawo9v4Seb9K9Jq/Xi1Q4YvfyjRs34uyzz8amTZvCu4lPmTIlavfy2267DY8//jg+/PDDqPsqKyvDqlWr8K1vfSvu9yTa0j1x4kS0tLSEdw+w0yc1gPlBQn9/PzZs2IDjjjsufL9O/fQptKZM+kTNjmvSdR3r168PZyYT1pSJj5Od1mQYRlxmnL6mTHyc7LQmAHGZcfqaMvFxstOahBDYuHEj5syZE56v09eUiY+TndZkGAY2bdqE4447Dqo60JrKyWvKxMfJTmvSdR3V1dWYO3du1B416VpTZ2cnioqKMmP38n/9619obGzEpEmTwmO6ruN73/se7rnnHuzbtw/jxo1DY2Nj1O2CwSBaW1sxbty4hPebnZ2N7OzsuHGXyxXXUj70h44V+SKRyniyVvUy45G7lEf+PNkcZcetWlOica4pfWtKlJlkc082brc1ZeLjZJc1GYaRNDNOXdNg41zT0NcUDAaTZsapawIy73EC7LOm0BvpRJlJNvdk43ZZ02BzlB3nmuLHIw//THQ/TlzTwca5JnuvKdF1Es4ppWtZ7Ktf/SoWLVoUNbZ48WJ89atfxYoVKwAAJ554Itrb27Fx40bMnTsXALB27VoYhoEFCxaM+JyHU2iX8shPa4gGw8yQLGaGZDEzJIuZIVnMDMmyS2Zss3t5Z2cndu/eDQCYM2cO7rrrLixcuBDFxcVRW7hDYncvB4AzzzwTDQ0NeOihh9Df348VK1Zg3rx5eOqpp1KaA7uXExERERERUSpSrR9tc57uDRs2YM6cOZgzZw4A4LrrrsOcOXPwk5/8JOX7ePLJJ1FVVYXTTz8dZ511Fk4++WQ8/PDDwzVlyxiGgcbGxpS75RExMySLmSFZzAzJYmZIFjNDsuySGdvsXn7aaadBZqP7vn374saKi4tT3qrtZIZhoKamBsXFxSkfR0CjGzNDspgZksXMkCxmhmQxMyTLLplhWomIiIiIiIiGCYtuIiIiIiIiomHCotuBFEWB1+u1vAsfOQczQ7KYGZLFzJAsZoZkMTMkyy6ZsU33cjtg93IiIiIiIiJKheO6l1PqDMNAbW2t5V34yDmYGZLFzJAsZoZkMTMki5khWXbJDItuB7JLeMg5mBmSxcyQLGaGZDEzJIuZIVl2yQyLbiIiIiIiIqJhwqKbiIiIiIiIaJiw6HYgVVVRWlpq6QneyVmYGZLFzJAsZoZkMTMki5khWXbJDLuXR2D3ciIiIiIiIhsIBAC32+pZDIrdyzOYYRjYs2eP5Q0ByDmYGZLFzJAsZoZkMTMki5kZRfr6AJ9vyHdjl8yw6HYgwzDQ1NRkeXjIOZgZksXMkCxmhmQxMySLmRlFGhvTcjd2yQyLbiIiIiIiIrIHvx/o6bF6FmnFopuIiIiIiIisZxhAc7PVs0g7Ft0OpKoqKisrLe/CR87BzJAsZoZkMTMki5khWczMKNDSAgSDabs7u2SG3csjsHs5ERERERGRBQIB4KOPgFB5WlQElJZaO6eDYPfyDKbrOrZv3w5d162eCjkEM0OymBmSxcyQLGaGZDEzGa6xcaDgThO7ZIZFtwMJIeDz+cCdFChVzAzJYmZIFjNDspgZksXMZLDOTqC7O+13a5fMsOgmIiIiIiIiawiRtlOE2RWLbiIiIiIiIrJGmpun2RGLbgdSVRXTpk2zvAsfOQczQ7KYGZLFzJAsZoZkMTMZqL8faGsbtru3S2bYvTwCu5cTERERERGNkP37ga6uxD9j93Kykq7r2LJli+Vd+Mg5mBmSxcyQLGaGZDEzJIuZyTBdXckL7jSxS2ZYdDuQEAI9PT2Wd+Ej52BmSBYzQ7KYGZLFzJAsZiaDCAE0NY3Ar7FHZlh0ExERERER0chpbQUCAatnMWJYdBMREREREdHI6O83i+5RhEW3A2mahqqqKmiaZvVUyCGYGZLFzJAsZoZkMTMki5nJEI2N5u7lI8AumXFZ+tvpkCiKgsLCQqunQQ7CzJAsZoZkMTMki5khWcxMBujsHPbmaZHskhlu6XagYDCI9evXI5jhJ5Gn9GFmSBYzQ7KYGZLFzJAsZsbhDMPcyj2C7JIZFt0OZXXbe3IeZoZkMTMki5khWcwMyWJmHKy1FbCg+LVDZlh0ExERERER0fAJBIC2NqtnYRkW3URERERERDR8GhpGrHmaHSnC6jOF24jf74fX64XP50NBQYHV00kqdJJ3j8cDRVGsng45ADNDspgZksXMkCxmhmQxMw7l9wP19fK3KyoCSkuH9KuHOzOp1o/c0u1Qbrfb6imQwzAzJIuZIVnMDMliZkgWM+MwhgE0NVk6BTtkhkW3A+m6jg0bNtiiKQA5AzNDspgZksXMkCxmhmQxMw7U3AxY+HjZJTMsuomIiIiIiCi9enuB9narZ2ELLLqJiIiIiIgovUb4nNx2xqKbiIiIiIiI0qe93dzSTQDYvTyKk7qX67oOTdPYuZFSwsyQLGaGZDEzJIuZIVnMjEMEg8C+fWYTtaFIU/fy4cwMu5dnuEAgYPUUyGGYGZLFzJAsZoZkMTMki5lxgMbGoRfcaWSHzLDodiBd17F161bLu/CRczAzJIuZIVnMDMliZkgWM+MAnZ3mxSbskhkW3URERERERDQ0hsHmaUmw6CYiIiIiIqKhaW42j+emOCy6HUrTNKunQA7DzJAsZoZkMTMki5khWcyMTdn4nNx2yAy7l0dwSvdyIiIiIiIiWxAC+PhjoK8vvfebhu7lw43dyzOYEALt7e3g5yWUKmaGZDEzJIuZIVnMDMliZmyqrS39BXea2CUzLLodSNd17Nixw/IufOQczAzJYmZIFjNDspgZksXM2FB/P9DSYvUskrJLZmxTdL/11ltYsmQJKioqoCgKXnzxxfDP+vv7ccMNN+CYY45Bbm4uKioqcOmll6Kuri7qPlpbW3HJJZegoKAAhYWFuOKKK9Bpo5b1REREREREGaOhwdy9nAZlm6K7q6sLs2fPxv333x/3s+7ubmzatAk33ngjNm3ahD//+c/48MMP8aUvfSnqepdccgn+85//4LXXXsMrr7yCt956C1deeeVILYGIiIiIiGh08PuB7m6rZ+EILqsnEHLmmWfizDPPTPgzr9eL1157LWrs17/+NY4//nh8/PHHmDRpErZv345XX30V69evx7x58wAA9913H8466yz84he/QEVFxbCvYaQoigKPxwNFUayeCjkEM0OymBmSxcyQLGaGZDEzNqLrQFOT1bM4KLtkxjZbumX5fD4oioLCwkIAwLvvvovCwsJwwQ0AixYtgqqqWLdunUWzHB6apmH27Nm2aH9PzsDMkCxmhmQxMySLmSFZzIyNNDSYhbfN2SUzttnSLaO3txc33HADLrroonBr9vr6epSVlUVdz+Vyobi4GPX19Qnvp6+vD30Rnfb8fj8AIBgMInjgxO6qqkJVVRiGAcMwwtcNjeu6HtUNL9m4pmlQFCV8v5HjAOIO7k827nK5oOs6GhsbMXbsWKiqCkVRoGla3ByTjdtxTUKIqHGuKb1rEkKgoaEhnJlMWFMmPk52WhMANDY2ori4OPy909eUiY+TndakqiqamppQVFQUzozT15SJj5Od1qQoClpaWlBYWBjOjNPXlImPk53WBJg9nIqLi6PGnLwmRz5ObW2A3w8FgKaqMISAETlHRYGqKEnHdcNA5FHgycY1IaAAQ1qTYRhob2/H2LFj455/0vE4xeYzGccV3f39/bjwwgshhMCDDz44pPtavXo1Vq1aFTdeXV2N3NxcAEBpaSmmT5+OvXv3oiliF4rKykpUVlZi586d8Pl84fFp06ahrKwM27ZtQ09PT3i8qqoKhYWFqK6ujgrCrFmz4Ha7sWHDhqg5zJs3D4FAAFu3bg2PaZqG+fPno729HZs3b0ZhYWF4l4nZs2ejubkZNTU14et7vV7MnDkTdXV1qK2tDY/bcU0+nw87duwIj3NN6V1TXl4etmzZAq/XG969xulrysTHyU5rmjx5Mj744IOoXbKcvqZMfJzstKY5c+Zg586dcLlc4cw4fU2Z+DjZaU0zZsxATU1N+I1sJqwpEx8nO61p7NixaGlpgc/nQ0tEx2wnr8lxj9OuXUBvr7mmnBzMLC1Fnd+P2gMbLwGgNDcX04uLsbetDU1dXQNrKihApdeLnS0t8B24DwCYVlSEsrw8bGtoQE9EgV2VnY1CYEhrCj2/aJqGXbt2JV7TEB4nr9eLVCjC6pOWJaAoCl544QUsXbo0ajxUcNfU1GDt2rUYO3Zs+GePPPIIvve976GtrS08FgwGkZOTg+eeew7nnntu3O9JtKV74sSJaGlpCW9Bt+OnT/39/diwYQOOO+648P1m/CdqXNOQ1qTrOtavXx/OTCasKRMfJzutyTCMuMw4fU2Z+DjZaU0A4jLj9DVl4uNkpzUJIbBx40bMmTMnPF+nrykTHyc7rckwDGzatAnHHXdc1N4RTl6Tox6n3l4YH38MHJjnsG/pLi6GUlY2pDXpuo7q6mrMnTs36rjudD1OnZ2dKCoqgs/nC9ePiThmS3eo4N61axfeeOONqIIbAE488US0t7dj48aNmDt3LgBg7dq1MAwDCxYsSHif2dnZyM7Ojht3uVxwuaL/NKE/dKzIF4lUxmPv91DGFUUJByLy58nmKDtu1ZoSjXNN6VtToswkm3uycbutKRMfJ7usyTCMpJlx6poGG+eahr6mYDCYNDNOXROQeY8TYJ81hd5IJ8pMsrknG7fLmgabo+w41xQ/Hnn4Z6L7ceKaDjZumzUZBtT6erMhWMw8Q0VzrGTjWoJ1Jhw/cFs7P06JrpNwTildawR0dnZi9+7d4e/37t2LzZs3o7i4GOPHj8f555+PTZs24ZVXXoGu6+HjtIuLi+F2uzFz5kycccYZ+MY3voGHHnoI/f39uOaaa7B8+fKM6lwOmKGJ3E2Y6GCYGZLFzJAsZoZkMTMki5mx0KefAoGA1bOQZpfM2Gb38n/+859YuHBh3Phll12Gm2++GVOnTk14uzfeeAOnnXYaALOxwjXXXIOXX34Zqqpi2bJluPfee5GXl5fSHPx+P7xe70F3DyAiIiIiIhoVmpuB1taR/71FRUBp6cj/Xgmp1o+2KbrtwClFt2EYqKurQ0VFRcq7NNDoxsyQLGaGZDEzJIuZIVnMjAU6Osyt3FZIQ9E93JlJtX5kWh3IMAzU1tam3KKeiJkhWcwMyWJmSBYzQ7KYmRHW1wckOfWyU9glMyy6iYiIiIiIaICuA/v3A9wpOi1YdBMREREREZFJCKCuDog5VRcdOhbdDqSqKkpLS3ksC6WMmSFZzAzJYmZIFjNDspiZEdLaCvT0WD2LtLBLZthILYJTGqkRERERERGlXU8P8MknVs/ClEHdy/kxkQMZhoE9e/ZY3hCAnIOZIVnMDMliZkgWM0OymJlhZhiOb5wWyy6ZYdHtQIZhoKmpyfLwkHMwMySLmSFZzAzJYmZIFjMzzBoagP5+q2eRVnbJDItuIiIiIiKi0czvN8/JTcOCRTcREREREdFo1d8PNDZaPYuMxqLbgVRVRWVlpeVd+Mg5mBmSxcyQLGaGZDEzJIuZGSb19ebx3BnILplh9/II7F5ORERERESjRkuLebEjdi8nK+m6ju3bt0PXdaunQg7BzJAsZoZkMTMki5khWcxMmvX22rfgThO7ZIZFtwMJIeDz+cCdFChVzAzJYmZIFjNDspgZksXMpJFhAJ9+avUshp1dMsOim4iIiIiIaDRpbMy404PZGYtuIiIiIiKi0cLnM08RRiOGRbcDqaqKadOmWd6Fj5yDmSFZzAzJYmZIFjNDspiZNPD5gIYGq2cxYuySGXYvj8Du5URERERElJHa2511Pm52Lycr6bqOLVu2WN6Fj5yDmSFZzAzJYmZIFjNDspiZIWhrc1bBnSZ2yYzL0t9Oh0QIgZ6eHsu78JFzMDMki5khWcwMyWJmSBYzc4haW4HmZqtnYQm7ZIZFNxERERERUSZqacn4c3E7AYtuIiIiIiKiTNPcbG7lJsux6HYgTdNQVVUFTdOsngo5BDNDspgZksXMkCxmhmQxMxKamszjuEc5u2SGRbcDKYqCwsJCq6dBDsLMkCxmhmQxMySLmSFZzEyKGhvNTuVkm8ywe7kDBYNBrF+/HsFg0OqpkEMwMySLmSFZzAzJYmZIFjOTgtZWFtwR7JIZFt0OZXXbe3IeZoZkMTMki5khWcwMyWJmBuH3j9ou5YOxQ2ZYdBMRERERETlZVxfQ0GD1LCgJFt1ERERERERO1dsLfPopwPOX25YirD5TuI34/X54vV74fD4UFBRYPZ2kQid593g8UBTF6umQAzAzJIuZIVnMDMliZkgWM5NAfz/w8ceADXahTruiIqC0dEh3MdyZSbV+5JZuh3K73VZPgRyGmSFZzAzJYmZIFjNDspiZCLoO1NZmZsGdRnbIDItuB9J1HRs2bLBFUwByBmaGZDEzJIuZIVnMDMliZiIYBrB/v7mlm5KyS2ZYdBMRERERETmFEOYx3L29Vs+EUsSim4iIiIiIyCkaG81u5eQYLLqJiIiIiIicwOczL+Qo7F4ewUndy3Vdh6Zp7NxIKWFmSBYzQ7KYGZLFzJCsUZ+ZYBDYt888nns0SFP38uHMDLuXZ7hAIGD1FMhhmBmSxcyQLGaGZDEzJGtUZ6ahYfQU3Glkh8yw6HYgXdexdetWy7vwkXMwMySLmSFZzAzJYmZI1qjOjN/P47gPgV0yw6KbiIiIiIjIroJBs3kaORaLbiIiIiIiIrvibuWOx6LboTRNs3oK5DDMDMliZkgWM0OymBmSNeoyw93Kh8wOmWH38ghO6V5OREREREQZbrR1K4+Vhu7lw43dyzOYEALt7e3g5yWUKmaGZDEzJIuZIVnMDMkadZnhbuVDZpfMsOh2IF3XsWPHDsu78JFzMDMki5khWcwMyWJmSNaoygx3K08Lu2SGRTcREREREZFdsFt5xmHRTUREREREZBfcrTzjsOh2IEVR4PF4oCiK1VMhh2BmSBYzQ7KYGZLFzJCsUZEZ7laeVnbJDLuXR2D3ciIiIiIiskQgAHz8Mbdyh7B7OVnJMAw0NjbC4H9IShEzQ7KYGZLFzJAsZoZkZXRmhAA+/ZQFd5rZJTMsuh3IMAzU1NRYHh5yDmaGZDEzJIuZIVnMDMnK6Mw0NQF9fVbPIuPYJTO2KbrfeustLFmyBBUVFVAUBS+++GLUz4UQ+MlPfoLx48fD4/Fg0aJF2LVrV9R1Wltbcckll6CgoACFhYW44oor0NnZOYKrICIiIiIiktDZCbS3Wz0LGka2Kbq7urowe/Zs3H///Ql/fscdd+Dee+/FQw89hHXr1iE3NxeLFy9Gb29v+DqXXHIJ/vOf/+C1117DK6+8grfeegtXXnnlSC2BiIiIiIgodcGg2a2cMprL6gmEnHnmmTjzzDMT/kwIgXvuuQc//vGPcc455wAA/vCHP6C8vBwvvvgili9fju3bt+PVV1/F+vXrMW/ePADAfffdh7POOgu/+MUvUFFRMWJrGW6KosDr9VrehY+cg5khWcwMyWJmSBYzQ7IyMjOffgroutWzyFh2yYxtiu7B7N27F/X19Vi0aFF4zOv1YsGCBXj33XexfPlyvPvuuygsLAwX3ACwaNEiqKqKdevW4dxzz427376+PvRFHDvh9/sBAMFgEMFgEACgqipUVYVhGFHHAoTGdV1HZAP4ZOOapkFRlPD9Ro4DgB7zny3ZuMvlgqqqmDFjBoQQCAaDUBQFmqbFzTHZuB3XJISIGuea0rsmTdOiMpMJa8rEx8lOa9I0DUcccQQMw4h7PnTqmjLxcbLbmqqqqqDrevi+MmFNmfg42WlNM2fOjHrflQlrysTHyU5rmjlzZtRrk6PX1NICtbsbqqLAEAJG5NwVBaqiQDcMRJ5qKtm4pijmmmKOXdYOFJt6zAmrko27VNVcU8S4AkBT1bg5JhsPzXHIaxICCjDkx2nmzJlR74GB9P1/SvVYcUcU3fX19QCA8vLyqPHy8vLwz+rr61FWVhb1c5fLheLi4vB1Yq1evRqrVq2KG6+urkZubi4AoLS0FNOnT8fevXvR1NQUvk5lZSUqKyuxc+dO+Hy+8Pi0adNQVlaGbdu2oaenJzxeVVWFwsJCVFdXRwVh1qxZcLvd2LBhQ9Qc5s2bh0AggK1bt4bHNE3D/Pnz0dbWhq1btyInJwcA4PF4MHv2bDQ3N6OmpiZ8fa/Xi5kzZ6Kurg61tbXhcTuuyefzYceOHeFxrim9ayooKMA777wDt9udMWvKxMfJTmuaOnUqNm/ejEAgkDFrysTHyU5rmjt3Lnbv3o3W1taMWVMmPk52WtPhhx+O7u5u1NXVRb1xdfKaMvFxstOaSkpKkJOTg97eXjQ3Nzt7TboO9PaiNDcX04uLsbetDU0R5+euLChApdeLnS0t8EUcTjutqAhleXnY1tCAnogisqqkBIUeD6rr6qIK5lnjxsGtadiwf3/0miZMQEDXsTWiTtIUBfMrK+Hr7cWOiL+vx+XC7PHj0dzVhZq2toE15eRgZmkp6vx+1B7YeAkgfWvKzkYhMKTHSVVVVFRUYMyYMdi5c+fAmtL0/8nr9SIVtjxPt6IoeOGFF7B06VIAwDvvvIOTTjoJdXV1GD9+fPh6F154IRRFwbPPPovbbrsNjz/+OD788MOo+yorK8OqVavwrW99K+73JNrSPXHiRLS0tITPs2bHTwn7+/uxYcMGHHfcceH75SefXNNga9J1HevXrw9nJhPWlImPk53WZBhGXGacvqZMfJzstCYAcZlx+poy8XGy05qEENi4cSPmzJkTnq/T15SJj5Od1mQYBjZt2oTjjjsOqjrQmspxawoGzfNxB4Pp2yqciVu6i4uhlJUN6XHSdR3V1dWYO3du1C7m6fr/1NnZiaKiooOep9sRW7rHjRsHAGhoaIgquhsaGnDssceGr9PY2Bh1u2AwiNbW1vDtY2VnZyM7Oztu3OVyweWK/tOE/tCxIl8kUhmPvd9DGVcO/KfSNC3q58nmKDtu1ZoSjXNN6VtToswkm3uycbutKRMfJ7usyTCMpJlx6poGG+eahr6myMOdUn0NtfuagMx7nAD7rCnycKdE83Himgabo+w41xQ/Hnm4U6L7ccyamprM83FHfnBwoPCMm3uC+xhs3JVsPMF9JxtXFCXheLI5yo6nvKYDt7VD9pKNJ7pOIrbpXj6YqVOnYty4cVizZk14zO/3Y926dTjxxBMBACeeeCLa29uxcePG8HXWrl0LwzCwYMGCEZ8zERERERFRlNZWIGKXaxodbLOlu7OzE7t37w5/v3fvXmzevBnFxcWYNGkSVq5ciVtvvRUzZszA1KlTceONN6KioiK8C/rMmTNxxhln4Bvf+AYeeugh9Pf345prrsHy5cszqnM5YH6iUlpamvInK0TMDMliZkgWM0OymBmS5fjMdHcDLS1Wz2JUsUtmbHNM9z//+U8sXLgwbvyyyy7DY489BiEEbrrpJjz88MNob2/HySefjAceeACHH354+Lqtra245ppr8PLLL0NVVSxbtgz33nsv8vLyUpqD3++H1+s96D75REREREREKevvN4/jTtAPg5IoKgJKS62exaBSrR9tU3TbgVOKbsMwsHfvXkydOtXyT23IGZgZksXMkCxmhmQxMyTLsZkxDOCTT4CIBs6UgjQU3cOdmVTrRwellUIMw0BTU1PK54UjYmZIFjNDspgZksXMkCzHZqa+ngW3ReySGRbdREREREREw6GlBejstHoWZDEW3UREREREROnW2cnGaQSARbcjqaqKyspKZx3LQpZiZkgWM0OymBmSxcyQLEdlpq/P3K2cLGWXzLCRWgSnNFIjIiIiIiKb0nWzU3l/v9UzcbYM6l7ugI+JKJau69i+fTt0nnKAUsTMkCxmhmQxMySLmSFZjsiMEMCnn7Lgtgm7ZIZFtwMJIeDz+cCdFChVzAzJYmZIFjNDspgZkuWIzDQ1Ad3dVs+CDrBLZlh0ExERERERDZXPB7S3Wz0LsiEW3UREREREREPR1QU0NFg9C7IpFt0OpKoqpk2bZnkXPnIOZoZkMTMki5khWcwMybJtZnp7gbo6q2dBCdglM+xeHoHdy4mIiIiIKGX9/Wancjs3d3Mqdi8nK+m6ji1btljehY+cg5khWcwMyWJmSBYzQ7JslxldB2prWXDbmF0yw6LbgYQQ6OnpsbwLHzkHM0OymBmSxcyQLGaGZNkqM0IA+/fz1GA2Z5fMsOgmIiIiIiKS8emn5rHcRClg0U1ERERERJSqxkags9PqWZCDsOh2IE3TUFVVBU3TrJ4KOQQzQ7KYGZLFzJAsZoZk2SIzra08F7eD2CIzAFyW/nY6JIqioLCw0OppkIMwMySLmSFZzAzJYmZIluWZ8fuB5mbrfj9JszwzB3BLtwMFg0GsX78ewWDQ6qmQQzAzJIuZIVnMDMliZkiWpZnp6ADq60f+99KQ2OV5hkW3Q1nd9p6ch5khWcwMyWJmSBYzQ7IsyQwLbkezw/MMi24iIiIiIqJEOjvNgtsOpykjx2LRTUREREREFKuz0zw1GAtuGiJFWH2mcBvx+/3wer3w+XwoKCiwejpJhU7y7vF4oCiK1dMhB2BmSBYzQ7KYGZLFzJCsEc1MVxdQV8eC20pFRUBp6ZDuYrgzk2r9yC3dDuV2u62eAjkMM0OymBmSxcyQLGaGZI1IZlhwZxQ7PM+w6HYgXdexYcMGWzQFIGdgZkgWM0OymBmSxcyQrBHJDAvujGKX5xkW3URERERERCy4aZi4rJ4AERERERGRpdragOZmFtw0LFh0ExERERHR6BQImKcE6+21eiaUwdi9PIKTupfrug5N09jtk1LCzJAsZoZkMTMki5khWWnNjBBAa6t5YTlkT2nqXj6czzPsXp7hAoGA1VMgh2FmSBYzQ7KYGZLFzJCstGSmtxf4+GOgpYUF9yhgh+cZFt0OpOs6tm7dankXPnIOZoZkMTMki5khWcwMyRpyZoQwj9v++GOgry+9kyNbssvzDI/pJiIiIiKizCWE2Zm8udk8hptohLHoJiIiIiKizGIYZqHd2Wn+axhWz4hGMRbdDqVpmtVTIIdhZkgWM0OymBmSxcyQrEEzYxhmkR0qtHm8NsEezzPsXh7BKd3Loevmxe22eiZERERERNbR9YFCu7ubhXYmSUP38uHG7uUZTASDaN+xA6Kx0XyiIToIIQTa29vBz9goVcwMyWJmSBYzQ7LCmQkEgLY24JNPgD17gIYGbtmmhOzyPMOi24F0w8COpibora3Avn1AezufZGhQuq5jx44dlnduJOdgZkgWM0OymBmS0tcHvakJO6qrodfUAE1NQE+P1bMim7PL8wyP6XY6XQcaG83Cu7QUyM21ekZEREREREMnBNDRYW7V7uszj9lmQzRyIBbdmSIQAPbvB8aMAcrKeLw3ERERETmTrpsblNrbeSglZQQW3Q6kAPC4XFAS/bC729zlvLgYKCkZ2YmRbSmKAo/HA0VJmBqiOMwMyWJmSBYzQ3H6+syt2h0dCQ+dHPQ9MFECdnmeYffyCI7pXh4ImIX1weTmAuPGATZok09ERERElFBXF9DaymO0KRq7l5OVDMNAY2cnjIN9XtLVBXz8sfmpIY1qhmGgsbERBo+DohQxMySLmSFZzAyhtxeorTUPkUyh4DaESO09MNEBdnmeYdHtQIYQqGlrS+0Jp7/fPJ1CR8fwT4xsyzAM1NTUWP6EQ87BzJAsZoZkMTOjWH8/8Omn5sah7u6Ubyb1HpgI9nme4THdo4FhmE9svb2230WDiIiIiDKUrpu7kfN0tzTKsOgeTUKnWxg/nsd5ExEREdHIEMIstFtb2Y2cRiUW3Q6kAPDm5Bxa58bubnNXnooKIDs7zTMju1IUBV6v1/LOjeQczAzJYmZIFjMzCvT3A36/eenvH/LdDek9MI1KdnmeYffyCBnXvXwwigKUlwN2XicREREROYuuA52dZqHNbuQ0FOxeTlYyDAO1Pt/QmkgIAdTXmxd+7pLxDMNAbW2t5U0kyDmYGZLFzJAsZiaDCGEW2nV1QE0N0NAwLAW3IcTQ3wPTqGKX5xnHFN26ruPGG2/E1KlT4fF4MH36dPz0pz9F5IZ6IQR+8pOfYPz48fB4PFi0aBF27dpl4ayHhyEEav3+9Dzh+P3m7uaBwNDvi2zLLk845BzMDMliZkgWM5MBurvNArumxiy4OzuHdWNOWt8D06hgl+cZxxTdt99+Ox588EH8+te/xvbt23H77bfjjjvuwH333Re+zh133IF7770XDz30ENatW4fc3FwsXrwYvb29Fs7cAfr6zMKbpxUjIiIiosGECu09e8xzbPt8bI5GdBCOaaT2zjvv4JxzzsHZZ58NAJgyZQqefvppvPfeewDMrdz33HMPfvzjH+Occ84BAPzhD39AeXk5XnzxRSxfvtyyuTtC6LRiPT3msRNsakJEREREgPn+sKPD3JIdDFo9GyLHcUzR/ZnPfAYPP/wwdu7cicMPPxxbtmzB22+/jbvuugsAsHfvXtTX12PRokXh23i9XixYsADvvvtuwqK7r68PfX194e/9fj8AIBgMInjgCUVVVaiqCsMwonZLCI3ruh61i3uycU3ToChK+H4jxwFz9/lUxl0uFxQAY8eMgSEEgoYBBYCmqjCEiNrdJtm4qihQFSXxeHs79O5uiIjTio3EmoQQUeOKokDTtLi/e7JxOz5OdlqTqqoYO3YsDMMIr83pa8rEx8lua4rNTCasKRMfJ7usSVVVlJSURGXG6WvKxMfJTmtSFAWlpaVRmXH6mjLmcQoEzEK7uxtaXx8UXUcwZvdc7cAGGj1mV+9k4y5VNdeUwnvVZOMAUJqbCwBR8wm9t9UNA5HXTjauKYr5ONlgTYO+Lx/taxICCjCk/0+GYaC0tDTu/2W6/j+lutu6Y4ru73//+/D7/aiqqoKmadB1HT/72c9wySWXAADq6+sBAOXl5VG3Ky8vD/8s1urVq7Fq1aq48erqauQe+A9dWlqK6dOnY+/evWhqagpfp7KyEpWVldi5cyd8Pl94fNq0aSgrK8O2bdvQE9FAoqqqCoWFhaiuro4KwqxZs+B2u7Fhw4aoOcybNw+BQABbt24Nj2mahvnz56OjsxMt3d1o6e4GAHhcLswePx7NXV2oaWsLX9+bk4OZpaWo8/tRe+ADBcB8sppeXIy9bW1o6uoaWFNBASq9Xuzcvx++mhrA7QZcrhFZk8/nw44dO8LjHo8Hs2fPRnNzM2pqagbW5PVi5syZqKurQ21t7cCabPg42W1N7e3taGlpyag1ZeLjZKc1qaqKTZs2ZdSaMvFxstOaSkpKojKTCWvKxMfJTmuaPn061q9fn1FrcuTjZBiYNm4cyjwebNu9Gz0RvX6qSkpQ6PGguq4uqhCbNW4c3JqGDfv3R69pwgQEdB1bI95/a4qC+ZWV8PX2Ykdz88CaDvE97J7W1sTvYVta4Is4rHRaURHK8vKwraEBPREFlx3XlPR9+WheU3Y2CoG0/H9qb28flv9PXq8XqXDMKcOeeeYZXH/99bjzzjtx1FFHYfPmzVi5ciXuuusuXHbZZXjnnXdw0kknoa6uDuPHjw/f7sILL4SiKHj22Wfj7jPRlu6JEyeipaUl3PLdjp986j09qNm8GZMLC6EqyvB++uTxQC0rg+rxZO6nuaNgTUII7NmzB5MnT4aqqhmxpkx8nOy0JgBxmXH6mjLxcbLTmlRVRU1NDSZNmhTOjNPXlImPk53WpCgK9u3bh4kTJ4Yz4/Q1OeZx0nXoHR0Q3d3mFm1dd8QWVAD4qL0dkwsLo8a4VThD11RcDKWsbMhbuj/55BNMmTIl7vknHf+fOjs7UVRUdNBThjlmS/f111+P73//++HdxI855hh89NFHWL16NS677DKMGzcOANDQ0BBVdDc0NODYY49NeJ/Z2dnIzs6OG3e5XHC5ov80oT90rNCDm+p47P0eyrgA0NLdjalFRXBFzCkU2Fiy41rkOvv6gE8+AQoLoY0dCySYTzrWpChKwvFkf3fZcSseJzutSdd1tLS0YOrUqXFzcuqaks1RdpxrSjweDAaTZsapaxpsnGsa+pqCwSCam5sxZcqUlF9D7b4mIPMeJ8A+awoGg2hqasLkyZMTzseJaxpsjrLjaV2TEGYDtNClvx9a9JXCX2oJ7gNA1HvOqPEE7yWTjSuKknA81feqQcNAU1cXJhcWJpxPsrnbeU0HGx/Vazpw26H8fzrY88xQnyMSXScRx3Qv7+7ujltU6FMIAJg6dSrGjRuHNWvWhH/u9/uxbt06nHjiiSM614zU3g7s22d2qCQiIiIi+9J1s+lZY6P5/m3PHrNhrs8H9PdbPTuiUccxW7qXLFmCn/3sZ5g0aRKOOuooVFdX46677sLXvvY1AOYnMitXrsStt96KGTNmYOrUqbjxxhtRUVGBpUuXWjv5TKHr5ikifD6grAzIybF6RkRERESk6+YW7APNzxBxTDYRWc8xRfd9992HG2+8EVdddRUaGxtRUVGBb37zm/jJT34Svs7//M//oKurC1deeSXa29tx8skn49VXX0VOhhWHqqKgsqAg4e4aI6K31zyvt9cLlJQASXatIvtQVRWVlZUp7wJDxMyQLGaGZDEzQyCEWWB3do6qItvy98DkOHZ5nnFMI7WR4Pf74fV6D3ogvOUCAXNXITtQVaC4GCgq4rm9iYiIiIaLEEBXl1lod3WZW7eJMllREVBaavUsBpVq/ciPFh1I13Vsb2qCnuJ54YaVYQDNzeaHAB0dVs+GktB1Hdu3b4/r8kiUDDNDspgZksXMpMAwzPdXn35qHpddVwf4/aO24NYNwz7vgckR7PI845jdy2mAAODr7YWtdlHo7zdfENraeLy3DQkh4PP5wB1bKFXMDMliZkgWM5NEMDiwRbu729zCTQBs+h6YbM0uzzMsuim9Qsd75+ebx3tnZVk9IyIiIiJ76+0d2G28r8/q2RBRmrHopuHR0WG+eJSVmQ3XiIiIiMjcch0ImJeuLh6fTTQKsOh2IFVRMK2oyP6dG4UwTzHW1QWUl7PLuYVUVcW0adMs79xIzsHMkCxmhmRlfGYMwyys+/oGiuxAgOfJHgLHvAcm27DL8wyLbgdSVRVleXlWTyN1nZ3mblPjxwMej9WzGZVUVUVZWZnV0yAHYWZIFjNDsjIuM4YxcJ7s7m7uJj4MVEVx1ntgspxdnmcy9KPFzKbrOrZ8+qmzOjcGg8AnnwAtLVbPZFTSdR1btmyxvHMjOQczQ7KYGZKVEZnp7TXf23zyidldfP9+s6ksC+5hoRuG894Dk6Xs8jzDLd0OJAD0BIPO7NzY0mJ++jt+POBi/EaKEAI9PT2Wd24k52BmSBYzQ7IclZnYXcX7+syCm8XfiHL0e2CyhF2eZ1j10Mjr6QE++sg8zpu7CBEREZFdGIZ5zHWosA4V2TwOm4iGgEU3WUPXgbo6s+geOxbIzrZ6RkRERDRaBIPRzc1Cl2DQ6pkRUQZi0e1AmqqiqqQEWiZ0buzsNC/5+Wbx7XZbPaOMpGkaqqqqoLGDPKWImSFZzAzJGpHMRO4WHnnhbuGOpClK5rwHphFhl9cmFt0OpCgKCjOtC3hHh3kpKDCL76wsq2eUURRFQWFhodXTIAdhZkgWM0Oy0p4ZwzCPsw5d+vq4W3iGycj3wDSs7PLaxO7lDhTUdayvrUUwEz+l9fuBffvM83tzF6+0CQaDWL9+PYL8m1KKmBmSxcyQrCFnpr/f/MC+sdHsFbN7N1BbCzQ3m3vRseDOOEHDyNz3wDQs7PLaxC3dDqU7odPnoRIC8PnMAryw0NzybfEJ7TOB1adKIOdhZkgWM0OyDpoZIcziub/f/DA+1OSst5cfzo9SGf0emIaFHV6bWHSTfQlhnuuyowMoK2OncyIiokxkGANdwkOdwiMLbSIih2PRTfYXDJqdznNzzdOM8fzeREREziJE9Jbq0Nbq7m6gpoZ7tBFRRlOE1WcKtxG/3w+v1wufz4eCggKrp5OU6OtDz+7d8LhcUEZb90ZVNXc3LyqyeiaOIoRAT08PPB7P6MsMHRJmhmQxMxTeFTxya3Xo62DQ/HnU1QV6gsHR+X6GDgkzM8oUFQGlpUO6i+F+bUq1fuQmQ4dyj9ZTshgG0NRkHu9dXg7k5Fg9I8dw83RsJImZIVnMzCgQeYx15O7gh3iO61H7foYOGTNDsuzw2sR9eRxINwxs2L9/dDeS6OsDPv7Y7FjKDpYHpes6NmzYYItGEuQMzAzJYmYyiK6bu353dACtreYZRWprgb17gV27zLOM7N9vfgju85m7iB9Cwa0LwfczJIWZIVl2eW3ilm5ytvZ2801BSQng9Vo9GyIiImcQYmBLdeSlv58fZhMRpRmLbnI+XTc/hff5zC7n3OWciIjI3PocuoSOqw51CWdXcCKiEcOimzJHb6+5y3lBgdl0gcf8EBFRJjOM6K3UkcV1gsZlRERkDXYvj+Ck7uX63r3QFIWdG5MJdTkvLAT4N4IQArquQ9M0ZoZSwsyQLGZmGAWDiXcFd/jWaiEEdCH4foZSxsyMMmnqXj6cr03sXp7hAroOD89XnVyoy7nPZ/5nzc21ekaWCwQC8Hg8Vk+DHISZIVnMzBBEnm4r9pLBx1jz/QzJYmZIlh1em9i93IF0w8DW+np2bkxFIGB2WP3kE6Cnx+rZWEbXdWzdutXyzo3kHMwMyWJmJPT3A52dQEsL8OmnZjfwUFfwujqgudk8NWZvb0YX3LoQfD9DUpgZkmWX1yZ+TESjQ0+PWXjn5pqdzrOzrZ4RERFlOsMwG5dFXjJ8yzUR0ZAJAbz/PnDYYUPevdwuWHTT6NLVZV7y881jvt1uq2dERESZIFRg9/YO/BsIWD0rIqKR190NtLWZ77m7u81L6D146BI5dvPN0e/JFQX43e+AL30JOPZYq1aRViy6HUpj84ih6egwLwUFZvGdlWX1jIadxm7uJImZIVkZn5nQcdehS+i81qGvSRrfz5AsZmYECDFQFIeK5sgiOfL7Y48FTjwx+vZvvAG8/HLqv6+7O35DWG6ueRhOGtjhtYlFtwO5NA3zKyutnkZm8PvNS24u4PWa/2bgk7nL5cL8+fOtngY5CDNDsjIqM7ENzULfO7xbuN24VJXvZ0gKMyNBCPN5K7ZQjiyYe3qAiy6Kvl0wCFxzTeq/p7g4vugeM0Zurl1d5hmHIk2caO6ZOkR2eW1i0e1AQgj4enrgzcnh6RLSJfSEpGnm1u+Cgow67lsIAZ/PB6/Xy8xQSpgZkuW4zMSe4zqywGaTphEhhICvt5fvZyhloy4zkYVzqFju6RkomqdOBaZPj77Nq68Cr79uXieV/hHLlkVvZXa5zO9T3Xunuzt+LDfX3Is0N9e8jBljXkJfR47n5Zl7nca66irzlGFDZJfXJhbdDqQbBnY0N2PehAlwjYYnnJGk6+YxKG1tQE6OufU7P98877eD6bqOHTt2YN68eXDxNBuUAmaGZNk2M7o+UFCHGplxq7Ut6ELw/QxJcWRmhDCfe2K3NPf3A7FbYLu7gfvuGyiye3rM57BkzjorvujWdbndsru6Eu/aHSq6Ywvm2OI50Z4H8+cDxx+f+hyGkV1em2z0qkhkM7295qWx0fwUrqDAfIJxypM8EdFoEAyal9Cx1bFfs1M4EQ2Vrg9sYQ4Vw2Vl8Vto33wT2Lw5vsBOtPeMpgHz5kW/r3S7gb17U59XotPh5ubGj7nd0UVzZOGcqK/R9dcP3OZQ3vfyvXIcFt1EByPEQOM1TTO3fBcUmFvCiYhoeA1WUHNXcCJKRezW5mAQmDIl+jqdncDzz0fvwh3ajTvRrtbnnw8sWhQ91tgIbN+e2px03XwOS3XX7qys6KJ5zBhg/Pj46x17rHk8dF6eeR2Px7xfGcXFcteng2LR7UAKAI/LBX6GZAFdB9rbzYvbbRbf+fm2736uKAo8Hs/oOP6J0oKZIVmHlJlQN/BExXRoCzaL6ozF9zOUsgPHNiudnShoboZSWBjfZOvdd4Fdu+K3SPf0mIVzpPx84M4743/Hv/+d+pwSHct8sAZisVucA4H4Xbsvv9wskmO3TKf6XrOwML4p2Shml/cz0kX3lClT8LWvfQ2XX345Jk2aNBxzooPQNA2zE32yRSMrEACam82Lx2M+gefnm1vDbUbTNMyePdvqaZCDMDMkK2FmDCN5Ud3fP/ixipTxNFXl+5nRQoiBAjgYBMrLo3/e3g689ppZyPb2xhfNB3bR1gAcCQCXXRbfMXvXLuCdd1KbT2iX78hCzONJ7bahIjjRHo9HHTWwhTm0lTlUPKe6xfm441KbB6XELu9npIvulStX4rHHHsMtt9yChQsX4oorrsC5556L7Azq9Gx3hmGgubMTJbm5ULkVyh5CLwqNjeYTa36++aRrkwLcMAw0NzejpKQEqsObwtHIYGYoKSEGCmddD1+M/n40t7WZr02GweOp6aAMIdDc1cX3M04QCJjFcE+PuZdfbIH67rvARx8NFMiRxXLodiFlZcAtt0Tfvq8PWLPmoNMQQiCg68jq6kLcK1OqRbPbbb5XCwajtx67XMCSJebZa0JFcuSWZo/HvAyW1SlT4ndbJ0vZ5f3MIRXdK1euxKZNm/DYY4/h29/+Nq666ipcfPHF+NrXvobj+OnMsDOEQE1bG4rHjOGLlB2FPp2NLcAt/I9uGAZqampQXFzMAopSwsyMUqGCWtfjd/M+yNZpwzBQU1eH4gkTmBlKCd/PjJBgcGDrMWAWvZGamoB//nOgUI68hIrmyG7/3/wmMGdO9H1s3QpUV6c2n0TNv1I8r7MA0AmgMNHZB2bOHDjuObJgDn0dKpoH29p89tkpzYOcwy7vZw75mO7jjjsOxx13HH75y1/igQcewA033IAHH3wQxxxzDK699lqsWLHC8n3niSwlxMD5vxVloFNkXp58QwsioqGI3DodWUiHiuvQFmtumSayl/7+gYK5t9fcLTt2t+bXXwfq6qKvF7mFub9/4LpTpgDf/3707Ts7U9rKHNbbGz8m01w20fOMxwOcemp8gZybO/D1mDEwsrOxq6EB8yZMiL+Po482L0Q2dMjv/Pv7+/HCCy/g0UcfxWuvvYYTTjgBV1xxBWpra/HDH/4Qr7/+Op566ql0zpXIuSIL8MZGc9elvDzzwkMziOhQGUbULt5Rl9imZEQ0coQYKHpD/7rdZlfpSJ98Yha8kdcLXWK3MAPAypVAVVX02PvvAx9+mNq8DqX5VyRFSdxZ+8gjB45zji2cQ+OhsUSH3rlcwEUXHfz384NBcijponvTpk149NFH8fTTT0NVVVx66aW4++67URXxBHDuuedifuzJ3iltFADenBx2+3Syvj7z0tIy0KEy9GnuMBwHrigKvF4v9z6hlDEzIyS0dTlyS3Po38iLENHfh65vo87efG0iWbbMzIEu2VHFb1+f+e/MmfHHDT/7rPlhemjLcmShHevII4Frr40e6+iQ65g91K3MieTnA6ecEl0oR14ix93uxMc0z59vXoaZLTNDtmaX9zPSRff8+fPx+c9/Hg8++CCWLl2KrATt66dOnYrly5enZYIUT9M0zCwttXoalC7BIODzmRfA3PId+UKXhiJc0zTMnDlzyPdDo0fGZyZZMRuiKIkvkbcd7CJE9CVyLLJwziCaqvK1iaSkNTOGEV/0hr7u6zPPOxz7nLZtG/DXv8ZvkU7mRz+K31K9axdQW5vaHBPdt0zBPGZM4ueNOXPM8zVHbmUObVmObAqWk5O4YB4zBrj44tTnYSE+z5Asu7yfkS66a2pqMHny5EGvk5ubi0cfffSQJ0WDMwwDdT4fKgoK2HgkE4W2gre3m9+73QMvlllZZhHuckkV44ZhoK6uDhUVFWxwRCkZ0cwk2qKb7N9EhXJsUQtEbwGOHAtdl9LOEAJ1fj9fmyhlhmGgrrkZFVlZUENbl3t7B7Ysh/7t7QXOPDP+cKzbbwdaW83rJNrlOdLcufFFd28vUFOT+oQTFc2pdMzOyhoogmONHQucddbA63zoQ/fQ9UP/JtvCDAAnnJD6GhyOzzMkyy7vgaWL7sbGRtTX12PBggVR4+vWrYOmaZg3b17aJkeJGUKg1u/HuPx8PuGMBoGAeQltCQ9RlOgC3OUyX9gjLwcKc8MwUFtbi3HjxrHoppQccmZCDbsiO16HGnUl23WaMgJfm0YRIcwPhvv6BrYohy6RhXLocsQR8edUXrMGeO455Pb0JN8CG+mzn40vuv3++NfGZA5lt2xNGyiEc3ISf9h92mlmQR9ZMEcW0Dk5gzdP9XqBL30ptTUQn2dIml3eA0sX3VdffTX+53/+J67o3r9/P26//XasW7cubZMjokFEFjfJqKr5Yq+qZuHe3m6+CQgV5XzBynyhLcCREn0fWxCHPuxpbjZzErsVOXaLcmQXbCKyt8ZG8xK7VTmycI7894Yb4k97+cMfpt5TICsrvujOypLrSSCza3Zoy3Jk8VtZGX+9ykrg8svji2SPxyzw3e6Dz2vu3NTXQESjlnTR/cEHHyQ8F/ecOXPwwQcfpGVSRJQmoeLJMMwtjs3N0W+cXC7zTUXk1nFVNS+KEv1v6GuyTqiwjT1/cqJjiofaZCuUmfZ2S88xTzTqCDFwmqj+fnP340iBAPCvfyUvkmOL6MWLgTPOiL6Pd94BXn019Tn19kbvGq0oZnE62PHPsbePFbtbtqIMFLuRW41D3ycqsC+5xPx7hXqhhK6b6mk5CwtH1a7ZRGQd6aI7OzsbDQ0NmDZtWtT4p59+ChfPPTwiVEVBaW4ud6uhlCXNzMG2lCe8MzW+GE80Flu0hxpRxd5G05xVzMfuFh2ae7KmW4M11Io9NjlZ8RwqskewUzWfZ0jWqMxMaI+jULEbWfj29QETJgCxTZ/eeQf44APzuoFAdOEcuo+Q7GzgV7+Kvr1hAM89l/och9q8C4gvukP3EQiY/8YWvaFLaCzRVuajjgJuuQXtfX3wlpcPfsxyMjHvRSnzjcrnGRoSVVVRWlpq+eGV0lXyF77wBfzgBz/ASy+9BK/XCwBob2/HD3/4Q3z+859P+wQpnqqqmF5cbPU0yEFURUlfZobjONzYYjzZi2lk0RlZ7Cb7N7LQj/0+tJZUGndFNuwaJdKaGRoVHJGZ2CI3EIgulkM/7+szi8DYLcTNzcB990Vfb7Dnw4suAk49NXps3z5gw4bU5tvXZz7vRD4nxh7XfDCJtjJ7vUBZ2UBxHFksJyqgc3Pj7+OnP019i3IiY8ZAHTMGUw/9HmgUcsTzDNmKqqqYPn261dOQL7p/8Ytf4JRTTsHkyZMxZ84cAMDmzZtRXl6OJ554Iu0TjLR//37ccMMN+Nvf/obu7m4cdthhePTRR8PN24QQuOmmm/Db3/4W7e3tOOmkk/Dggw9ixowZwzqvkWYYBva2tmJqURE/6aOUGEJgb1ubfTMjxMB5h8kWbJ8Zsp20ZSa0e3Xs8bSdnebpmUJbhCML5tDXkcXw0qXA4YdH38dvfwu8/35q8ygqii+6VRVoaEh9Lek4p3IgEF1oKwpw3HHmXELFcahAji2ec3LMAjvWiSfGH2MtKw17N/J5hmQxMyTLMAzs3bsXU6dOdVYjtQkTJmDr1q148sknsWXLFng8HqxYsQIXXXRRwnN2p0tbWxtOOukkLFy4EH/7299QWlqKXbt2oaioKHydO+64A/feey8ef/xxTJ06FTfeeCMWL16MDz74ADmyL3I2ZgiBpq4uTC4s5BMOpYSZIVnMDA0qVBhHFL9GTw+6amthFBZCPeyw+K2jr70G1NdHF8yxhXPoMm0a8D//E337hgbgN79JfY6JulrLbCVOdAqqgzXWcrvNS6joTXSKqCOPjC6MYwvmyMI5WcPLK69MfR02xucZksXMkCzDMNDU1ITJkyc7q+gGzPNwXznCT/i33347Jk6cGHX+76lTB3ZKEkLgnnvuwY9//GOcc845AIA//OEPKC8vx4svvojly5eP6HyJiIhso7Exfgtx6OvQJfT9+PHAKadE337bNuDpp6NvE0MVAhN7e6Hm5ADXXw8cdlj0FTZvBvbsSW2+h1Lwxurrix+LLLpDBW/kJVT0ut2Jd6keMwa4+uro64aun5OTWtPBqirzQkREo8Yh7xv0wQcf4OOPP0Yg5oXxS8N0rsG//OUvWLx4MS644AK8+eabmDBhAq666ip84xvfAADs3bsX9fX1WLRoUfg2Xq8XCxYswLvvvsuim4iI7CPUHT624B0zxjzWNtK+fcB//hN/3divQ5cbbgBij3m85x6gtTW1uR19dHzRbRhAS0vq6ztYwXsotx8zxmzI5XYPFL2hryO3LofGEjXZuvBC4MtfPvRTJqoqcMwx8rcjIqJRTbrorqmpwbnnnov3338fiqJAHGgspBx48dKH6ZjMmpoaPPjgg7juuuvwwx/+EOvXr8e1114Lt9uNyy67DPX19QCA8vLyqNuVl5eHfxarr68PfREv7H6/HwAQDAYRPNDRWVVVqKoKwzBgRDRLCY3ruh7+Gww2rmkaFEUJ32/kOBD/d0s27nK5oACoyMuDIQSChgEFgKaqMISAEfE7k42rigJVUZKO64aByHZRycY1RTHXFNNERgtlIabpVLJxl6pCCBE1zjWld02qokRlJhPWlImPk93WVJGfH5WZTFiT9OPk80G0t5vFbH8/tP5+KP390CN3h+7vh3rgX33ZMrMjf+SaVq+GiDnuWD3wGhH5OxUAyqmnwrjooug17d0L7eWXE1//wOtw1F+stxcqELUmNSsLihAJrx+6n/DvDARgGEb045GVBTX0en/gdlG/MysLSnY2svLzIXJzEVRVIOb1ScyZYxbNBwpjLScHhtsNI1QkZ2dDzc6GmpMDIzs7+jVXUaCOHQv9hz8cWvYObC3XI881D5tmLxP/P8WMKwAqCwqinmecvqZMfJzstCbAzAyAqPk4eU2Z+DilbU1CQAGGVD8ZhoHKysq4OkxRFGiaFlfjJRtPVhMaxiDNNCNIF93f+c53MHXqVKxZswZTp07Fe++9h5aWFnzve9/DL37xC9m7S5lhGJg3bx5uu+02AOZ5wbdt24aHHnoIl1122SHd5+rVq7Fq1aq48erqauQe2K2stLQU06dPx969e9HU1BS+TmVlJSorK7Fz5074Io4bmzZtGsrKyrBt2zb0RJymo6qqCoWFhaiuro4KwqxZs+B2u7EhppPpvHnzEAgEsHXr1vCYpmmYP38+Ojo7UXfgAgAelwuzx49Hc1cXatrawtf35uRgZmkp6vx+1B74QAEASnNzMb24GHvb2tDU1TWwpoICVHq92NnSAl9E85dpRUUoy8vDtoYG9ESEtaqkBIUeD6rr6qL+Y84aNw5uTcOG/fuj1zRhAgK6jq0RH4JoioL5lZXw9fZiR3NzeJxrSv+aGrq6wpnJlDVl4uNkpzX1GwY21dVZv6YJE+Dr6MDO+noo/f1Q+/vhMQwcWVSENp8PdS0tgGGgq6oqak37m5tRsmYN1P5+5KsqSlwutPn96OnqgnqgeM4HkKco6OzoQP1nPoO2z342ak37X3wR+WvXhueT53YjS9PQ0dMT9cagIDsbiqJg47x5EBFbdOdNmADU16Mj4nVCAVDo8SBoGOiM2FtMVRR4A4G4x2l8Xx8mA+gNBtEb8fd1axpy3W509/cjEPG60tfSgnEVFVGP0yRdR7HbjZwxY9AaDKJf08IF79jCQnjGjMEnPT3Qs7IQKC1F+/79UY+TqmnIWb4chtuNoydNQkDT8J/2dhjZ2RBZWdBUFfMrKxHs6cH6UPb274/O3pQpwJQpACKy5/NFZ2/MGPP/U2srmiLykQn/nzLxOSIda6r0erG+tjaj1pSJj5Pd1rSntTXj1pSJj9OQ15SdjUIgLfVTe3s7duzYMbAmjwezZ89Gc3MzampqBtbk9WLmzJmoq6tDbW3twJqS1ITeRM0qE1CEiPl44yBKSkqwdu1azJo1C16vF++99x6OOOIIrF27Ft/73vdQXV0tc3cpmzx5Mj7/+c/jd7/7XXjswQcfxK233or9+/ejpqYG06dPR3V1NY499tjwdU499VQce+yx+FXseS6ReEv3xIkT0dLSgoIDn6LZcUt3sLsbH27ahBnFxVBVlZ+ocU0HXZMhBHY0N4czkwlrysTHyU5rEkLgw+ZmHBaRmfDcdR2ivz+8e7SqKFCLi6PX1N0N7T//gRIMmluFQ9c/UDSjvx/Gga3DCAQgFi6EdtRRUWtSnnkGyrvvQu3vP/hW3pwcGHffHb2m7m6o112X+PoJ7sc44wyIAz1Bwo/r//t/wF/+Enf92C0voa2/+u23AwdeP8KP0w03QMQ09VJj55KVBbjdUOfOhXHxxdGPU00NtH/9C0ZWFsSB68HthnJgy7DhdsPIygpvQVYnToSakzPi2VOAuMzw/xPXNNg4hMCu1lZMLyqKanDk5DVl4uNkpzUJIbC7tRWHFReH97J1+poy8XFK25qKi6GUlQ15S/eePXvizmaVri3dnZ2dKCoqgs/nC9ePiUhv6dZ1Hfn5+QDMAryurg5HHHEEJk+ejA8//FD27lJ20kknxd3/zp07MXnyZABmU7Vx48ZhzZo14aLb7/dj3bp1+Na3vpXwPrOzs5Gd4Bgzl8sFV8ypMEJ/6FihBzfV8dj7PaRxRUFHXx9UVYUrYk6hwMaSHdeSNIJJNu5KNp7gvpONK4qScJxrSs+ahBAJM5Ns7snG7bQmIPMeJ0ByTULAZRhxp+5Renrg+vTTgWOGI4pdNaL4DY9/9rNQx4+Pug/9j39E0ebNcLndUIPBqOtrMS9+GDcOuPnm6DV1dAAHGl8mfjaMGZ81K3yMbXitQpi/E+bjlOhRDY/390c9R6uKAjU7O+643cHuRwsG4xphqR6PeVqmUFfqA8WtGvo6NH7g4srKim+mdeml5u8MXe9AcawcuMDtjpqnemD+YYcdBhx2GJK16FIPXGKN9P+noGHAn+R5xhH/n5KMO/o5Ism4XdYUNAz4ensTZibZ3JON22VN4Tlm0OMUnqMN1hTKjKIoCefjxDUdbHxUryn0vmAI9VMwGAzvlZzo+slqvFTHU+2ILl10H3300diyZQumTp2KBQsW4I477oDb7cbDDz+MaYmalqTJd7/7XXzmM5/BbbfdhgsvvBDvvfceHn74YTz88MMAzHCsXLkSt956K2bMmBE+ZVhFRQWWLl06bPMiIorS1WU2rAoVqjEFa9RYMGg2rDrwQWbYs8+a3aaDwaiiOe7+gkGzC/LKldG337cPuPfe1OdcVWV2rI7U2IicujqzOVWSF+qwRJ2mZU8heaC4jjJYt+rIojf0r64j8nhquFzAqaeaPw9dsrMTFstwuxOfz/hznzMvQ3H00UO7PRERETmadNH94x//GF0H9s2/5ZZb8MUvfhGf/exnMXbsWDz77LNpn2DI/Pnz8cILL+AHP/gBbrnlFkydOhX33HMPLrnkkvB1/ud//gddXV248sor0d7ejpNPPhmvvvpqRp2jm4hgdlIWIrrAAszz8ra1xRemoUvs2Be+EF/YPfqoWThHFsaxhXNobP58ILanxJYtwB/+kPpaZs2KL7p37QIijiMaVOxWZ0C+4B3q6ZkSNdDMyQGmTh0odhMVyZHFcMxuXwCA008HTjwx+jZut1lMH+yDgJCLLkp9HURERETDQLroXrx4cfjrww47DDt27EBrayuKioqijq0YDl/84hfxxS9+MenPFUXBLbfcgltuuWVY52E1VVEwrago4e4aRIkccmaEMAsqXTeLTV03i7wxY8xdbiPV1pqnFAoVpaHrRn4f+lpRgGXLom8fCAD33x9fJCe6L8MAzjgDiN2L5e23gZdfTn19p50WX1xu22YW3alItHU2HQWvzH0kmkNOjrnVNivLLFBDhWpsARy6xJ6iCoBy+unAkUcO3E/sbSLvK9HhNHl55qmrhqK4OP7UV2RbfG0iWcwMyWJmSJaqqpg2bVrKu4EPF6miu7+/Hx6PB5s3b8bREbvLFfNN0YhSVRVleXlWT4PSJRgEensHisnIIjPR11OmxO8Gu3GjuTtyktupwSDKQt8XFABf+Ur07RsbgV/9KrrgDV0/kYsuMnfbjfTmm8C//pXamjUtvuhWFECmL8RwbeGVuY9EcwgdsxtZ5IYuobHIQvjAmRKinH66WfjH3kfo+8gCONEW6YkTgdtvT30dCaiHHYaiww4b0n3Q6KIqCl+bSAozQ7KYGZKlqirKEmxcGGlSRXdWVhYmTZo0bOfiptTouo5tn36Ko8vLkzYiGDVCjZZCxWrkv6GiMTSWmxu/Ra+pCaipiS92Q1t3Q5fQ/XzhC0BhYfR9PP000NwcfbvQVuHI+wsGgenTgauuir79rl1mwZuqq64yd0mO9O675hbapH8mAX9fn3lao9LSxFdqaUl9DomeA5I0s0h6eyGidxGWuX2yOWRnm4+zyxVd4Mb+G1nMxjrrLPOxSlTwRo65XPFb+wFg9my5xzORefOGdvs00A0D2xoa+DxDKWNmSBYzQ7KYGZKl6zq2bduGo48+Ommj65EgvXv5j370I/zwhz/EE088wS3cFhEAeoLB6NNuJLyiMAtFRYnvptvZaW5d1fWBAjXZvwBw4FQ+Yf39ZqEnRHSRG1v0hr4/6qj4QnH9emDduvjbJSqedR24+eb4ImflSiDitG+DOuEE4PLLo8d27ZI7/vbEE+OL7j17Uj/+NuLc7WGyLxqJtq4epGAVAIwDpydShlowA4kL3sJCoKLC3IodW+DGXrKy4otuRTG3wCe6fVZW/HiigvfUU+O3wMs65ZSh3T5DpPw8Q3QAM0OymBmSxcyQLCEEenp6IHmW7LSTLrp//etfY/fu3aioqMDkyZORG7Nr5KZNm9I2OUpi/35MvesuqDk5A8fcGkZ8sRwK11e/Cpx0UvR9/OlPZtGciuzs+C13wSDw1FOpz3nMmPiiu7Fx0K2zcZIVi6kW3THnLQQgX/AmmoPMp2apFMyKMlBshgpNTTMvoe7LsQ47bODnkdc9cFuhqmjy+VBQVmYeaxsrP9/8ACP0+yIvkfcbKnoTHUu1eLF5GYqTTx7a7YmIiIiIbEa66Obpt2xACLhbW1M7lQ8w9EIxUbEqu3vGcBW8g92Hqg4UoJqWuFj1es0Oyy6Xef3IQjf0fehflyu+yzQAfP7z5vG3od+TqFgOfT1mTPztp0wB7r47+vfKWrRo0B8Lw0Dr/v2YNmFC4vvPyjJPG0VERERERGklXXTfdNNNwzEPkqBpGvLcbqTctzHR7hShwiu0VVVRogvUUMGqqomPe9U0s0hLdpvQv6Eicvr0+Ps48kjzg4PI28cWu5HjiQrWH/5wYA2xt0vlA4mZM83LUAz1+FtNS7yrdBppioKqkhJo7PZJKWJmJIQO4Yn8N/Jnib4GBp6bE/0buoROj+cAzAzJYmZIFjNDsjRNQ1VVlaXHcwOAIqzewd1G/H4/vF4vfD4fCgoKrJ5Och0dwNq10UVpbMEbWUzn5sZv5Q0d680nLSKyi9jCNbaYBQYvVIH42x/s+0RfR0r0fei6ia4/XCIL8NC/iYr0yOvGNoSMbQxJRERkZ0VFQLIGwDaRav0ovaVbVdVBz8fNzubDL+hyoTo/H3MqKuA61M6N7Pg4qgQNA9V1dUPLDI0qUpkJFaGRe77E7gET+jAwslhNtnWY4oX2RkqXyMI8tidI7NfJvo/B5xmSxcyQLGaGZAWDQVRXV2POnDlwyTYOTiPp3/zCCy9Efd/f34/q6mo8/vjjWLVqVdomRoPTuYMCSWJmKErsISWxW3sNA3pjI1BcbB5iEiqWE+1hw4LZeSIf/0MVWYAfOFWi3twMjB1r3n9oPHarO5+LKAJfm0gWM0Oy7LBRWLroPuecc+LGzj//fBx11FF49tlnccUVV6RlYkREhMS7R6eyi3Tkv4m2Qh+sUA4GgY8+MotuCz8ZJhsLZSuUj9D57YuKBs9M6KwboUsgEH1JdJYHIiIiB0vbO6kTTjgBV155ZbrujogoM8RuUY7tbB+5BTl212vuOkeZKPK0iEB8k0zDAPr744vxQIBbyYmIyJHSUnT39PTg3nvvxYQJE9Jxd3QQmqpi1rhx7NxIKdMUhZlJp9D5yiO75Sc7jtnibpmHStM0zJo1y/Jun+QcacuMqprNPxOd5jEQMAvyvr6BQry/P/EpJcn2+NpEspgZkmWX9zPSRXdRUVFUIzUhBDo6OjBmzBj87//+b1onR8m5+UaYJDEzkrKzzcI60WWUvNi73W6rp0AOM+yZcbvNS25u9LgQ5m7pyS79/dxt3ab42kSymBmSZYf3M9JF99133x1VdKuqitLSUixYsABFRUVpnRwlphsGNuzfj3kTJsA1St7809DoQjAzB5Odbe7mOmaMed70Ub5rt67r2LBhA+bNm2dpt09yDkszoygDH4olE1mY9/cPFOKRX3P39RHF1yaSxcyQLLu8n5H+zZdffvkwTIOIaITl5JjFNYtsotEhsjD3eBJfJ7IIj7yEinUW5UREdAiki+5HH30UeXl5uOCCC6LGn3vuOXR3d+Oyyy5L2+SIiNJGUcwCOy/PvHD3NCKKFWrwlqwojzz9WTAY/XVkwW4YIztvIiKyNemie/Xq1fjNb34TN15WVoYrr7ySRTcR2Yemmcd+5uWZBTe3ZhPRUITOKjDYbuzAQAf2yEI8EDAbwPHYciKiUUcRQm5fqZycHOzYsQNTpkyJGt+3bx9mzpyJnp6edM5vRPn9fni9Xvh8PhQUFFg9naREXx/0vXuhKUrU8fVEyQghoAsxOjKjKEBBAZCfH38qIkqZEAK6rkPTtMzPDKUFM5MiXTeL78jLKD0d2qh6baK0YGZGmaIioLR0SHcx3K9NqdaP0lu6y8rKsHXr1riie8uWLRg7dqz0ROnQBHQdHjY3IgkZnxlFAbxeoLh44Py/NCSBQACeZLvZEiXAzKRA0waaNoYIMXAqtMhCvL/funmOkIx/baK0Y2ZIlh1em6T3tbzoootw7bXX4o033oCu69B1HWvXrsV3vvMdLF++fDjmSDF0w8DW+nroo/BTcTo0uhCZmxlFMT8JnToVKCtjwZ0muq5j69at0Hn+Y0oRMzMEimKeCi0/HygpASZMMJ/TDjsMmDQJKC8HCgvNBpAZtHUvo1+baFgwMyTLLq9N0u9Of/rTn2Lfvn04/fTTw23XDcPApZdeittuuy3tEyQiSkhVB7ZssykaEWUiVTUL7ZycgTEhzK3gvb3mJbRlnEUIEZFtSRfdbrcbzz77LG699VZs3rwZHo8HxxxzDCZPnjwc8yMiihbaGlRYyGKbiEYfRQGys82L12uOhQrx0C7psecfZzd1IiJLHfJ+mDNmzMCMGTPSOReSoGXQ7mU0MhybGUUxT98T6kJ+sK7BlDYaP9QgScyMRSIL8URCpzWLPOd46BJ5+jMLOPa1iSzDzJAsO7w2SXcvX7ZsGY4//njccMMNUeN33HEH1q9fj+eeey6tExxJTulejkAA2LfP6lkQDZ/Qqb5CF57qi4hoeAkRX4gn+5qIaCSkoXv5cBu27uVvvfUWbr755rjxM888E7/85S9l744OgRACvp4eeHNyeLoESokQAr7eXvtnxu0Gxo41dx8nSwkh4PP54PV67Z0Zsg1mxuEUxdyTKJW9iWK3lkdeQlvTU9im45jXJrINZoZk2eW1SXrzUWdnJ9xud9x4VlYW/H5/WiZFg9MNAzuam9m5kVKmC2HvzLjdwPjxwJQpLLhtQtd17Nixw/Jun+QczMwo4nKZzd3y8sz+GiUlwLhxQGXlQNf1KVOAigrzZ16veZhQzC6etn9tItthZkiWXV6bpIvuY445Bs8++2zc+DPPPIMjjzwyLZMiolGCxTYRUeYJnQItL888w0R5OTBxIjB9unkpL48+TzkRUYaT3r38xhtvxHnnnYc9e/bgc5/7HABgzZo1eOqpp/D888+nfYJElIHcbvONmJ17JxARUfppmrnl2+s1T3XW1GRuNQ8ErJ4ZEdGwkS66lyxZghdffBG33XYbnn/+eXg8HsyePRtr165FcXHxcMyRYigAPC4XeCQLpco2mdG0gV0NydYURYHH4+Exc5QyZoZkKS4XPAUFUCZONE9r1tFhXvr6rJ4a2ZRt3s+QY9jltUm6e3ksv9+Pp59+Gr///e+xceNGy/eXHwp2LycaRgUFZgdKG5y2gYiIbEzXo887Hvk1j+UdfVwucw85wwB6e62eDY2k0dy9POStt97C73//e/zpT39CRUUFzjvvPNx///2HenckwTAMNHd2oiQ3Fyq3KFAKDCHQ3NVlTWbcbvP4PY9nZH8vDYlhGGhubkZJSQlUnrKNUsDMkKykmdE08zUj0etGf795MQyzABci+dcH+17XUz8/uaqand1drugu76H7THQRwrydopj/xl5iX49jP1AIzbGvz7wYRup/XDsIdcR3ucz1Rv79I/8NfZ2VZb5ncLvNc86Hvo7IhhEMonn/fpTk5EDt6eFhCXRQdnltkiq66+vr8dhjj+H3v/89/H4/LrzwQvT19eHFF19kE7URZAiBmrY2FI8Zw6KbUmJJZhTFPP1XUVH8GwuyPcMwUFNTg+LiYhZQlBJmhmQdUmZSPa2Z3EQGCnBdHygENW3g99kh06Gt/qEivK/v0IpORYm+RBbBqdI0s5h2uQa+DhXYkeNpZgCo+fRTFM+bB9XlMk9P191tXnp7oz9gibzQqGWX16aUi+4lS5bgrbfewtlnn4177rkHZ5xxBjRNw0MPPTSc8yMiJ8rNBcrK0v/GiIiIKN1CW57t/poV+gAgNzfxzyOLy9hCM1RgDyZUfEd+8BD5AURkgW0XLpd5+NrBDgsNFd+hc8nHXgIBFuc0rFL+X/O3v/0N1157Lb71rW9hxowZwzknInIql8sstvPyrJ4JERHR6BJZVB/KHmaKYhbVmdh7JfShQ2iX9USCQbP47u01L319ZkFOlAYpb2N/++230dHRgblz52LBggX49a9/jebm5uGcGyWhAPDm5LBzI6VsRDJTWGieb5sFd0ZQFAVer9fybp/kHMwMyWJmSNawZsblMs8fX1wMVFQAU6ea55WfMME8XC43115b+Skldnmeke5e3tXVhWeffRaPPPII3nvvPei6jrvuugtf+9rXkJ+fP1zzHBHsXk50CNgojYiIiEaLYHBga3joMtxN7kId3LOzzQsQv4t8MDi8c7BCBnUvH9Ipwz788EP8/ve/xxNPPIH29nZ8/vOfx1/+8pdDvTvLOaXoNnp7Uff++6goKGAjNUqJIQTq/P70ZkZRzE+Di4vZKC0DGYaBuro6VFRUsCkWpYSZIVnMDMmybWYid0s/WAEeKr0i/40di+zinp2d2i7/QkQfox7ZbM+px6unoege7swM+ynDAOCII47AHXfcgdWrV+Pll1/GI488MpS7oxQZQqDW78e4/HwW3ZSStGfG4zG3bic7LooczzAM1NbWYty4cfZ6Y0O2xcyQLGaGZNk2M6Ei2cqNdpHHrEc22xMiuuN96Hh1pxbikuySmbQcmKBpGpYuXYqlS5em4+6IyK5UFSgpMY/fJiIiIiJ7UxQgJ8e8RIoswkdZIW4FdgMgotSMGWNu3bb7KVWIiIiIaHChXddDW+eFGNhNfhRuER9uLLodSFUUlObmctdyStmQMqOq5vE0Xm/6J0a2paoqSktL7bX7HtkaM0OymBmSxcwMI0WJbtQGRO+aHrlF3EHskpkhNVLLNE5ppMbu5TRiuHWbiIiIiEKEiC7Ae3vN2mQ4ZFD3cn5M5ECGYWBPaysMfl5CKTKEkMuMqprFdmUlC+5RyjAM7NmzB8ZwnwaFMgYzQ7KYGZLFzNiAopgNdYuKgHHjgClTgMMOM98zlpQAeXm2Op+5XTLDotuBDCHQ1NXFoptSJpWZMWOAyZO5O/koZxgGmpqaLH+RIudgZkgWM0OymBmbUlXz/WNxMVBRAUybZl7Ky80C3UJ2yYx9PoYgImspirkLDzuTExEREdFQuFzmBhyvFwgGgY4OwO933DHh6cKim4jMphnjx/O820RERESUXi6XuTt6UZF5/HdHh3kZrmPBbYhFtwOpioLKggJ2L6eUDZqZwkJzCzfzRBFUVUVlZaXl3T7JOZgZksXMkCxmJgO43cDYsealuxtobjabsQ0Tu2SG3csjsHs5jSqaZjbAyM21eiZERERENFp1dgItLfG7nrN7ufV+/vOfQ1EUrFy5MjzW29uLq6++GmPHjkVeXh6WLVuGhoYG6yY5THRdx/amJuhsIkEp0g0jOjOhZmksuCkJXdexfft26Lpu9VTIIZgZksXMkCxmJkPl5ZnvS8ePT/tZc+ySGUcW3evXr8dvfvMbzJo1K2r8u9/9Ll5++WU899xzePPNN1FXV4fzzjvPolkOHwHA19sL7qJAqQpnJtQsrbLSVqdzIPsRQsDn84E7Q1GqmBmSxcyQLGYmw+Xnm6cgKy9P2/tUu2TGcUV3Z2cnLrnkEvz2t79FUVFReNzn8+H3v/897rrrLnzuc5/D3Llz8eijj+Kdd97Bv//9bwtnTGQTqgpMnGjuqkNEREREZDeKYnY8nzoVsPPhvpIct6nr6quvxtlnn41Fixbh1ltvDY9v3LgR/f39WLRoUXisqqoKkyZNwrvvvosTTjgh7r76+vrQF3HsgN/vBwAEg0EEg0EA5sH3qqrCMIyo87uFxnVdj/rkJNm4pmlQFCV8v5HjAOJ2eUg27nK5IISAECK8q7ACQFNVGEJEnYc52biqKFAVJem4bhhRW9GTjWuKYq4pZjd37UBDLj3mE6Vk4y5VNdeTwty5pkNbE/LzIdraoGuaedoGHHr2IscVRYGmaXH/P5KN2/X/E9cUP3cAcffj9DVl4uNkpzUB8Zlx+poy8XGy05pCX6c6dyesKRMfJzutKfS1YRhR83HymjLxcUrbmtxuKMCQ1hT6WggRdT/pWlOq5/92VNH9zDPPYNOmTVi/fn3cz+rr6+F2u1EYc47h8vJy1NfXJ7y/1atXY9WqVXHj1dXVyD1wrGtpaSmmT5+OvXv3oqmpKXydyspKVFZWYufOnfD5fOHxadOmoaysDNu2bUNPT094vKqqCoWFhaiuro4KwqxZs+B2u7Fhw4aoOcybNw+BQABbt24Nj2mahvnz56OjsxP9uo7qujpAUeBxuTB7/Hg0d3Whpq0tfH1vTg5mlpaizu9H7YEPFACgNDcX04uLsbetDU1dXQNrKihApdeLnS0t8EV0EZxWVISyvDxsa2hAT0RYq0pKUOjxoLquLqq4nDVuHNyahg3790evacIEBHQdWyMeD01RML+yEr7eXuxobg6Pc01pXFNVFQrGj4e+dy+qq6sH1nQI2fP5fNixY8fAmjwezJ49G83NzaipqRlYk9eLmTNnoq6uDrW1tQNrsuH/J64p8ZqmTp2KMWPGRGXG6WvKxMfJTmuaO3cuysvLozLj9DVl4uNkpzUdfvjhmDZtGrZs2RL1xtXJa8rEx8lOayopKcG0adPw8ccfozniPZaT15SJj5Od1qSqKqZNm4aOjg7s3Lkz7Wvyer1IhWO6l3/yySeYN28eXnvttfCx3KeddhqOPfZY3HPPPXjqqaewYsWKqC3XAHD88cdj4cKFuP322+PuM9GW7okTJ6KlpSXcfc6Wnz719UHfuzc8xq3CXFPC8ZwcYNw4aNnZmffJZyZ+mss1cU1cE9fENXFNXBPXxDU5ak2dnZ0oKio6aPdyxxTdL774Is4999zwHxMw/6CKokBVVfz973/HokWL0NbWFrW1e/LkyVi5ciW++93vHvR3OOWUYXpPD7a99x6OLi+HpjrusHwaCUVFQElJ+Nzbuq5j27ZtOProo6P+DxElw8yQLGaGZDEzJIuZIVnDnZlU60fH7F5++umn4/33348aW7FiBaqqqnDDDTdg4sSJyMrKwpo1a7Bs2TIAwIcffoiPP/4YJ554ohVTHjYCQE8wyO7lFE9LfO5tIQR6enos79xIzsHMkCxmhmQxMySLmSFZdsmMY4ru/Px8HH300VFjubm5GDt2bHj8iiuuwHXXXYfi4mIUFBTg29/+Nk488cSETdSIMo7HY57fkKcCIyIiIiKyjYx6d3733XdDVVUsW7YMfX19WLx4MR544AGrp0U0/PLzzS3cB3YnJyIiIiIie3DMMd0jwSnHdIu+Pvh27IA3JwcKiywqKgJKSwe9ihACPp8PXq+XmaGUMDMki5khWcwMyWJmSNZwZybjjummAYqioNDjsXoaZAdlZUDMafISURQl7nR6RINhZkgWM0OymBmSxcyQLLtkhq2vHSio61hfWxt3WisaRRQFqKhIqeAGgGAwiPXr18edcoEoGWaGZDEzJIuZIVnMDMmyS2a4pduhYs8LTaOIpgETJpjn4ZYQe85CooNhZkgWM0OymBmSxcyQLDtkhkU3kZO43WbBnZVl9UyIiIiIiCgFLLqJnMLjMXcp1zSrZ0JERERERCli9/IITupe3rN7NzwuFzs3jhZer9k07RAfbyEEenp64PF4mBlKCTNDspgZksXMkCxmhmQNd2bYvTzDubm1c3RQFLPY9nqHfFdutzsNE6LRhJkhWcwMyWJmSBYzQ7LskBl2L3cg3TCwYf9+NlPLdC4XUFmZloJb13Vs2LDBFo0kyBmYGZLFzJAsZoZkMTMkyy6Z4ZZuIjvKyTGP33bxvygRERERkZPxHT2R3Qzx+G0iIiIiIrIPFt1EdpHG47eJiIiIiMge2L08gpO6l+t790JTFHZuzBSaZu5O7vEMy90LIaDrOjRNY2YoJcwMyWJmSBYzQ7KYGZI13JlJtX5kIzWHCrCBRObQNLNh2jAV3CGBQGBY758yDzNDspgZksXMkCxmhmTZITMsuh1INwxsra9n9/JMECq4s7OH9dfouo6tW7da3rmRnIOZIVnMDMliZkgWM0Oy7JIZFt1EVhmhgpuIiIiIiKzDopvICiy4iYiIiIhGBRbdDqWxeYRzWVRwa5o2or+PnI+ZIVnMDMliZkgWM0Oy7JAZdi+P4JTu5QgEgH37rJ4FHQpu4SYiIiIiygjsXp7BhBBo7+kBPy9xGAsLbiEE2tvbmRlKGTNDspgZksXMkCxmhmTZJTMsuh1INwzsaG5m93InsXgLt67r2LFjh+WdG8k5mBmSxcyQLGaGZDEzJMsumWHRTTTcVBWYMIG7lBMRERERjUIsuomGk6KYBXdOjtUzISIiIiIiC7DodiAFgMflAvuX25yiABUVgMdj9UygKAo8Hg8Udr2nFDEzJIuZIVnMDMliZkiWXTLD7uUR2L2c0qqiAsjLs3oWREREREQ0DNi9PIMZhoHGzk4Y/LzEvsaNs1XBbRgGGhsbYRiG1VMhh2BmSBYzQ7KYGZLFzJAsu2SGRbcDGUKgpq2NRbddlZUBNttTwjAM1NTUWP6EQ87BzJAsZoZkMTMki5khWXbJDItuonQqKQEKC62eBRERERER2QSLbqJ0KS42L0RERERERAew6HYgBYA3J4fdy+2ksNDcym1TiqLA6/Va3rmRnIOZIVnMDMliZkgWM0Oy7JIZdi+PwO7ldEgKCszGaURERERENGqwe3kGMwwDtT4fG6nZQX6+IwpuwzBQW1treRMJcg5mhmQxMySLmSFZzAzJsktmWHQ7kCEEav1+Ft1Wy88Hxo+3ehYpscsTDjkHM0OymBmSxcyQLGaGZNklMyy6iQ5FXp4jtnATEREREZG1WHQTycrNNbdws4kHEREREREdBItuB1IVBaW5uVBZ9I28MWOAigrHFdyqqqK0tBSqyv/ylBpmhmQxMySLmSFZzAzJsktm2L08AruX06A8HmDCBIBP9EREREREox67l2cwwzCwp7WVjdRGUk6OowtuwzCwZ88ey5tIkHMwMySLmSFZzAzJYmZIll0y48wKYpQzhEBTVxeL7pGSnQ1UVjq24AbMJ5ympibLn3DIOZgZksXMkCxmhmQxMyTLLplxbhVBNBJcLkdv4SYiIiIiImuxkiBKRlXNgtvlsnomRERERETkUCy6HUhVFFQWFLB7+XAbP97ctTwDqKqKyspKyzs3knMwMySLmSFZzAzJYmZIll0yw+7lEdi9nMLKyoDCQqtnQURERERENsXu5RlM13Vsb2qCziYSw6OwMOMKbl3XsX37dui6bvVUyCGYGZLFzJAsZoZkMTMkyy6ZYdHtQAKAr7cX3EVhGOTlmVu5M4wQAj6fD9yxhVLFzJAsZoZkMTMki5khWXbJDItuopDsbGDcOKtnQUREREREGYRFNxHAU4MREREREdGwYIXhQKqiYFpREbuXp8soODWYqqqYNm2a5Z0byTmYGZLFzJAsZoZkMTMkyy6ZcUxiV69ejfnz5yM/Px9lZWVYunQpPvzww6jr9Pb24uqrr8bYsWORl5eHZcuWoaGhwaIZDx9VVVGWl8eiO10y6NRgyaiqirKyMsufcMg5mBmSxcyQLGaGZDEzJMsumXFMYt98801cffXV+Pe//43XXnsN/f39+MIXvoCurq7wdb773e/i5ZdfxnPPPYc333wTdXV1OO+88yyc9fDQdR1bPv2U3cvToaQEyM21ehbDTtd1bNmyxfLOjeQczAzJYmZIFjNDspgZkmWXzDhmf9pXX3016vvHHnsMZWVl2LhxI0455RT4fD78/ve/x1NPPYXPfe5zAIBHH30UM2fOxL///W+ccMIJVkx7WAgAPcEgu5cPVX4+UFxs9SxGhBACPT09lnduJOdgZkgWM0OymBmSxcyQLLtkxjFFdyyfzwcAKD5QNG3cuBH9/f1YtGhR+DpVVVWYNGkS3n333YRFd19fH/r6+sLf+/1+AEAwGEQwGARg7pKgqioMw4ARsWU5NK7retSDmGxc0zQoihK+38hxAHGfviQbd7lcEEJACBHe0q0A0FQVhhAwIn5nsnFVUaAqStJx3TCiCvpk45qimGuK2eKuHdjtXY8Jd7Jxl6qa60lh7mlbU04O1PLyYX+cIscVRYGmaXFZSjaezuwBiJuP09eUiY+TndYExGfG6WvKxMfJTmsC4jPj9DVl4uNkpzWFvk517k5YUyY+TnZaU+hrwzCi5uPkNWXi42SnNYW+FkJE3U+61hT59WAcWXQbhoGVK1fipJNOwtFHHw0AqK+vh9vtRmFhYdR1y8vLUV9fn/B+Vq9ejVWrVsWNV1dXI/fALselpaWYPn069u7di6ampvB1KisrUVlZiZ07d4Y/AACAadOmoaysDNu2bUNPT094vKqqCoWFhaiuro4KwqxZs+B2u7Fhw4aoOcybNw+BQABbt24Nj2mahvnz58Pf0YH23l5sqquDoijwuFyYPX48mru6UNPWFr6+NycHM0tLUef3o/bABwoAUJqbi+nFxdjb1oamiN3zKwsKUOn1YmdLC3y9vQNrKipCWV4etjU0oCcirFUlJSj0eFBdVxdVMM8aNw5uTcOG/fuj1zRhAgK6jq0Rj4emKJhfWQlfby92NDeHx4d1TYqCaVVVKFNVbNuyZdgeJ5/Phx07dgysyePB7Nmz0dzcjJqamoE1eb2YOXMm6urqUFtbO7CmNGYvLy8PPp8PmzZtgnLgww+nrykTHyc7rWny5Mno6emJyozT15SJj5Od1jRnzhwEg8GozDh9TZn4ONlpTTNmzAAAbNmyJeqNq5PXlImPk53WNHbsWADARx99hJaWloxYUyY+TnZaU2hDgt/vx65du9K+Jq/Xi1Qowupt7YfgW9/6Fv72t7/h7bffRmVlJQDgqaeewooVK6K2XAPA8ccfj4ULF+L222+Pu59EW7onTpyIlpYWFBQUALDXJzWA+emT0duLtu3bUZCTA0VRuKVbdk0TJkDNzR1VnxICQGtrKwoKCsJvhp2+pkx8nOy0JkVR0NbWhvz8/HBmnL6mTHyc7LQmTdPQ3t6OvLy8cGacvqZMfJzstCZVVeH3+5GbmxvOjNPXlImPk53WpCgKOjo6kJ+fn3LG7L6mTHyc7LQmIQS6urpQUFCQcsZk1tTZ2YmioiL4fL5w/ZiI44rua665Bi+99BLeeustTJ06NTy+du1anH766Whra4va2j158mSsXLkS3/3udw96336/H16v96B/NMsFAsC+fVbPwplKS4GiIqtnQUREREREDpdq/eiY7uVCCFxzzTV44YUXsHbt2qiCGwDmzp2LrKwsrFmzJjz24Ycf4uOPP8aJJ5440tMdVkFdx/ra2rgtzHQQBQWjtuAOBoNYv3593CeFRMkwMySLmSFZzAzJYmZIll0y45hjuq+++mo89dRTeOmll5Cfnx8+Ttvr9cLj8cDr9eKKK67Addddh+LiYhQUFODb3/42TjzxxIzqXB4Su4s2HURODlBebvUsLBW7Cw7RwTAzJIuZIVnMDMliZkiWHTLjmKL7wQcfBACcdtppUeOPPvooLr/8cgDA3XffDVVVsWzZMvT19WHx4sV44IEHRnimZDuaBlRUABHHixEREREREY0ExxTdqRx6npOTg/vvvx/333//CMyIHEFRzILb5ZioExERERFRBnFcI7Xh5JRGaqKvDz27d8PjckV1+6QEysuBFFv5ZzIhBHp6euDxeJgZSgkzQ7KYGZLFzJAsZoZkDXdmMq6RGkVzH2iJT4PwellwR3C73VZPgRyGmSFZzAzJYmZIFjNDsuyQGRbdDqQbBjbs389maoPxeICyMqtnYRu6rmPDhg22aCRBzsDMkCxmhmQxMySLmSFZdskMi27KPC4XMH48G6cREREREZHlWHRTZmHjNCIiIiIishEW3ZRZysvNc3ITERERERHZALuXR3BS93J9715oisLOjZGKioDSUqtnYUtCCOi6Dk3TmBlKCTNDspgZksXMkCxmhmQNd2bYvTzDBdhAItqYMUBJidWzsLVAIGD1FMhhmBmSxcyQLGaGZDEzJMsOmWHR7UC6YWBrfT27l4dkZbFx2kHouo6tW7da3rmRnIOZIVnMDMliZkgWM0Oy7JIZFt3kbKHGaTxvORERERER2RCLbnK28nIgO9vqWRARERERESXEotuhNO5KDRQUmBdKica9AUgSM0OymBmSxcyQLGaGZNkhM+xeHsEp3csRCAD79lk9C2u53cCkSYDKz42IiIiIiGjksXt5BhNCoL2nB6P28xJFMRunseBOmRAC7e3tozczJI2ZIVnMDMliZkgWM0Oy7JIZVi0OpBsGdjQ3j97u5WVlPI5bkq7r2LFjh+WdG8k5mBmSxcyQLGaGZDEzJMsumWHRTc6Snw94vVbPgoiIiIiIKCUsusk53G6zWzkREREREZFDsOh2IAWAx+XCqOpfzuO4h0RRFHg8Hijsek8pYmZIFjNDspgZksXMkCy7ZIbdyyOwe7mNlZUBhYVWz4KIiIiIiAgAu5dnNMMw0NjZCWO0fF6Sl8eCe4gMw0BjYyMMw7B6KuQQzAzJYmZIFjNDspgZkmWXzLDodiBDCNS0tY2OojsrCxg3zupZOJ5hGKipqbH8CYecg5khWcwMyWJmSBYzQ7LskhkW3WRv48bxOG4iIiIiInIsVjNkX4WFgMdj9SyIiIiIiIgOGYtuB1IAeHNyMrt7ucsFlJRYPYuMoSgKvF6v5Z0byTmYGZLFzJAsZoZkMTMkyy6ZYffyCOxebiMVFWYDNSIiIiIiIhti9/IMZhgGan2+zG2klpfHgjvNDMNAbW2t5U0kyDmYGZLFzJAsZoZkMTMkyy6ZYdHtQIYQqPX7M7PoVlXznNyUVnZ5wiHnYGZIFjNDspgZksXMkCy7ZIZFN9lLaal5PDcREREREVEGYNFN9uHxAF6v1bMgIiIiIiJKGxbdDqQqCkpzc6FmUudGRQHKy62eRcZSVRWlpaVQec5zShEzQ7KYGZLFzJAsZoZk2SUz7F4egd3LLTR2rHkhIiIiIiJyAHYvz2CGYWBPa2vmNFJzu4HiYqtnkdEMw8CePXssbyJBzsHMkCxmhmQxMySLmSFZdskMi24HMoRAU1dX5hTd5eXm7uU0bAzDQFNTk+VPOOQczAzJYmZIFjNDspgZkmWXzLDoJmt5vWYDNSIiIiIiogzEopus43KZpwgjIiIiIiLKUCy6HUhVFFQWFDi/e3l5OcDukyNCVVVUVlZa3rmRnIOZIVnMDMliZkgWM0Oy7JIZdi+PwO7lI8jr5SnCiIiIiIjIsdi9PIPpuo7tTU3QndpEgruVjzhd17F9+3boum71VMghmBmSxcyQLGaGZDEzJMsumWHR7UACgK+3F47dRWHcOO5WPsKEEPD5fOCOLZQqZoZkMTMki5khWcwMybJLZlj50MjyeoExY6yeBRERERER0Yhg0U0jJyuLu5UTEREREdGowqLbgVRFwbSiIud1L+du5ZZRVRXTpk2zvHMjOQczQ7KYGZLFzJAsZoZk2SUz7F4egd3Lh1FhIVBWZvUsiIiIiIiI0oLdyzOYruvY8umnzule7nZzt3KL6bqOLVu2WN65kZyDmSFZzAzJYmZIFjNDsuySGRbdDiQA9ASDzuleXl4OOG1X+AwjhEBPT4/lnRvJOZgZksXMkCxmhmQxMyTLLplh0U3Dq6gI8HisngUREREREZElWHTT8HG7gZISq2dBRERERERkmYwsuu+//35MmTIFOTk5WLBgAd577z2rp5RWmqqiqqQEmt132eZu5bahaRqqqqqgaZrVUyGHYGZIFjNDspgZksXMkCy7ZCbjiu5nn30W1113HW666SZs2rQJs2fPxuLFi9HY2Gj11NJGURQUejxQ7FzQFhZyt3IbURQFhYWF9s4M2QozQ7KYGZLFzJAsZoZk2SUzGVd033XXXfjGN76BFStW4Mgjj8RDDz2EMWPG4JFHHrF6amkT1HWsr61F0K7dy7OyuFu5zQSDQaxfvx7BYNDqqZBDMDMki5khWcwMyWJmSJZdMpNRRXcgEMDGjRuxaNGi8Jiqqli0aBHeffddC2eWfrqduzaWlwMWn4Ce4ll9qgRyHmaGZDEzJIuZIVnMDMmyQ2ZcVk8gnZqbm6HrOsrLy6PGy8vLsWPHjrjr9/X1oa+vL/y93+8HYH4iEvo0RFVVqKoKwzBgRGxZDo3ruh7Vgj7ZuKZpUBQl7lOW0PEFsWFINu5yuSCEgBAifJ5uBeZx3oYQMCJ+Z7JxVVGgKkrScd0wok5HlmxcUxRzTZFb3PPzoXk8gBDSa4ocVxQFmqbF/d2Tjdv1cbLLmgDEzcfpa8rEx8lOawLiM+P0NWXi42SnNQHxmXH6mjLxcbLTmkJfpzp3J6wpEx8nO60p9LVhGFHzcfKaMvFxstOaQl8LIaLuJ11rivx6MBlVdMtavXo1Vq1aFTdeXV2N3NxcAEBpaSmmT5+OvXv3oqmpKXydyspKVFZWYufOnfD5fOHxadOmoaysDNu2bUNPT094vKqqCoWFhaiuro4KwqxZs+B2u7Fhw4aoOcybNw+BQABbt24Nj2mahvnz58Pf0YH23l5sqquDoijwuFyYPX48mru6UNPWFr6+NycHM0tLUef3o/bABwoAUJqbi+nFxdjb1oamrq6BNRUUoNLrxc6WFvh6ewfWVFSEsrw8bGtoQE9EWKtKSlDo8aC6rs7c8q4ogMeDWUVF0mvy+XxRH4x4PB7Mnj0bzc3NqKmpGViT14uZM2eirq4OtbW1A2uy4eNkpzXl5eXB5/Nh06ZN4WNanL6mTHyc7LSmyZMno6enJyozTl9TJj5OdlrTnDlzEAwGozLj9DVl4uNkpzXNmDEDALBly5aoN65OXlMmPk52WtPYsWMBAB999BFaWloyYk2Z+DjZaU2hDQl+vx+7du1K+5q8Xi9SoQirzxSeRoFAAGPGjMHzzz+PpUuXhscvu+wytLe346WXXoq6fqIt3RMnTkRLSwsKCgoA2OuTGsD89Mno7UXXrl3IcbmgKIp9tnSPHw/k5o76T9TsuCYA6OzsRE5OTvjNsNPXlImPk53WpCgKurq6kJ2dHc6M09eUiY+TndakaRq6u7vhdrvDmXH6mjLxcbLTmlRVRW9vL7KysqKaHDl5TZn4ONlpTYqioK+vD9nZ2SlnzO5rysTHyU5rEkKgv78fOTk5KWdMZk2dnZ0oKiqCz+cL14+JZFTRDQALFizA8ccfj/vuuw+Aucl/0qRJuOaaa/D9739/0Nv6/X54vd6D/tGsJvr6oO/dGy56bSEvD6iosHoWlEToyTP05EV0MMwMyWJmSBYzQ7KYGZI13JlJtX7MuG5X1113HX7729/i8ccfx/bt2/Gtb30LXV1dWLFihdVTSxvdMLBh/377NFPTNLN5GtmWruvYsGFD3CeCRMkwMySLmSFZzAzJYmZIll0yk3HHdH/5y19GU1MTfvKTn6C+vh7HHnssXn311bjmapRGpaVm4U1ERERERERRMq7oBoBrrrkG11xzjdXTGB3GjAFsvCs+ERERERGRlTJu93IaQarK3cqJiIiIiIgGkXGN1IaCjdQklZUBhYXW/X5KGRuPkCxmhmQxMySLmSFZzAzJYiM1GpKA1Q0kcnJYcDtMIBCwegrkMMwMyWJmSBYzQ7KYGZJlh8yw6HYg3TCwtb7e2u7l3K3cUXRdx9atWy3v3EjOwcyQLGaGZDEzJIuZIVl2yQyLbpJXVARkZ1s9CyIiIiIiIttj0U1yXC5g7FirZ0FEREREROQILLodSrOqeURZmdm1nBxH47nUSRIzQ7KYGZLFzJAsZoZk2SEz7F4ewSndyxEIAPv2jfzvzcsDKipG/vcSERERERHZDLuXZzAhBNp7ejCin5eoqrmVmxxJCIH29vaRzQw5GjNDspgZksXMkCxmhmTZJTMsuh1INwzsaG4e2e7lY8eax3OTI+m6jh07dljeuZGcg5khWcwMyWJmSBYzQ7LskhkW3XRw2dlmx3IiIiIiIiKSwqKbDo7n5CYiIiIiIjokLLodSAHgcbkwIv3LCwuBnJyR+E00jBRFgcfjgWJV13tyHGaGZDEzJIuZIVnMDMmyS2bYvTwCu5fHcLmAKVN4ijAiIiIiIqIY7F6ewQzDQGNnJ4zh/ryktJQFd4YwDAONjY0wDMPqqZBDMDMki5khWcwMyWJmSJZdMsOKyoEMIVDT1ja8RXduLpCfP3z3TyPKMAzU1NRY/oRDzsHMkCxmhmQxMySLmSFZdskMi26KpyjmVm4iIiIiIiIaEhbdFK+oCHC7rZ4FERERERGR47HodiAFgDcnZ3i6l7tcwNixw3HPZCFFUeD1ei3v3EjOwcyQLGaGZDEzJIuZIVl2yQy7l0dg93IA48fzWG4iIiIiIqKDYPfyDGYYBmp9vvQ3UhszhgV3hjIMA7W1tZY3kSDnYGZI1v9v796Do6rv/4+/dkOuYC6QkICBSAgS7peoEAWkkkmACmq1KjIKYrEiVq2AilYiWCFYi1rGCy0jdFpHbDuC1Aoj5SbyjVQwF8IlEgSRSyACSbhDdj+/PzD7Y02AHMlm9yTPx8zO7J7z2ZPPh/PibN57Tj6HzMAqMgOryAysCpTMUHTbkNsY7a2srN+i2+GQWreuv+0hoATKAQf2QWZgFZmBVWQGVpEZWBUomaHoxnnR0UyeBgAAAAD1jKIbTJ4GAAAAAD5C0W1DTodDcc2by1lfs/DFxUlOotCYOZ1OxcXFycl+Rh2RGVhFZmAVmYFVZAZWBUpmmL38Ak1y9vKICCkxsX62BQAAAABNBLOXN2Jut1s7jxy58onUmDytyXC73dq5c6ffJ5GAfZAZWEVmYBWZgVVkBlYFSmYoum3IbYzKTpy48qKbydOaDLfbrbKyMr8fcGAfZAZWkRlYRWZgFZmBVYGSGYruporJ0wAAAADA5yi6m6rYWCZPAwAAAAAfo+qyIafDocTIyJ8+e3lYmBTIE8Wh3jmdTiUmJvp95kbYB5mBVWQGVpEZWEVmYFWgZIbZyy/QZGYvb9dOCg+vt+4AAAAAQFPD7OWNmMvl0rayMrl+yoQAV11Fwd0EuVwubdu2TS6Xy99dgU2QGVhFZmAVmYFVZAZWBUpmKLptyEiqOH1ali9RcDikuDgf9AiBzhijiooKcWEL6orMwCoyA6vIDKwiM7AqUDJD0d2UxMScn7UcAAAAANAgKLqbimbNpJYt/d0LAAAAAGhSKLptyOlwKDkmxtrs5dwirElzOp1KTk72+8yNsA8yA6vIDKwiM7CKzMCqQMkMs5dfoNHOXh4WJrVv77PuAAAAAEBTw+zljZjL5VLBgQN1n728dWvfdggBz+VyqaCgwO8zN8I+yAysIjOwiszAKjIDqwIlMxTdNmQknaqqqtvs5Vdddf5MN5o0Y4xOnTrl95kbYR9kBlaRGVhFZmAVmYFVgZIZiu7GjFuEAQAAAIBfUXQ3Zi1bcoswAAAAAPAjim4bCnI6lRobq6BLzV7OLcJwgaCgIKWmpiooKMjfXYFNkBlYRWZgFZmBVWQGVgVKZjgNakMOh0PR4eGXbhQbe/7yckA/ZCY62t/dgI2QGVhFZmAVmYFVZAZWBUpmONNtQ1Uul77cu1dVF5u9PDRUCuRbnqHBVVVV6csvv1RVVZW/uwKbIDOwiszAKjIDq8gMrAqUzFB025TrUjPwxcY2XEdgG/6+VQLsh8zAKjIDq8gMrCIzsCoQMkPR3diEhUnNm/u7FwAAAAAAUXQ3PpzlBgAAAICAYYuie/fu3XrooYfUoUMHhYeHq2PHjsrOztbZs2e92hUWFmrgwIEKCwtTu3bt9Morr/ipx74V5HSqZ0JCzdnLIyLOP4AfCQoKUs+ePf0+cyPsg8zAKjIDq8gMrCIzsCpQMmOL2cu3b98ut9utefPmKSUlRUVFRRo/frxOnDihV199VZJUWVmpzMxMZWRk6J133tHmzZs1btw4RUdH6+GHH/bzCOpfSG3B4Sw3LiEkJMTfXYDNkBlYRWZgFZmBVWQGVgVCZmxxpnvo0KFasGCBMjMzlZycrJEjR2ry5Mn68MMPPW3ee+89nT17Vu+++666deume++9V48//rjmzJnjx577hsvt1sZ9+7wnU2vR4vzfcwO1cLlc2rhxY0BMJAF7IDOwiszAKjIDq8gMrAqUzNjiTHdtKioq1LJlS8/r3NxcDRo0yOubjKysLM2ePVtHjx5VTExMjW2cOXNGZ86c8byurKyUdH5q+epp5Z1Op5xOp9xut9wX3KKrernL5ZK5oPi92PKgoCA5HI4a09VXX+rw4yBcbHmzZs1kjJExRq4f+uOQFNSqVY0+OhwOBQUFXbTvgTamC5dfrO+M6aeNSVKN/th9TI1xPwXSmKSambH7mBrjfgqkMUk1M2P3MTXG/RRIY6p+Xte+22FMjXE/BdKYqp+73W6v/th5TI1xPwXSmKqfG2O8tlNfY7rw+aXYsuguKSnR3LlzPZeWS1Jpaak6dOjg1S4+Pt6zrraie9asWZo+fXqN5Xl5eWr+wwzgcXFx6tixo3bt2qWysjJPm8TERCUmJurrr79WRUWFZ3lycrJat26toqIinTp1yrM8NTVV0dHRysvL8wpCz549FRISoo0bN3r14brrrtPZs2dVWFjoWRYUFKTrr79elceOqfz0aX21f78cDofCIyLUKzVV3x86pG+++cbTPioqSl26dNH+/fu1d+9ez/JAHFNFRYW2b9/uWR4eHq5evXrp+++/Z0z1MKYWLVqooqJCX331lRw/zAVg9zE1xv0USGNKSkrSqVOnvDJj9zE1xv0USGPq06ePqqqqvDJj9zE1xv0USGPq1KmTJKmgoMDrF1c7j6kx7qdAGlOrVq0kSd9++60OHz7cKMbUGPdTII2p+kRCZWWlduzYUe9jioqKUl04zIVfJzSwZ599VrNnz75km23btik1NdXzet++fbr55ps1ePBgzZ8/37M8MzNTHTp00Lx58zzLtm7dqm7dumnr1q3q0qVLjW3Xdqa7Xbt2Onz4sCIjIyUF1jc10vlvn86dPKmN//d/6tu27fntJiUpKCzMlt8+VY+pMX2jFohjcrlc+vLLL9W3b19Pn+0+psa4nwJpTG63u0Zm7D6mxrifAmlMkmpkxu5jaoz7KZDGZIzRpk2b1KdPH09/7T6mxrifAmlMbrdbX331lfr27esppuw+psa4nwJpTC6XS3l5eUpLS/N8IVyfYzp+/LhiYmJUUVHhqR9r49eiu6yszOtbqtokJyd7Lhnfv3+/Bg8erP79+2vhwoVe/9keeOABVVZWasmSJZ5lq1ev1i233KIjR47Ueqb7xyorKxUVFXXZfzR/M2fOyLVrl4IcDjmio6UfzugDF1N98Kw+eAGXQ2ZgFZmBVWQGVpEZWOXrzNS1fvTr5eVxcXGKi4urU9t9+/bpZz/7mdLS0rRgwQKvgluS0tPT9fzzz+vcuXMKDg6WJK1YsUKdO3euU8FtN2ddLoUHB0s/XGYDXM7Zs2cVHh7u727ARsgMrCIzsIrMwCoyA6sCITO2mL183759Gjx4sNq3b69XX31VZWVlKi0tVWlpqafNfffdp5CQED300EPasmWLPvjgA73xxht66qmn/Nhz33C53SosLZUrMlJqZss/y0cDc7lcKiwsrPVyUKA2ZAZWkRlYRWZgFZmBVYGSGVtUbCtWrFBJSYlKSkqUmJjota766vioqCh9+umnmjhxotLS0hQbG6tp06Y1ynt0e1wwezsAAAAAIPDYougeO3asxo4de9l2PXv21Lp163zfoUAQHCw5bXGhAgAAAAA0WVRtduR0KigszN+9gM1cODMsUBdkBlaRGVhFZmAVmYFVgZAZv85eHmjsMns5AAAAAMC/6lo/cqbbhowxKi8vF9+XoK7IDKwiM7CKzMAqMgOryAysCpTMUHTbkMvl0vbt2/0+Cx/sg8zAKjIDq8gMrCIzsIrMwKpAyQxFNwAAAAAAPkLRDQAAAACAj1B025DD4VB4eLgcDoe/uwKbIDOwiszAKjIDq8gMrCIzsCpQMsPs5Rdg9nIAAAAAQF0we3kj5na7dejQIbndbn93BTZBZmAVmYFVZAZWkRlYRWZgVaBkhqLbhtxut7755hu/hwf2QWZgFZmBVWQGVpEZWEVmYFWgZIaiGwAAAAAAH6HoBgAAAADARyi6bcjhcCgqKsrvs/DBPsgMrCIzsIrMwCoyA6vIDKwKlMwwe/kFmL0cAAAAAFAXzF7eiLndbu3du9fvEwLAPsgMrCIzsIrMwCoyA6vIDKwKlMxQdNtQoIQH9kFmYBWZgVVkBlaRGVhFZmBVoGSGohsAAAAAAB+h6AYAAAAAwEcoum3I6XQqLi5OTie7D3VDZmAVmYFVZAZWkRlYRWZgVaBkhtnLL8Ds5QAAAACAumD28kbM7XZr586dfp8QAPZBZmAVmYFVZAZWkRlYRWZgVaBkhqLbhtxut8rKyvweHtgHmYFVZAZWkRlYRWZgFZmBVYGSGYpuAAAAAAB8pJm/OxBIqv+8vbKy0s89ubSqqiqdOHFClZWVataMXYjLIzOwiszAKjIDq8gMrCIzsMrXmamuGy83TRppvcCxY8ckSe3atfNzTwAAAAAAdnDs2DFFRUVddD2zl1/A7XZr//79uuqqq+RwOPzdnYuqrKxUu3bt9N133zHLOuqEzMAqMgOryAysIjOwiszAKl9nxhijY8eOqW3btpe8LRlnui/gdDqVmJjo727UWWRkJAccWEJmYBWZgVVkBlaRGVhFZmCVLzNzqTPc1ZhIDQAAAAAAH6HoBgAAAADARyi6bSg0NFTZ2dkKDQ31d1dgE2QGVpEZWEVmYBWZgVVkBlYFSmaYSA0AAAAAAB/hTDcAAAAAAD5C0Q0AAAAAgI9QdAMAAAAA4CMU3Tbz5ptv6pprrlFYWJj69eun//3vf/7uEvzkxRdflMPh8HqkpqZ61p8+fVoTJ05Uq1at1KJFC9155506ePCg1zb27Nmjn//854qIiFDr1q01ZcoUVVVVNfRQ4COfffaZRowYobZt28rhcGjJkiVe640xmjZtmtq0aaPw8HBlZGRox44dXm2OHDmi0aNHKzIyUtHR0XrooYd0/PhxrzaFhYUaOHCgwsLC1K5dO73yyiu+Hhp85HKZGTt2bI3jztChQ73akJmmY9asWbr++ut11VVXqXXr1rr99ttVXFzs1aa+PovWrFmjvn37KjQ0VCkpKVq4cKGvhwcfqUtuBg8eXONY88gjj3i1ITdNx9tvv62ePXt67rWdnp6uZcuWedbb4jhjYBuLFi0yISEh5t133zVbtmwx48ePN9HR0ebgwYP+7hr8IDs723Tr1s0cOHDA8ygrK/Osf+SRR0y7du3MypUrzcaNG03//v3NjTfe6FlfVVVlunfvbjIyMkxeXp755JNPTGxsrJk6dao/hgMf+OSTT8zzzz9vPvzwQyPJLF682Gt9Tk6OiYqKMkuWLDEFBQVm5MiRpkOHDubUqVOeNkOHDjW9evUyX3zxhVm3bp1JSUkxo0aN8qyvqKgw8fHxZvTo0aaoqMi8//77Jjw83MybN6+hhol6dLnMjBkzxgwdOtTruHPkyBGvNmSm6cjKyjILFiwwRUVFJj8/3wwfPty0b9/eHD9+3NOmPj6LvvnmGxMREWGeeuops3XrVjN37lwTFBRkli9f3qDjRf2oS25uvvlmM378eK9jTUVFhWc9uWlali5dav7zn/+Yr7/+2hQXF5vnnnvOBAcHm6KiImOMPY4zFN02csMNN5iJEyd6XrtcLtO2bVsza9YsP/YK/pKdnW169epV67ry8nITHBxs/vnPf3qWbdu2zUgyubm5xpjzv1w7nU5TWlrqafP222+byMhIc+bMGZ/2HQ3vxwWU2+02CQkJ5g9/+INnWXl5uQkNDTXvv/++McaYrVu3Gknmyy+/9LRZtmyZcTgcZt++fcYYY9566y0TExPjlZlnnnnGdO7c2ccjgq9drOi+7bbbLvoeMtO0HTp0yEgya9euNcbU32fR008/bbp16+b1s+655x6TlZXl6yGhAfw4N8acL7qfeOKJi76H3CAmJsbMnz/fNscZLi+3ibNnz2rTpk3KyMjwLHM6ncrIyFBubq4fewZ/2rFjh9q2bavk5GSNHj1ae/bskSRt2rRJ586d88pLamqq2rdv78lLbm6uevToofj4eE+brKwsVVZWasuWLQ07EDS4Xbt2qbS01CsjUVFR6tevn1dGoqOjdd1113naZGRkyOl0asOGDZ42gwYNUkhIiKdNVlaWiouLdfTo0QYaDRrSmjVr1Lp1a3Xu3FkTJkzQ4cOHPevITNNWUVEhSWrZsqWk+vssys3N9dpGdRt+/2kcfpybau+9955iY2PVvXt3TZ06VSdPnvSsIzdNl8vl0qJFi3TixAmlp6fb5jjTrF62Ap/7/vvv5XK5vMIiSfHx8dq+fbufegV/6tevnxYuXKjOnTvrwIEDmj59ugYOHKiioiKVlpYqJCRE0dHRXu+Jj49XaWmpJKm0tLTWPFWvQ+NWvY9ry8CFGWndurXX+mbNmqlly5ZebTp06FBjG9XrYmJifNJ/+MfQoUP1i1/8Qh06dNDOnTv13HPPadiwYcrNzVVQUBCZacLcbreefPJJ3XTTTerevbsk1dtn0cXaVFZW6tSpUwoPD/fFkNAAasuNJN13331KSkpS27ZtVVhYqGeeeUbFxcX68MMPJZGbpmjz5s1KT0/X6dOn1aJFCy1evFhdu3ZVfn6+LY4zFN2ATQ0bNszzvGfPnurXr5+SkpL0j3/8gw8SAD5x7733ep736NFDPXv2VMeOHbVmzRoNGTLEjz2Dv02cOFFFRUX6/PPP/d0V2MjFcvPwww97nvfo0UNt2rTRkCFDtHPnTnXs2LGhu4kA0LlzZ+Xn56uiokL/+te/NGbMGK1du9bf3aozLi+3idjYWAUFBdWYie/gwYNKSEjwU68QSKKjo3XttdeqpKRECQkJOnv2rMrLy73aXJiXhISEWvNUvQ6NW/U+vtQxJSEhQYcOHfJaX1VVpSNHjpAjSJKSk5MVGxurkpISSWSmqXrsscf08ccfa/Xq1UpMTPQsr6/Poou1iYyM5EtmG7tYbmrTr18/SfI61pCbpiUkJEQpKSlKS0vTrFmz1KtXL73xxhu2Oc5QdNtESEiI0tLStHLlSs8yt9utlStXKj093Y89Q6A4fvy4du7cqTZt2igtLU3BwcFeeSkuLtaePXs8eUlPT9fmzZu9fkFesWKFIiMj1bVr1wbvPxpWhw4dlJCQ4JWRyspKbdiwwSsj5eXl2rRpk6fNqlWr5Ha7Pb8Apaen67PPPtO5c+c8bVasWKHOnTtzmXATsHfvXh0+fFht2rSRRGaaGmOMHnvsMS1evFirVq2q8WcD9fVZlJ6e7rWN6jb8/mNPl8tNbfLz8yXJ61hDbpo2t9utM2fO2Oc4Uy/TsaFBLFq0yISGhpqFCxearVu3mocffthER0d7zcSHpmPSpElmzZo1ZteuXWb9+vUmIyPDxMbGmkOHDhljzt8+oX379mbVqlVm48aNJj093aSnp3veX337hMzMTJOfn2+WL19u4uLiuGVYI3Ls2DGTl5dn8vLyjCQzZ84ck5eXZ7799ltjzPlbhkVHR5uPPvrIFBYWmttuu63WW4b16dPHbNiwwXz++eemU6dOXrd/Ki8vN/Hx8eb+++83RUVFZtGiRSYiIoLbP9nUpTJz7NgxM3nyZJObm2t27dpl/vvf/5q+ffuaTp06mdOnT3u2QWaajgkTJpioqCizZs0ar1s7nTx50tOmPj6Lqm/lM2XKFLNt2zbz5ptvcusnG7tcbkpKSsyMGTPMxo0bza5du8xHH31kkpOTzaBBgzzbIDdNy7PPPmvWrl1rdu3aZQoLC82zzz5rHA6H+fTTT40x9jjOUHTbzNy5c0379u1NSEiIueGGG8wXX3zh7y7BT+655x7Tpk0bExISYq6++mpzzz33mJKSEs/6U6dOmUcffdTExMSYiIgIc8cdd5gDBw54bWP37t1m2LBhJjw83MTGxppJkyaZc+fONfRQ4COrV682kmo8xowZY4w5f9uwF154wcTHx5vQ0FAzZMgQU1xc7LWNw4cPm1GjRpkWLVqYyMhI8+CDD5pjx455tSkoKDADBgwwoaGh5uqrrzY5OTkNNUTUs0tl5uTJkyYzM9PExcWZ4OBgk5SUZMaPH1/ji18y03TUlhVJZsGCBZ429fVZtHr1atO7d28TEhJikpOTvX4G7OVyudmzZ48ZNGiQadmypQkNDTUpKSlmypQpXvfpNobcNCXjxo0zSUlJJiQkxMTFxZkhQ4Z4Cm5j7HGccRhjTP2cMwcAAAAAABfib7oBAAAAAPARim4AAAAAAHyEohsAAAAAAB+h6AYAAAAAwEcougEAAAAA8BGKbgAAAAAAfISiGwAAAAAAH6HoBgAAAADARyi6AQCwmd27d8vhcCg/P9/fXfHYvn27+vfvr7CwMPXu3btetx2I4wUAoK4ougEAsGjs2LFyOBzKycnxWr5kyRI5HA4/9cq/srOz1bx5cxUXF2vlypU11jscjks+XnzxxYbvNAAADYCiGwCAnyAsLEyzZ8/W0aNH/d2VenP27Nmf/N6dO3dqwIABSkpKUqtWrWqsP3DggOfx+uuvKzIy0mvZ5MmTr6TrAAAELIpuAAB+goyMDCUkJGjWrFkXbfPiiy/WuNT69ddf1zXXXON5PXbsWN1+++2aOXOm4uPjFR0drRkzZqiqqkpTpkxRy5YtlZiYqAULFtTY/vbt23XjjTcqLCxM3bt319q1a73WFxUVadiwYWrRooXi4+N1//336/vvv/esHzx4sB577DE9+eSTio2NVVZWVq3jcLvdmjFjhhITExUaGqrevXtr+fLlnvUOh0ObNm3SjBkzLnrWOiEhwfOIioqSw+HwvG7durXmzJlz0e3/mMvl0rhx45Samqo9e/ZIkj766CP17dtXYWFhSk5O1vTp01VVVeXVx/nz5+uOO+5QRESEOnXqpKVLl3rWHz16VKNHj1ZcXJzCw8PVqVOnWv/NAQCwiqIbAICfICgoSDNnztTcuXO1d+/eK9rWqlWrtH//fn322WeaM2eOsrOzdeuttyomJkYbNmzQI488ol//+tc1fs6UKVM0adIk5eXlKT09XSNGjNDhw4clSeXl5brlllvUp08fbdy4UcuXL9fBgwd19913e23jr3/9q0JCQrR+/Xq98847tfbvjTfe0B//+Ee9+uqrKiwsVFZWlkaOHKkdO3ZIOn8Wu1u3bpo0adJPOmt9ue1f6MyZM/rlL3+p/Px8rVu3Tu3bt9e6dev0wAMP6IknntDWrVs1b948LVy4UC+//LLXe6dPn667775bhYWFGj58uEaPHq0jR45Ikl544QVt3bpVy5Yt07Zt2/T2228rNjbW0jgAAKiVAQAAlowZM8bcdtttxhhj+vfvb8aNG2eMMWbx4sXmwo/W7Oxs06tXL6/3vvbaayYpKclrW0lJScblcnmWde7c2QwcONDzuqqqyjRv3ty8//77xhhjdu3aZSSZnJwcT5tz586ZxMREM3v2bGOMMS+99JLJzMz0+tnfffedkWSKi4uNMcbcfPPNpk+fPpcdb9u2bc3LL7/stez66683jz76qOd1r169THZ29mW3ZYwxCxYsMFFRUXXefvV4161bZ4YMGWIGDBhgysvLPW2HDBliZs6c6fX+v/3tb6ZNmzae15LM7373O8/r48ePG0lm2bJlxhhjRowYYR588ME69R8AACua+bPgBwDA7mbPnq1bbrnliv4muVu3bnI6///FZ/Hx8erevbvndVBQkFq1aqVDhw55vS89Pd3zvFmzZrruuuu0bds2SVJBQYFWr16tFi1a1Ph5O3fu1LXXXitJSktLu2TfKisrtX//ft10001ey2+66SYVFBTUcYT1s/1Ro0YpMTFRq1atUnh4uGd5QUGB1q9f73Vm2+Vy6fTp0zp58qQiIiIkST179vSsb968uSIjIz3/phMmTNCdd96pr776SpmZmbr99tt14403XvH4AADg8nIAAK7AoEGDlJWVpalTp9ZY53Q6ZYzxWnbu3Lka7YKDg71eOxyOWpe53e469+v48eMaMWKE8vPzvR47duzQoEGDPO2aN29e52362/Dhw1VYWKjc3Fyv5cePH9f06dO9xrl582bt2LFDYWFhnnaX+jcdNmyYvv32W/32t7/V/v37NWTIECZ3AwDUC4puAACuUE5Ojv7973/XKAbj4uJUWlrqVXjX572mv/jiC8/zqqoqbdq0SV26dJEk9e3bV1u2bNE111yjlJQUr4eVQjsyMlJt27bV+vXrvZavX79eXbt2veIxWNn+hAkTlJOTo5EjR3pNGte3b18VFxfXGGdKSorXFQSXExcXpzFjxujvf/+7Xn/9df35z3++ssEBACCJy8sBALhCPXr00OjRo/WnP/3Ja/ngwYNVVlamV155RXfddZeWL1+uZcuWKTIysl5+7ptvvqlOnTqpS5cueu2113T06FGNGzdOkjRx4kT95S9/0ahRo/T000+rZcuWKikp0aJFizR//nwFBQXV+edMmTJF2dnZ6tixo3r37q0FCxYoPz9f7733Xr2Mw8r2f/Ob38jlcunWW2/VsmXLNGDAAE2bNk233nqr2rdvr7vuuktOp1MFBQUqKirS73//+zr1Ydq0aUpLS1O3bt105swZffzxx54vMAAAuBIU3QAA1IMZM2bogw8+8FrWpUsXvfXWW5o5c6Zeeukl3XnnnZo8eXK9nUHNyclRTk6O8vPzlZKSoqVLl3pm3K4+e/zMM88oMzNTZ86cUVJSkoYOHWrp7K8kPf7446qoqNCkSZN06NAhde3aVUuXLlWnTp3qZRxWt//kk0/K7XZr+PDhWr58ubKysvTxxx9rxowZmj17toKDg5Wamqpf/epXde5DSEiIpk6dqt27dys8PFwDBw7UokWL6mV8AICmzWF+/MdmAAAAAACgXvA33QAAAAAA+AhFNwAAAAAAPkLRDQAAAACAj1B0AwAAAADgIxTdAAAAAAD4CEU3AAAAAAA+QtENAAAAAICPUHQDAAAAAOAjFN0AAAAAAPgIRTcAAAAAAD5C0Q0AAAAAgI9QdAMAAAAA4CP/D3UDbZGXgq5IAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process all indices from 0 to 99\n",
    "all_texts, all_accs, all_token_counts, all_cumulative_counts = [], [], [], []\n",
    "for i in range(model_funcs[\"metadata\"][\"processed_samples\"]):\n",
    "    prompt_idx = model_funcs[\"samples\"][i][\"index\"]\n",
    "    models_type_json = model_funcs[\"samples\"][i][\"model_evaluation_table\"]\n",
    "    model_type_json = get_model_text(prompt_idx, models_type_json)\n",
    "    texts = [model[\"text\"] for model in model_type_json if \"text\" in model]\n",
    "    accs = [model[\"accuracy\"] for model in model_type_json if \"text\" in model]\n",
    "    token_counts = [count_tokens(text) for text in texts]\n",
    "    cumulative_token_counts = [sum(token_counts[:j+1]) for j in range(len(token_counts))]\n",
    "    \n",
    "    all_texts.extend(texts)\n",
    "    all_accs.extend(accs)\n",
    "    all_token_counts.extend(token_counts)\n",
    "    all_cumulative_counts.extend(cumulative_token_counts)\n",
    "\n",
    "# Print for verification\n",
    "print(f\"Individual token counts: {all_token_counts}\")\n",
    "print(f\"Cumulative token counts: {all_cumulative_counts}\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(all_cumulative_counts, all_accs, marker='o', s=100, alpha=0.7)\n",
    "\n",
    "# Add trend line\n",
    "if len(all_token_counts) > 1:\n",
    "    # Use seaborn for polynomial regression\n",
    "    sns.regplot(x=all_cumulative_counts, y=all_accs, scatter=False,\n",
    "                order=3,  # 2nd degree polynomial\n",
    "                line_kws={\"color\": \"r\", \"linestyle\": \"--\", \"alpha\": 0.7})\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy vs Token Count')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add annotations for each point (simplified to fit one line)\n",
    "# for i, (x, y) in enumerate(zip(all_cumulative_counts, all_accs)): plt.annotate(f\"Model {i}\", (x, y), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'data_source': 'circles',\n",
       " 'prompt': \"[{'content': '\\\\n        The dataset has 2 features and 2 classes: [0, 1]. We first provide you with some examples of how to classify data points.\\\\nFeatures: [3.358, 8.360], Label: 1\\\\nFeatures: [-0.048, 10.016], Label: 0\\\\nFeatures: [-7.937, -4.357], Label: 1\\\\nFeatures: [-7.024, 7.181], Label: 0\\\\nFeatures: [-4.078, -8.878], Label: 0\\\\nFeatures: [-8.701, -2.135], Label: 1\\\\nFeatures: [-5.647, -7.949], Label: 0\\\\nFeatures: [-9.129, -0.411], Label: 1\\\\nFeatures: [5.137, -8.616], Label: 0\\\\nFeatures: [-8.787, 1.588], Label: 1\\\\nFeatures: [7.104, -5.168], Label: 1\\\\nFeatures: [1.929, -9.611], Label: 0\\\\nFeatures: [3.526, -9.428], Label: 0\\\\nFeatures: [4.828, 8.829], Label: 0\\\\nFeatures: [-7.388, 6.772], Label: 0\\\\nFeatures: [-7.129, 5.457], Label: 1\\\\nFeatures: [-3.345, -9.385], Label: 0\\\\nFeatures: [5.514, -7.015], Label: 1\\\\nFeatures: [8.409, 2.986], Label: 1\\\\nFeatures: [-9.732, -1.864], Label: 0\\\\nFeatures: [-8.652, 2.220], Label: 1\\\\nFeatures: [1.541, 9.850], Label: 0\\\\nFeatures: [8.131, 5.733], Label: 0\\\\nFeatures: [-0.835, -8.949], Label: 1\\\\nFeatures: [-9.863, -2.332], Label: 0\\\\nFeatures: [-9.163, -3.652], Label: 0\\\\nFeatures: [1.260, 8.763], Label: 1\\\\nFeatures: [-4.510, -7.755], Label: 1\\\\nFeatures: [0.312, -9.919], Label: 0\\\\nFeatures: [8.015, 4.588], Label: 1\\\\nFeatures: [2.236, -8.584], Label: 1\\\\nFeatures: [1.995, 8.663], Label: 1\\\\nFeatures: [-8.384, 3.167], Label: 1\\\\nFeatures: [3.248, -9.499], Label: 0\\\\nFeatures: [6.077, -7.597], Label: 0\\\\nFeatures: [0.561, -8.882], Label: 1\\\\nFeatures: [-3.008, 9.430], Label: 0\\\\nFeatures: [-9.035, 0.101], Label: 1\\\\nFeatures: [-8.909, 1.595], Label: 1\\\\nFeatures: [9.838, -2.505], Label: 0\\\\nFeatures: [-0.920, -8.949], Label: 1\\\\nFeatures: [-8.163, 5.617], Label: 0\\\\nFeatures: [4.632, 7.653], Label: 1\\\\nFeatures: [7.667, -4.609], Label: 1\\\\nFeatures: [8.115, -3.849], Label: 1\\\\nFeatures: [-2.561, 8.762], Label: 1\\\\nFeatures: [-6.520, -7.357], Label: 0\\\\nFeatures: [-6.241, -7.859], Label: 0\\\\nFeatures: [8.859, 2.090], Label: 1\\\\nFeatures: [-3.877, -8.053], Label: 1\\\\n Given the following data points:\\\\n1. Features: [5.079, -8.708]\\\\n2. Features: [-9.121, -0.111]\\\\n3. Features: [6.552, 6.119]\\\\n4. Features: [-6.681, -7.499]\\\\n5. Features: [0.981, 10.166]\\\\n6. Features: [-4.944, -7.424]\\\\n7. Features: [-8.687, -2.395]\\\\n8. Features: [-5.661, -8.500]\\\\n9. Features: [-8.799, 1.916]\\\\n10. Features: [0.354, 9.079]\\\\nClassify each of them into one of the possible classes.  Your answer should be just the class label, without any other text or punctuation. And return the final answer in <answer> </answer> tags, for example <answer>1, 0, 0, 0, 1, 1, 0, 0, 1, 1</answer>\\\\n        ', 'role': 'user'}]\",\n",
       " 'model_responses': '[\"<think>Okay, so I need to classify these 10 data points based on the given examples. Let me look at the dataset first to see if I can find a pattern or a decision boundary that separates the classes 0 and 1. \\\\n\\\\nLooking at the provided examples, the features are two-dimensional, so maybe plotting them in my mind would help. Let me list out some of the points and their labels:\\\\n\\\\nPositive labels (1):\\\\n- [3.358, 8.360] â†’ 1 (high x1, high x2)\\\\n- [-7.937, -4.357] â†’ 1 (low x1, negative x2)\\\\n- [7.104, -5.168] â†’ 1 (high x1, negative x2)\\\\n- [1.260, 8.763] â†’ 1 (moderate x1, high x2)\\\\n- [8.409, 2.986] â†’ 1 (high x1, moderate x2)\\\\n- [8.015, 4.588] â†’ 1 (high x1, moderate x2)\\\\n- [-8.384, 3.167] â†’ 1 (low x1, moderate x2)\\\\n- [4.632, 7.653] â†’ 1 (moderate x1, high x2)\\\\n- [7.667, -4.609] â†’1 (high x1, low x2)\\\\n- [-2.561, 8.762] â†’1 (mod x1, high x2)\\\\n- [-3.877, -8.053] â†’1 (low x1, very low x2)\\\\n\\\\nNegative labels (0):\\\\n- [-0.048, 10.016] â†’0 (low x1, very high x2)\\\\n- [-7.024, 7.181] â†’0 (low x1, high x2)\\\\n- [-4.078, -8.878] â†’0 (low x1, very low x2)\\\\n- [5.137, -8.616] â†’0 (high x1, very low x2)\\\\n- [1.929, -9.611] â†’0 (mod x1, very low x2)\\\\n- [-7.129,5.457] â†’1? Wait no, that\\'s labeled 1. Wait, the example says: Features: [-7.129, 5.457], Label: 1. Oh right, so some points with x1 negative and x2 positive can be 1. But others like [-7.024,7.181] are 0. Hmm. So maybe there\\'s a more complex boundary.\\\\n\\\\nWait, perhaps it\\'s a non-linear decision boundary. Let me try to see if there\\'s a pattern based on quadrants or regions. Let\\'s see:\\\\n\\\\nLooking at the positive labels:\\\\n\\\\n- Some are in the first quadrant (positive x1, positive x2) but not all. For example, [3.358,8.360] is 1, but [4.828,8.829] is 0. That\\'s confusing. Wait, [4.828,8.829] is 0, while [3.358,8.360] is 1. So same quadrant but different labels. So maybe the boundary isn\\'t based on quadrants.\\\\n\\\\nAlternatively, maybe it\\'s a diagonal line or a circle? Let\\'s think about other features.\\\\n\\\\nLooking at points with x2 high (like 8+). Some are 1, some are 0. For example, [3.358,8.36] is 1, but [-0.048,10.016] is 0. Similarly, [1.260,8.763] is 1, but [1.995,8.663] is 1. Wait, that\\'s labeled as 1. Wait, no, the example given: [1.995, 8.663] is 1. Then what\\'s different between those 0s and 1s in high x2? Let\\'s check their x1 values. The 0s in high x2 have x1 around negative or lower. For example, [-0.048,10.016] (x1 is -0.048), but [1.541,9.850] is 0. Wait, no, that\\'s labeled 0. Wait, Features: [1.541,9.850], Label:0. Hmm. So that\\'s x1=1.5, x2=9.85. So maybe even positive x1 but high x2 can be 0. So that complicates things.\\\\n\\\\nAlternatively, perhaps the sum or difference of the features. Let\\'s calculate some of them:\\\\n\\\\nFor example, [3.358,8.360] â†’ sum is ~11.7, difference (x2 - x1) is ~5. Label 1.\\\\n\\\\n[-0.048,10.016] â†’ sum ~10, difference ~10.06. Label 0.\\\\n\\\\n[-7.937, -4.357] â†’ sum ~-12.3, difference 3.58. Label 1.\\\\n\\\\n[5.137, -8.616] â†’ sum ~-3.5, difference -13.75. Label 0.\\\\n\\\\nHmm. Not sure. Maybe some other function. Let\\'s think about the product or other relations.\\\\n\\\\nAlternatively, perhaps a circle. Let\\'s check distances from the origin. For example:\\\\n\\\\n[3.358,8.36]: distance sqrt(3.358Â² +8.36Â²) â‰ˆ sqrt(11.27 +69.9) â‰ˆ sqrt(81.17)â‰ˆ9.01. Label 1.\\\\n\\\\n[-0.048,10.016]: distance ~sqrt(0.0023 +100.32)â‰ˆ10.01. Label 0.\\\\n\\\\n[1.260,8.763]: sqrt(1.5876+76.8)â‰ˆsqrt(78.4)â‰ˆ8.85. Label 1.\\\\n\\\\n[1.541,9.85]: sqrt(2.37+97.0)â‰ˆsqrt(99.37)â‰ˆ9.97. Label 0.\\\\n\\\\nSo maybe points within a certain radius from the origin are 1, and outside are 0? But 10.01 is 0, and 9.01 is 1, but 9.97 is 0 and 8.85 is 1. So perhaps the threshold is around 9.5? Let\\'s check another point. [4.632,7.653] is 1. Its distance is sqrt(21.46+58.57)=sqrt(80)â‰ˆ8.94. So that\\'s inside 9.5, label 1. Then [8.409,2.986], distance sqrt(70.7+8.92)=sqrt(79.6)=8.92, so label 1. [-7.937,-4.357], distance sqrt(63+19)=sqrt(82)=9.06, which is over 9, but label is 1. So that contradicts. Maybe not a circle.\\\\n\\\\nAlternatively, maybe a combination of x1 and x2. Let\\'s look for other patterns.\\\\n\\\\nLooking at some 0 labels:\\\\n\\\\n[-4.078, -8.878] â†’ both negative. Label 0.\\\\n\\\\n[5.137, -8.616] â†’ x1 positive, x2 negative. Label 0.\\\\n\\\\n[-7.024,7.181] â†’ x1 negative, x2 positive. Label 0.\\\\n\\\\n[1.929,-9.611] â†’ x1 positive, x2 negative. Label 0.\\\\n\\\\n[3.526,-9.428] â†’ same. Label 0.\\\\n\\\\n[8.131,5.733] â†’ both positive. Label 0.\\\\n\\\\n[-9.732,-1.864] â†’ x1 very negative, x2 negative. Label 0.\\\\n\\\\n[ -3.345,-9.385] â†’ x1 negative, x2 very negative. Label 0.\\\\n\\\\n[ -6.520,-7.357] â†’ label 0.\\\\n\\\\nBut then some other points with similar positions are labeled 1. For example:\\\\n\\\\n[-7.937, -4.357] â†’ label 1. But [-4.078, -8.878] is 0. So even in the same quadrant, labels differ. \\\\n\\\\nWait, maybe there\\'s a diagonal line. For example, perhaps points where x1 + x2 is above a certain value are 0 or 1. Let\\'s test:\\\\n\\\\nFor [3.358,8.360], x1 +x2 â‰ˆ11.7 â†’ label 1.\\\\n\\\\n[-0.048,10.016], sum â‰ˆ10 â†’ label 0.\\\\n\\\\n[-7.937, -4.357] sumâ‰ˆ-12.3 â†’ label 1.\\\\n\\\\n[5.137, -8.616] sumâ‰ˆ-3.48 â†’ label 0.\\\\n\\\\nHmm. Not sure. What about x1 - x2:\\\\n\\\\n[3.358 -8.360 = -5 â†’ label 1.\\\\n\\\\n[-0.048 -10.016 â‰ˆ-10 â†’ label 0.\\\\n\\\\n[-7.937 - (-4.357) = -3.58 â†’ label1.\\\\n\\\\nNot obvious. Maybe another approach. Let\\'s look for regions where certain conditions hold. For example, maybe if x1 is positive and x2 is negative, then label 0. But wait, [5.137,-8.616] is 0, [7.104,-5.168] is 1. So that can\\'t be the case. Similarly, [7.667,-4.609] is 1. So same quadrant (x1 positive, x2 negative) but different labels. So that\\'s not a rule.\\\\n\\\\nAnother idea: perhaps if x2 is greater than a certain function of x1. Let\\'s see.\\\\n\\\\nLooking at points where x2 is high. Let\\'s see if there\\'s a line that separates them. For example, in positive x2 region:\\\\n\\\\n[3.358,8.36] (label1) vs [4.828,8.829] (label0). So higher x1 but same x2 gives a different label. What\\'s the difference here? Maybe x1 in a certain range.\\\\n\\\\nWait, 3.358 is less than 4.828. So maybe when x1 is below a certain value and x2 is high, it\\'s 1, but if x1 is above, 0? Not sure. For example, [1.260,8.763] is 1, [1.541,9.85] is 0. Hmm, but 1.541 is higher x1. Maybe not.\\\\n\\\\nAlternatively, check if x1 is positive or negative. For example, for high x2 (like over 8), if x1 is negative, maybe label 0. But [-7.024,7.181] is x2=7.18, which is not as high. Wait, but [-3.008,9.430] is label0. So x1 is negative, x2 high (9.43). So label0. Then the [1.260,8.763], which is x1 positive, x2 high (8.76), label1. So maybe for x2 high (above say 8), x1 positive is 1, x1 negative is 0? Let\\'s check:\\\\n\\\\n[-3.008,9.43] â†’ x1 negative â†’ label0. [1.260,8.763] â†’ x1 positive â†’ label1. [3.358,8.36] â†’ positive x1 â†’ label1. [4.828,8.829] â†’ positive x1 â†’ label0. Wait, that breaks the pattern. So there\\'s an exception here. So maybe that\\'s not the case.\\\\n\\\\nAnother approach: perhaps use a decision tree-like approach. Let\\'s look for splits. For example, maybe split on x2. Let\\'s see if x2 > some value.\\\\n\\\\nLooking at points with x2 >8:\\\\n\\\\n[3.358,8.36] â†’1\\\\n\\\\n[-0.048,10.016] â†’0\\\\n\\\\n[-3.008,9.43] â†’0\\\\n\\\\n[1.260,8.763] â†’1\\\\n\\\\n[1.995,8.663] â†’1\\\\n\\\\n[4.828,8.829] â†’0\\\\n\\\\n[1.541,9.85] â†’0\\\\n\\\\nSo for x2 >8, labels are 1 and 0. How to distinguish? Maybe x1 > something. For x2>8, when x1 is positive, sometimes 1, sometimes 0. For example, [3.358,8.36] â†’x1=3.358â†’1, [4.828,8.829]â†’x1=4.828â†’0. Hmm. So maybe there\\'s a threshold around x1=4 in x2>8 area. Let\\'s see: if x1>4, then 0? But [8.409,2.986] which is x2=2.986, x1=8.4 â†’ label1. So maybe not. This seems complicated.\\\\n\\\\nLooking at points where x1 is positive and x2 is negative:\\\\n\\\\n[5.137,-8.616] â†’0\\\\n\\\\n[7.104,-5.168] â†’1\\\\n\\\\n[3.526,-9.428] â†’0\\\\n\\\\n[1.929,-9.611] â†’0\\\\n\\\\n[0.561,-8.882] â†’1\\\\n\\\\n[2.236,-8.584] â†’1\\\\n\\\\n[6.077,-7.597] â†’0\\\\n\\\\n[7.667,-4.609] â†’1\\\\n\\\\n[8.115,-3.849] â†’1\\\\n\\\\nHmm, so when x1 is positive and x2 negative, it\\'s a mix of 0 and 1. So perhaps x1 and x2 follow a certain relationship here. Maybe if x1 + x2 > something? Let\\'s calculate for these points:\\\\n\\\\n5.137 + (-8.616) = -3.48 â†’0\\\\n\\\\n7.104 + (-5.168)=1.936 â†’1\\\\n\\\\n3.526 + (-9.428)= -5.9 â†’0\\\\n\\\\n1.929 + (-9.611)= -7.68 â†’0\\\\n\\\\n0.561 + (-8.882)= -8.32 â†’1 (wait, 0.561, -8.882 is labeled 1?)\\\\n\\\\nYes, the example says: Features: [0.561, -8.882], Label:1. So that sum is -8.32, which is lower than the other 0 cases. So sum isn\\'t the key.\\\\n\\\\nAlternatively, x1 vs |x2|. For example, in positive x1, negative x2:\\\\n\\\\nx1=5.137, |x2|=8.616. x1 < |x2| â†’0.\\\\n\\\\nx1=7.104, |x2|=5.168. x1 > |x2| â†’1.\\\\n\\\\nx1=3.526, |x2|=9.428 â†’x1 < |x2| â†’0.\\\\n\\\\nx1=1.929 < 9.611 â†’0.\\\\n\\\\nx1=0.561 <8.882 â†’1. Hmm, that breaks the pattern. Because 0.561 <8.882 but label is 1.\\\\n\\\\nSo maybe that\\'s not the rule.\\\\n\\\\nAlternatively, maybe when x1 > |x2| - some value. For example, 7.104 >5.168 â†’ yes, label 1. 5.137 <8.616 â†’0.\\\\n\\\\nBut 0.561 <8.882 â†’ label1. So that contradicts.\\\\n\\\\nHmm. Maybe another angle. Let\\'s look for points that are near the edges. Let\\'s think about the given test points. For example, the first test point is [5.079, -8.708]. Looking at similar points in the training data:\\\\n\\\\n[5.137, -8.616] is label 0. So very close. So maybe this is 0. But wait, [5.137 is -8.616] â†’0. The test point is [5.079, -8.708], which is almost the same. So maybe label 0. But wait, there\\'s also [2.236, -8.584] which is label1. So why is 5.137 labeled 0 and 2.236 labeled1? Let me check the x1 and x2.\\\\n\\\\nWait, maybe for positive x1 and negative x2, if x1 is greater than a certain value and x2 is less than a certain value, it\\'s 1. For example, 7.104 is x1=7.1, x2=-5.1. Label1. 8.115, -3.849 â†’ label1. So higher x1 and less negative x2.\\\\n\\\\nBut then [5.137,-8.6] is x1=5.1, x2=-8.6 â†’0, while [7.104,-5.1] â†’1.\\\\n\\\\nSo maybe when x1 is high enough compared to |x2|, it\\'s 1. For example, if x1 > |x2|/something. Let\\'s compute for these points:\\\\n\\\\n7.104 /5.168â‰ˆ1.37. 5.137/8.616â‰ˆ0.6. 2.236/8.584â‰ˆ0.26. 0.561/8.882â‰ˆ0.063. 7.667/4.609â‰ˆ1.66. 8.115/3.849â‰ˆ2.1. Hmm, in the cases where the ratio (x1/|x2|) is higher, the label is 1. For example, 7.1/5.1â‰ˆ1.37 â†’1. 8.115/3.849â‰ˆ2.1 â†’1. 5.1/8.6â‰ˆ0.6 â†’0. 2.236/8.584â‰ˆ0.26 â†’1. But that\\'s inconsistent. For 2.236/8.584 is 0.26, which is lower than 0.6, but the label is 1.\\\\n\\\\nSo that doesn\\'t hold. Maybe another pattern.\\\\n\\\\nLooking at the points with x1 positive and x2 negative:\\\\n\\\\nLabel1 when x1 is high (like 7.1, 7.6, 8.1, 8.4) but sometimes lower x1 (like 2.236) is label1. Hmm. Maybe it\\'s based on x1 being above a certain threshold, but the threshold varies.\\\\n\\\\nAlternatively, maybe the product of x1 and x2. Let\\'s compute:\\\\n\\\\nFor [5.079, -8.708] â†’5.079 * (-8.708) â‰ˆ-44.3. The similar point [5.137,-8.616] product is ~-44.3, which is 0. So maybe negative product. But many points have negative products. Not helpful.\\\\n\\\\nAlternative approach: let\\'s try to see if there\\'s a linear decision boundary. Maybe using a support vector machine or logistic regression approach. But since this is a thought process, let\\'s try to find a line that separates most of the points.\\\\n\\\\nLooking at the positive labels (1):\\\\n\\\\nThey seem to be in areas where either:\\\\n\\\\n- High positive x1 with moderate to low x2 (positive or negative).\\\\n\\\\n- High negative x1 with x2 not too high.\\\\n\\\\nWait, but some points like [-7.937,-4.357] (x1=-7.9, x2=-4.3) are 1. While [-4.078,-8.878] (x1=-4.07, x2=-8.87) is 0. So what\\'s the difference? The x1 is more negative in the first case, but x2 is less negative. Maybe the sum? For [-7.937, -4.357], sum is -12.29. For [-4.078, -8.878], sum is -12.956. The first is slightly higher sum, but label is 1. Not sure.\\\\n\\\\nAlternatively, maybe if x1 is more negative than x2. For [-7.937, -4.357], x1=-7.9, x2=-4.3 â†’x1 is more negative (since -7.9 < -4.3). So |x1| > |x2|. For [-4.078, -8.878], |x1| is 4.07, |x2|=8.87 â†’ |x1| < |x2|. So label 0. So maybe in the negative x1 and x2 region, if |x1| > |x2|, label 1, else 0. Let\\'s check:\\\\n\\\\n[-7.937,-4.357] â†’|x1|>|x2| â†’1.\\\\n\\\\n[-4.078,-8.878] â†’|x1|<|x2| â†’0.\\\\n\\\\n[-9.732,-1.864] â†’|x1|>|x2| â†’ label0. Wait, this is conflicting. This point is x1=-9.732, x2=-1.864. |x1|>|x2| â†’9.73>1.864. But label is 0. So that breaks the pattern.\\\\n\\\\nBut in the examples, there\\'s [-9.129,-0.411] â†’ label1. Here, x1 is very negative, x2 slightly negative. |x1|>|x2| â†’ yes. Label1. So why is [-9.732,-1.864] label0? That also has |x1|>|x2|. Hmm. So that contradicts the previous idea.\\\\n\\\\nSo maybe there\\'s another factor. Let\\'s look at these two points:\\\\n\\\\n[-9.129, -0.411] â†’ label1.\\\\n\\\\n[-9.732,-1.864] â†’ label0.\\\\n\\\\nWhat\\'s different? The x2 values are -0.411 vs -1.864. Also, x1 is -9.129 vs -9.732. Maybe x1 is past a certain threshold. For example, if x1 < -9, then label0. But [-9.129 is -9.129, which is less than -9, and it\\'s label1. So that\\'s not it.\\\\n\\\\nAlternatively, the sum of x1 and x2. For [-9.129, -0.411], sum is -9.54. For [-9.732,-1.864], sum is -11.596. Maybe sum is less than -10 â†’ label0. The first sum is -9.54 (above -10), label1. Second is -11.596 (below -10), label0. Let\\'s check other points.\\\\n\\\\n[-8.701,-2.135] sum is -10.836 â†’ label1. But according to the sum threshold, this would be below -10, so label0. But the actual label is1. So that\\'s a problem. Hmm.\\\\n\\\\nThis is getting complicated. Maybe I should look for another pattern. Let\\'s consider the following:\\\\n\\\\nPositive labels (1) appear in regions where:\\\\n\\\\n- x1 is positive and x2 is negative with x1 high enough (like 7.104, 7.667, 8.115, etc.)\\\\n\\\\n- x1 is negative and x2 is positive but not too high (maybe?)\\\\n\\\\nWait, [-7.129,5.457] is label1, while [-7.024,7.181] is label0. So for negative x1 and positive x2, perhaps if x2 is below a certain value, it\\'s 1. For example, x2 <6. Then [-7.129,5.457] is 5.457 <6 â†’1. [-7.024,7.181] is 7.18>6 â†’0. Let\\'s check other points.\\\\n\\\\n[-8.384,3.167] â†’3.167 <6 â†’1. Label1.\\\\n\\\\n[-8.652,2.220] â†’2.22 <6 â†’1. Label1.\\\\n\\\\n[-8.787,1.588] â†’1.588 <6 â†’1. Label1.\\\\n\\\\nYes, those are all label1. Then [-7.024,7.181] is x2=7.18 â†’ label0. So maybe in the negative x1 and positive x2 region, if x2 <6 â†’1, else 0.\\\\n\\\\nSimilarly, in the positive x1 and positive x2 region, maybe there\\'s a different rule. For example, [3.358,8.36] is label1, but [4.828,8.829] is 0. So what\\'s the difference? Maybe x1 <4.8 â†’1, else 0? But [8.409,2.986] is x1=8.4, x2=2.986 â†’ label1. So maybe in this region, different rules. \\\\n\\\\nAlternatively, in positive x1 and positive x2, if x1 <5 and x2>8 â†’1, else 0. Let\\'s see:\\\\n\\\\n[3.358,8.36] â†’ x1<5, x2>8 â†’1.\\\\n\\\\n[4.828,8.829] â†’x1<5? No, 4.828 is less than 5. x2>8. So why label0? Hmm. That breaks the pattern.\\\\n\\\\nWait, [4.632,7.653] is x1=4.6, x2=7.65 â†’ both positive. Label1. So maybe x2>7.65 â†’1? But 4.828,8.829 has x2=8.82>7.65, but label0. So that\\'s not it.\\\\n\\\\nThis is getting too time-consuming. Maybe there\\'s a better approach. Let me try to see if the labels are determined by the sign of (x1 + x2) or something similar. Let\\'s test:\\\\n\\\\nFor [3.358,8.36] â†’ x1+x2=11.718 â†’ positive. Label1.\\\\n\\\\n[-0.048,10.016] â†’ sumâ‰ˆ10 â†’ positive. Label0.\\\\n\\\\n[-7.937,-4.357] â†’ sumâ‰ˆ-12.3 â†’ negative. Label1.\\\\n\\\\n[5.137,-8.616] â†’ sumâ‰ˆ-3.48 â†’ negative. Label0.\\\\n\\\\nHmm, inconsistent. So maybe not sum.\\\\n\\\\nAnother idea: maybe the labels are based on whether the point is inside or outside of certain polygons or regions. For example, a region in the upper left (negative x1, positive x2) where x2 <6 â†’ label1, and others in that area are 0. In the lower right (positive x1, negative x2) where x1 > some value â†’1, else 0. In the lower left (negative x1, negative x2) where |x1|>|x2| â†’1, else 0. And upper right (positive x1, positive x2) where x1 < some value and x2 > some other value â†’1, else 0.\\\\n\\\\nLet\\'s try this:\\\\n\\\\n1. Upper left quadrant (x1 <0, x2>0):\\\\n\\\\n- If x2 <6 â†’ label1.\\\\n\\\\n- Else â†’0.\\\\n\\\\nExamples:\\\\n\\\\n[-7.129,5.457] â†’5.457<6 â†’1. Correct.\\\\n\\\\n[-7.024,7.181] â†’7.18>6 â†’0. Correct.\\\\n\\\\n[-8.384,3.167] â†’3.167<6 â†’1. Correct.\\\\n\\\\n[-3.008,9.43] â†’x2=9.43>6 â†’0. Correct.\\\\n\\\\n[-8.652,2.22] â†’2.22<6 â†’1. Correct.\\\\n\\\\nYes, this seems to fit.\\\\n\\\\n2. Lower right quadrant (x1>0, x2<0):\\\\n\\\\n- If x1 >6 â†’ label1.\\\\n\\\\n- Else â†’ check if x2 >-5 â†’ maybe, but examples are mixed.\\\\n\\\\nWait, let\\'s check examples:\\\\n\\\\n[7.104,-5.168] â†’x1=7.1>6 â†’ label1.\\\\n\\\\n[5.137,-8.616] â†’x1=5.1<6 â†’ label0.\\\\n\\\\n[1.929,-9.611] â†’x1=1.9<6 â†’0.\\\\n\\\\n[0.561,-8.882] â†’x1=0.56<6 â†’1. Hmm, but this breaks the rule. So this point is x1=0.56<6, x2=-8.88, label1. So the rule would fail here.\\\\n\\\\nAlternatively, maybe for x1>0 and x2<0, if x1 + x2 > some value.\\\\n\\\\nFor example:\\\\n\\\\n7.104 + (-5.168) =1.936 â†’1.936>? Let\\'s say >0 â†’1.\\\\n\\\\n5.137 + (-8.616) =-3.48 â†’-3.48 <0 â†’0.\\\\n\\\\n0.561 + (-8.882) =-8.32 â†’<0 â†’ but label is1. So that\\'s not working.\\\\n\\\\nAnother approach: for x1>0 and x2<0, label1 if x1 > |x2|. Let\\'s check:\\\\n\\\\n7.104 >5.168 â†’ yes â†’1.\\\\n\\\\n5.137 <8.616 â†’ no â†’0.\\\\n\\\\n0.561 <8.882 â†’ no â†’ but label1. So no.\\\\n\\\\nHmm. What about x1 > something like 5 and x2 >-6? Let\\'s see:\\\\n\\\\n[7.104, -5.168] â†’x2=-5.168. Is x2 >-6? Yes. So x1>5 and x2> -6 â†’ label1.\\\\n\\\\n[5.137, -8.616] â†’x1=5.137>5, x2=-8.616 < -6 â†’ label0.\\\\n\\\\n[0.561,-8.882] â†’x1<5 â†’ label1 (doesn\\'t fit).\\\\n\\\\n[2.236,-8.584] â†’x1=2.236<5 â†’ label1. Doesn\\'t fit.\\\\n\\\\nThis is tricky. Maybe in this quadrant, there\\'s another rule. Alternatively, perhaps if x1 is greater than a certain value (like 6) and x2 is greater than a certain value (like -6), it\\'s label1. Otherwise, label0. Let\\'s check:\\\\n\\\\n7.104 >6, x2=-5.168 >-6 â†’1. Correct.\\\\n\\\\n5.137 <6 â†’0. Correct.\\\\n\\\\n7.667>6, x2=-4.609 >-6 â†’1. Correct.\\\\n\\\\n8.115>6, x2=-3.849>-6 â†’1. Correct.\\\\n\\\\n6.077>6? 6.077 is just over 6. x2=-7.597 < -6 â†’0. Which matches the example: Features: [6.077, -7.597], Label:0.\\\\n\\\\nBut then there\\'s [0.561,-8.882], x1=0.561<6, so label0 according to this rule, but actual label is1. So this rule would miss that point. So maybe there\\'s another pattern for points with x1<6 but x2< -something.\\\\n\\\\nAlternatively, the points in lower right (x1>0, x2<0) are label1 if x1 is greater than a certain value, regardless of x2. Let\\'s see:\\\\n\\\\nPoints with x1>6: [7.104,7.667,8.115,8.409,8.859, etc.] all label1.\\\\n\\\\nPoints with x1 between 5 and 6: [5.137,5.514,5.079 (test point), etc.] â†’label0.\\\\n\\\\nBut [5.514,-7.015] â†’ x1=5.514<6 â†’ but label1. Wait, the example says Features: [5.514, -7.015], Label:1. So this is a problem for the rule. Because x1=5.514 is less than 6, but label is1.\\\\n\\\\nHmm. So the rule that x1>6 â†’1, else0 doesn\\'t hold here. So maybe there\\'s a different threshold. Let\\'s see:\\\\n\\\\nLooking at x1 values for positive labels in this quadrant:\\\\n\\\\n7.104,7.667,8.115,8.409,8.859, etc. â†’ all >7.\\\\n\\\\nBut [5.514,-7.015] is x1=5.514 â†’ label1. So this is an exception. So the rule isn\\'t straightforward.\\\\n\\\\nMaybe it\\'s a diagonal line. For example, x2 = -x1 + c. Let\\'s see for [5.514,-7.015]: x2 = -7.015, x1=5.514. So -x1 + c = -5.514 +c = -7.015 â†’ c =-7.015 +5.514 â‰ˆ-1.5. So maybe x2 < -x1 -1.5 â†’ label1.\\\\n\\\\nLet\\'s test this:\\\\n\\\\nFor [5.514,-7.015]: x2=-7.015 < -5.514 -1.5= -7.014 â†’ yes, so label1.\\\\n\\\\nFor [7.104,-5.168]: x2=-5.168 < -7.104 -1.5= -8.604 â†’ no â†’ so label0. But actual label is1. So this doesn\\'t work.\\\\n\\\\nAnother idea: maybe in the lower right quadrant, label1 if x1 +x2 >0. Let\\'s check:\\\\n\\\\n[7.104, -5.168] â†’7.104-5.168=1.936>0 â†’1. Correct.\\\\n\\\\n[5.514, -7.015] â†’5.514-7.015=-1.5<0 â†’ label1. Doesn\\'t fit.\\\\n\\\\n[5.137,-8.616] â†’-3.48<0 â†’0. Correct.\\\\n\\\\n[0.561,-8.882] â†’-8.32<0 â†’ label1. Doesn\\'t fit.\\\\n\\\\nSo no.\\\\n\\\\nThis is getting too time-consuming. Perhaps the best approach is to use a k-nearest neighbors classifier with k=3 or k=5, looking at the nearest neighbors in the training data for each test point. Since there are 42 training examples, this might be manageable.\\\\n\\\\nLet\\'s try this for each test point:\\\\n\\\\n1. [5.079, -8.708]\\\\n\\\\nLooking for the nearest neighbors in the training data. Let\\'s check points with similar x1 and x2.\\\\n\\\\nTraining points with x1 around 5 and x2 around -8:\\\\n\\\\n[5.137, -8.616] â†’ label0. The distance between test point and this is sqrt((5.079-5.137)^2 + (-8.708+8.616)^2) â‰ˆ sqrt( (-0.058)^2 + (-0.092)^2 ) â‰ˆ sqrt(0.003364 +0.008464)â‰ˆsqrt(0.0118)â‰ˆ0.108. Very close. Label0.\\\\n\\\\nAnother close point: [5.514,-7.015] â†’ label1. Distance sqrt((5.079-5.514)^2 + (-8.708+7.015)^2)â‰ˆ sqrt( (-0.435)^2 + (-1.693)^2 )â‰ˆ sqrt(0.19+2.866)â‰ˆsqrt(3.056)â‰ˆ1.748. Further away.\\\\n\\\\nThe closest point is [5.137,-8.616] which is label0. So test point 1 is likely 0.\\\\n\\\\n2. [-9.121, -0.111]\\\\n\\\\nTraining points near this:\\\\n\\\\n[-9.129, -0.411] â†’ label1. Distance sqrt( (-9.121+9.129)^2 + (-0.111+0.411)^2 ) â‰ˆ sqrt(0.008^2 +0.3^2)â‰ˆsqrt(0.000064+0.09)â‰ˆ0.3. Very close. Another point: [-9.035,0.101] â†’ label1. Distance sqrt(0.086^2 +0.212^2)â‰ˆsqrt(0.0074+0.045)â‰ˆ0.23. Closer? Let\\'s compute:\\\\n\\\\nTest point: [-9.121, -0.111]\\\\n\\\\nDistance to [-9.035,0.101]:\\\\n\\\\nÎ”x=0.086, Î”y=0.212. Distanceâ‰ˆsqrt(0.0074 +0.045)â‰ˆ0.23.\\\\n\\\\nDistance to [-9.129,-0.411]:\\\\n\\\\nÎ”x=0.008, Î”y=0.3 â†’ distanceâ‰ˆ0.3.\\\\n\\\\nSo the closest is [-9.035,0.101] (distance 0.23) â†’ label1. Next closest is [-9.129,-0.411] (distance 0.3) â†’ label1. So with k=3, let\\'s see:\\\\n\\\\nOther neighbors might include [-8.787,1.588] â†’ label1, but further away. So majority is 1. So test point 2 â†’1.\\\\n\\\\n3. [6.552,6.119]\\\\n\\\\nLooking for training points near x1=6.5, x2=6.1. Training data has:\\\\n\\\\n[8.409,2.986], [4.632,7.653], [3.248,-9.499], etc. Let\\'s find points with similar x1 and x2.\\\\n\\\\nLooking at positive x1 and positive x2:\\\\n\\\\n[4.632,7.653] â†’ label1. Distance sqrt((6.552-4.632)^2 + (6.119-7.653)^2) â‰ˆ sqrt(3.92^2 + (-1.534)^2)â‰ˆ sqrt(15.36 +2.35)â‰ˆ17.71 â†’ distanceâ‰ˆ4.2.\\\\n\\\\n[3.358,8.36] â†’ label1. Distance sqrt( (6.552-3.358)^2 + (6.119-8.36)^2 )â‰ˆ sqrt(10.2^2 + (-2.24)^2 )â‰ˆ sqrt(104.04+5.02)â‰ˆ10.4.\\\\n\\\\n[8.015,4.588] â†’ label1. Distance sqrt( (6.552-8.015)^2 + (6.119-4.588)^2 )â‰ˆ sqrt( (-1.463)^2 +1.531^2 )â‰ˆ sqrt(2.14 +2.34)â‰ˆsqrt(4.48)=2.12.\\\\n\\\\n[8.131,5.733] â†’ label0. Distance sqrt( (6.552-8.131)^2 + (6.119-5.733)^2 )â‰ˆ sqrt( (-1.579)^2 +0.386^2 )â‰ˆ sqrt(2.49 +0.15)=sqrt(2.64)=1.625.\\\\n\\\\nSo the closest is [8.131,5.733] â†’ label0 (distance 1.625). Next closest is [8.015,4.588] â†’ label1 (distance 2.12). Then maybe [4.632,7.653] â†’4.2. So with k=3: labels are 0,1,1. Majority is 1. But the closest is 0. If k=1, it\\'s 0. But let\\'s see other points.\\\\n\\\\nAnother nearby point: [7.104,-5.168] is in different quadrant. Not relevant.\\\\n\\\\n[8.859,2.090] â†’ label1. Distance sqrt( (6.552-8.859)^2 + (6.119-2.09)^2 )â‰ˆ sqrt(5.27^2 +4.029^2)=sqrt(27.7+16.23)=sqrt(43.93)=6.62. Not close.\\\\n\\\\nThe closest is [8.131,5.733] â†’0. Then [8.015,4.588] â†’1. Next could be [8.409,2.986] â†’1. So if k=3, two 1\\'s and one 0 â†’ majority 1. So test point 3 â†’1.\\\\n\\\\nBut wait, [8.131,5.733] is label0. So if this is the nearest, but others are 1. However, maybe there\\'s a point with x1=6.5, x2=6.1, which is not present. Alternatively, maybe the model here is that in positive x1 and x2, label is 0 if x1 is high enough. For example, [8.131,5.733] is label0. So maybe for x1>8 and x2>5 â†’0. But [8.409,2.986] is x1>8, x2<3 â†’1. So no.\\\\n\\\\nAlternatively, this test point [6.552,6.119] is in a region where there are few training examples. The closest is [8.131,5.733] (label0) but others are label1. It\\'s possible that the majority is 1. So test point 3 is 1.\\\\n\\\\n4. [-6.681, -7.499]\\\\n\\\\nTraining points near this:\\\\n\\\\nLooking for x1 around -6.6, x2 around -7.5.\\\\n\\\\nTraining examples:\\\\n\\\\n[-6.520, -7.357] â†’ label0. Distance sqrt( (-6.681+6.52)^2 + (-7.499+7.357)^2 )â‰ˆ sqrt( (-0.161)^2 + (-0.142)^2 )â‰ˆ sqrt(0.0259 +0.0202)=sqrt(0.0461)=0.215.\\\\n\\\\n[-6.241,-7.859] â†’ label0. Distance sqrt( (-6.681+6.241)^2 + (-7.499+7.859)^2 )â‰ˆ sqrt( (-0.44)^2 +0.36^2 )â‰ˆ sqrt(0.1936 +0.1296)=sqrt(0.323)=0.568.\\\\n\\\\n[-5.647,-7.949] â†’ label0. Distance sqrt( (-6.681+5.647)^2 + (-7.499+7.949)^2 )â‰ˆ sqrt( (-1.034)^2 +0.45^2 )â‰ˆ sqrt(1.07 +0.2025)=sqrt(1.2725)=1.128.\\\\n\\\\n[-7.937,-4.357] â†’ label1. Distance sqrt( ( -6.681+7.937)^2 + (-7.499+4.357)^2 )â‰ˆ sqrt(1.256^2 + (-3.142)^2 )â‰ˆ sqrt(1.58+9.87)=sqrt(11.45)=3.38.\\\\n\\\\n[-4.510,-7.755] â†’ label1. Distance sqrt( (-6.681+4.51)^2 + (-7.499+7.755)^2 )â‰ˆ sqrt( (-2.171)^2 +0.256^2 )â‰ˆ sqrt(4.71+0.065)=sqrt(4.775)=2.185.\\\\n\\\\nSo the closest point is [-6.520, -7.357] â†’ label0. Next closest is [-6.241,-7.859] â†’0. So k=2 â†’ both 0. Test point 4 â†’0.\\\\n\\\\n5. [0.981,10.166]\\\\n\\\\nLooking for points with x1 around 1, x2 around10.\\\\n\\\\nTraining examples:\\\\n\\\\n[1.541,9.85] â†’ label0. Distance sqrt( (0.981-1.541)^2 + (10.166-9.85)^2 )â‰ˆ sqrt( (-0.56)^2 +0.316^2 )â‰ˆ sqrt(0.3136 +0.10)=sqrt(0.4136)=0.643.\\\\n\\\\n[-0.048,10.016] â†’ label0. Distance sqrt(0.981+0.048)^2 + (10.166-10.016)^2 )â‰ˆ sqrt(1.029^2 +0.15^2 )â‰ˆ sqrt(1.058+0.0225)=sqrt(1.0805)=1.04.\\\\n\\\\n[1.260,8.763] â†’ label1. Distance sqrt( (0.981-1.26)^2 + (10.166-8.763)^2 )â‰ˆ sqrt( (-0.279)^2 +1.403^2 )â‰ˆ sqrt(0.0778+1.968)=sqrt(2.0458)=1.43.\\\\n\\\\n[1.995,8.663] â†’ label1. Distance sqrt( (0.981-1.995)^2 + (10.166-8.663)^2 )â‰ˆ sqrt( (-1.014)^2 +1.503^2 )â‰ˆ sqrt(1.028+2.259)=sqrt(3.287)=1.813.\\\\n\\\\nSo closest is [1.541,9.85] â†’0, next is [-0.048,10.016] â†’0. So with k=2 â†’0. Test point 5 â†’0.\\\\n\\\\n6. [-4.944, -7.424]\\\\n\\\\nTraining points near this:\\\\n\\\\n[-4.510,-7.755] â†’ label1. Distance sqrt( (-4.944+4.51)^2 + (-7.424+7.755)^2 )â‰ˆ sqrt( (-0.434)^2 +0.331^2 )â‰ˆ sqrt(0.188+0.109)=sqrt(0.297)=0.545.\\\\n\\\\n[-5.647,-7.949] â†’ label0. Distance sqrt( (-4.944+5.647)^2 + (-7.424+7.949)^2 )â‰ˆ sqrt(0.703^2 +0.525^2 )â‰ˆ sqrt(0.494+0.276)=sqrt(0.77)=0.878.\\\\n\\\\n[-4.078,-8.878] â†’ label0. Distance sqrt( (-4.944+4.078)^2 + (-7.424+8.878)^2 )â‰ˆ sqrt( (-0.866)^2 +1.454^2 )â‰ˆ sqrt(0.75+2.114)=sqrt(2.864)=1.692.\\\\n\\\\n[-3.877,-8.053] â†’ label1. Distance sqrt( (-4.944+3.877)^2 + (-7.424+8.053)^2 )â‰ˆ sqrt( (-1.067)^2 +0.629^2 )â‰ˆ sqrt(1.138+0.395)=sqrt(1.533)=1.238.\\\\n\\\\nSo closest is [-4.510,-7.755] â†’1. Next is [-5.647,-7.949] â†’0. Then [-3.877,-8.053] â†’1. So with k=3: labels 1,0,1 â†’ majority 1. Test point 6 â†’1.\\\\n\\\\n7. [-8.687, -2.395]\\\\n\\\\nTraining points near this:\\\\n\\\\n[-8.701, -2.135] â†’ label1. Distance sqrt( (-8.687+8.701)^2 + (-2.395+2.135)^2 )â‰ˆ sqrt(0.014^2 + (-0.26)^2 )â‰ˆ sqrt(0.000196 +0.0676)=sqrt(0.0678)=0.26.\\\\n\\\\n[-9.129, -0.411] â†’ label1. Distance sqrt(0.442^2 +1.984^2 )â‰ˆ sqrt(0.195+3.936)=sqrt(4.131)=2.032.\\\\n\\\\n[-8.787,1.588] â†’ label1. Further away.\\\\n\\\\n[-9.732,-1.864] â†’ label0. Distance sqrt( ( -8.687+9.732)^2 + (-2.395+1.864)^2 )â‰ˆ sqrt(1.045^2 + (-0.531)^2 )â‰ˆ sqrt(1.092+0.282)=sqrt(1.374)=1.172.\\\\n\\\\nSo closest point is [-8.701,-2.135] â†’1. So test point 7 â†’1.\\\\n\\\\n8. [-5.661, -8.500]\\\\n\\\\nTraining points near this:\\\\n\\\\n[-5.647, -7.949] â†’ label0. Distance sqrt( (-5.661+5.647)^2 + (-8.5+7.949)^2 )â‰ˆ sqrt( (-0.014)^2 + (-0.551)^2 )â‰ˆ sqrt(0.0002+0.3036)=sqrt(0.3038)=0.551.\\\\n\\\\n[-6.520,-7.357] â†’ label0. Distance sqrt( (-5.661+6.52)^2 + (-8.5+7.357)^2 )â‰ˆ sqrt(0.859^2 + (-1.143)^2 )â‰ˆ sqrt(0.738+1.306)=sqrt(2.044)=1.43.\\\\n\\\\n[-4.078,-8.878] â†’ label0. Distance sqrt( (-5.661+4.078)^2 + (-8.5+8.878)^2 )â‰ˆ sqrt( (-1.583)^2 +0.378^2 )â‰ˆ sqrt(2.506+0.143)=sqrt(2.649)=1.627.\\\\n\\\\n[-4.510,-7.755] â†’ label1. Distance sqrt( (-5.661+4.51)^2 + (-8.5+7.755)^2 )â‰ˆ sqrt( (-1.151)^2 + (-0.745)^2 )â‰ˆ sqrt(1.324+0.555)=sqrt(1.879)=1.371.\\\\n\\\\nSo closest is [-5.647,-7.949] â†’0. Next is [-4.510,-7.755] â†’1. Then [-6.520,-7.357] â†’0. For k=3: 0,1,0 â†’ majority 0. So test point 8 â†’0.\\\\n\\\\n9. [-8.799, 1.916]\\\\n\\\\nTraining points near this:\\\\n\\\\n[-8.787,1.588] â†’ label1. Distance sqrt( (-8.799+8.787)^2 + (1.916-1.588)^2 )â‰ˆ sqrt( (-0.012)^2 +0.328^2 )â‰ˆ sqrt(0.000144+0.1076)=sqrt(0.1077)=0.328.\\\\n\\\\n[-8.384,3.167] â†’ label1. Distance sqrt( (-8.799+8.384)^2 + (1.916-3.167)^2 )â‰ˆ sqrt( (-0.415)^2 + (-1.251)^2 )â‰ˆ sqrt(0.172+1.565)=sqrt(1.737)=1.317.\\\\n\\\\n[-8.652,2.220] â†’ label1. Distance sqrt( (-8.799+8.652)^2 + (1.916-2.220)^2 )â‰ˆ sqrt( (-0.147)^2 + (-0.304)^2 )â‰ˆ sqrt(0.0216+0.0924)=sqrt(0.114)=0.337.\\\\n\\\\n[-9.035,0.101] â†’ label1. Distance sqrt(0.236^2 +1.815^2 )â‰ˆ sqrt(0.055+3.296)=sqrt(3.351)=1.83.\\\\n\\\\nSo closest points: [-8.787,1.588] â†’1, [-8.652,2.220] â†’1. So test point 9 â†’1.\\\\n\\\\n10. [0.354,9.079]\\\\n\\\\nTraining points near this:\\\\n\\\\n[0.312, -9.919] â†’ label0. But x2 is negative; not relevant.\\\\n\\\\n[1.260,8.763] â†’ label1. Distance sqrt( (0.354-1.26)^2 + (9.079-8.763)^2 )â‰ˆ sqrt( (-0.906)^2 +0.316^2 )â‰ˆ sqrt(0.820+0.100)=sqrt(0.92)=0.959.\\\\n\\\\n[1.541,9.85] â†’ label0. Distance sqrt( (0.354-1.541)^2 + (9.079-9.85)^2 )â‰ˆ sqrt( (-1.187)^2 + (-0.771)^2 )â‰ˆ sqrt(1.409+0.594)=sqrt(2.003)=1.415.\\\\n\\\\n[-0.048,10.016] â†’ label0. Distance sqrt( (0.354+0.048)^2 + (9.079-10.016)^2 )â‰ˆ sqrt(0.402^2 + (-0.937)^2 )â‰ˆ sqrt(0.161+0.878)=sqrt(1.039)=1.019.\\\\n\\\\n[1.995,8.663] â†’ label1. Distance sqrt( (0.354-1.995)^2 + (9.079-8.663)^2 )â‰ˆ sqrt( (-1.641)^2 +0.416^2 )â‰ˆ sqrt(2.693+0.173)=sqrt(2.866)=1.693.\\\\n\\\\nSo closest points are [1.260,8.763] â†’1 (distance0.959), [-0.048,10.016]â†’0 (distance1.019), and [1.541,9.85] â†’0 (distance1.415). So k=3: labels 1,0,0 â†’ majority 0. But the closest is 1. If k=1, it\\'s 1. If k=3, two 0\\'s and one 1. So this is ambiguous. Let\\'s check another nearby point:\\\\n\\\\n[1.929,-9.611] â†’x2 is negative, not relevant.\\\\n\\\\n[1.541,9.85] is label0. So the nearest neighbors are 1 (distance0.95), 0 (distance1.01), and 0 (distance1.41). So with k=3, majority 0. But the closest is 1. Depending on the model, it could be either. But given that two of the three nearest are 0, perhaps label0.\\\\n\\\\nAlternatively, looking at the point [0.354,9.079], x1 is positive and x2 is high (9.079). Looking at similar training points:\\\\n\\\\n[1.260,8.763] â†’1.\\\\n\\\\n[1.541,9.85]â†’0.\\\\n\\\\n[-0.048,10.016]â†’0.\\\\n\\\\n[1.995,8.663]â†’1.\\\\n\\\\nThis suggests that when x1 is positive and x2 is high, it\\'s a mix of 0 and 1. The closest is 1, but the next two are 0. Hmm. Maybe the decision is 0.\\\\n\\\\nBut this is a tough call. Alternatively, in the region where x1 is positive and x2>8, the labels are 1 if x1 is less than about 4. For example, [3.358,8.36] â†’1, [4.828,8.829] â†’0. This test point has x1=0.354 <4 â†’ label1. But [1.541,9.85] is x1=1.541<4 â†’ label0. So that breaks the pattern.\\\\n\\\\nAlternatively, there\\'s no clear rule, so using nearest neighbors, since the closest is 1 (distance0.95), and the next two are 0 (1.01 and 1.41). Depending on whether k=1 or k=3. If k=1 â†’1, else 0. But it\\'s unclear. Since the user didn\\'t specify the method, but the examples are limited, I might go with the nearest neighbor (k=1) â†’ label1. But earlier in test point 5, the two closest were label0. But this is a judgment call. However, the training data has [1.260,8.763] (label1) at distance0.95 and [-0.048,10.016] (label0) at distance1.01. The difference in distance is very small. So possibly, it\\'s a toss-up. But given that the first nearest is 1, I\\'ll go with 1.\\\\n\\\\nBut wait, another point: [0.312,-9.919] is label0 but it\\'s in a different quadrant. Not relevant.\\\\n\\\\nAnother training point: [1.541,9.85] is label0. x1=1.541>0.354, x2=9.85>9.079. So perhaps in this region, higher x1 leads to label0. So 0.354 is lower than 1.541, so maybe label1. \\\\n\\\\nThis is really challenging. Based on the closest neighbor being label1, I\\'ll say test point 10 is 1. But I\\'m not confident. Alternatively, maybe the user intended a different pattern.\\\\n\\\\nAfter struggling through all these points, here are my tentative classifications:\\\\n\\\\n1. 0\\\\n\\\\n2. 1\\\\n\\\\n3. 1\\\\n\\\\n4. 0\\\\n\\\\n5. 0\\\\n\\\\n6. 1\\\\n\\\\n7. 1\\\\n\\\\n8. 0\\\\n\\\\n9. 1\\\\n\\\\n10. 1\\\\n\\\\nBut I\\'m not certain about test points 3 and 10. Let me double-check.\\\\n\\\\nTest point 3: [6.552,6.119]. The closest training points are [8.131,5.733] (label0), [8.015,4.588] (label1), [4.632,7.653] (label1). So with k=3, two 1\\'s and one 0 â†’ label1.\\\\n\\\\nTest point 10: [0.354,9.079]. Closest is [1.260,8.763] (1), next is [-0.048,10.016] (0), then [1.541,9.85] (0). So two 0\\'s and one 1 â†’ label0. But the closest is 1, but the next two are 0. Depending on k=3, majority 0. So maybe I was wrong earlier. So test point 10 is 0.\\\\n\\\\nBut this changes the answer. Let me adjust.\\\\n\\\\nFinal list:\\\\n\\\\n1. 0\\\\n\\\\n2. 1\\\\n\\\\n3. 1\\\\n\\\\n4. 0\\\\n\\\\n5. 0\\\\n\\\\n6. 1\\\\n\\\\n7. 1\\\\n\\\\n8. 0\\\\n\\\\n9. 1\\\\n\\\\n10. 0\\\\n\\\\nBut wait, test point 10: if the three nearest are 1,0,0 â†’ two 0\\'s. So majority 0. So correct.\\\\n<answer><answer>0, 1, 1, 0, 0, 1, 1, 0, 1, 0</answer></answer>\"]',\n",
       " 'model_evaluation_table': [{'order': 0,\n",
       "   'model': 'Points in the first quadrant (x>0, y>0) are Class 1',\n",
       "   'accuracy': 54.0,\n",
       "   'correct_count': 27,\n",
       "   'total_count': 50,\n",
       "   'details': '27 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if x > 0 and y > 0:\\n        return 1\\n    return 0',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"<think>Okay, so I need to classify these 10 data points based on the given examples. Let me look at the dataset first to see if I can find a pattern or a decision boundary that separates the classes 0 and 1. Looking at the provided examples, the features are two-dimensional, so maybe plotting them in my mind would help. Let me list out some of the points and their labels: Positive labels (1): - [3.358, 8.360] â†’ 1 (high x1, high x2) - [-7.937, -4.357] â†’ 1 (low x1, negative x2) - [7.104, -5.168] â†’ 1 (high x1, negative x2) - [1.260, 8.763] â†’ 1 (moderate x1, high x2) - [8.409, 2.986] â†’ 1 (high x1, moderate x2) - [8.015, 4.588] â†’ 1 (high x1, moderate x2) - [-8.384, 3.167] â†’ 1 (low x1, moderate x2) - [4.632, 7.653] â†’ 1 (moderate x1, high x2) - [7.667, -4.609] â†’1 (high x1, low x2) - [-2.561, 8.762] â†’1 (mod x1, high x2) - [-3.877, -8.053] â†’1 (low x1, very low x2) Negative labels (0): - [-0.048, 10.016] â†’0 (low x1, very high x2) - [-7.024, 7.181] â†’0 (low x1, high x2) - [-4.078, -8.878] â†’0 (low x1, very low x2) - [5.137, -8.616] â†’0 (high x1, very low x2) - [1.929, -9.611] â†’0 (mod x1, very low x2) - [-7.129,5.457] â†’1? Wait no, that's labeled 1. Wait, the example says: Features: [-7.129, 5.457], Label: 1. Oh right, so some points with x1 negative and x2 positive can be 1. But others like [-7.024,7.181] are 0. Hmm. So maybe there's a more complex boundary. Wait, perhaps it's a non-linear decision boundary. Let me try to see if there's a pattern based on quadrants or regions. Let's see: Looking at the positive labels: - Some are in the first quadrant (positive x1, positive x2) but not all. For example, [3.358,8.360] is 1, but [4.828,8.829] is 0. That's confusing. Wait, [4.828,8.829] is 0, while [3.358,8.360] is 1. So same quadrant but different labels. So maybe the boundary isn't based on quadrants. Alternatively, maybe it's a diagonal line or a circle? Let's think about other features. Looking at points with x2 high (like 8+). Some are 1, some are 0. For example, [3.358,8.36] is 1, but [-0.048,10.016] is 0. Similarly, [1.260,8.763] is 1, but [1.995,8.663] is 1. Wait, that's labeled as 1. Wait, no, the example given: [1.995, 8.663] is 1. Then what's different between those 0s and 1s in high x2? Let's check their x1 values. The 0s in high x2 have x1 around negative or lower. For example, [-0.048,10.016] (x1 is -0.048), but [1.541,9.850] is 0. Wait, no, that's labeled 0. Wait, Features: [1.541,9.850], Label:0. Hmm. So that's x1=1.5, x2=9.85. So maybe even positive x1 but high x2 can be 0. So that complicates things. Alternatively, perhaps the sum or difference of the features. Let's calculate some of them: For example, [3.358,8.360] â†’ sum is ~11.7, difference (x2 - x1) is ~5. Label 1. [-0.048,10.016] â†’ sum ~10, difference ~10.06. Label 0. [-7.937, -4.357] â†’ sum ~-12.3, difference 3.58. Label 1. [5.137, -8.616] â†’ sum ~-3.5, difference -13.75. Label 0. Hmm. Not sure. Maybe some other function. Let's think about the product or other relations. \"},\n",
       "  {'order': 1,\n",
       "   'model': 'Points within a radius of ~9.5 from origin are Class 1, otherwise Class 0',\n",
       "   'accuracy': 100.0,\n",
       "   'correct_count': 50,\n",
       "   'total_count': 50,\n",
       "   'details': '50 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'import math\\n\\ndef model(x, y, data):\\n    if x**2 + y**2 < 9.5**2:\\n        return 1\\n    return 0',\n",
       "   'model_family': 'custom',\n",
       "   'model_family_best_accuracy': None,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True}],\n",
       "   'text': \"Alternatively, perhaps a circle. Let's check distances from the origin. For example: [3.358,8.36]: distance sqrt(3.358Â² +8.36Â²) â‰ˆ sqrt(11.27 +69.9) â‰ˆ sqrt(81.17)â‰ˆ9.01. Label 1. [-0.048,10.016]: distance ~sqrt(0.0023 +100.32)â‰ˆ10.01. Label 0. [1.260,8.763]: sqrt(1.5876+76.8)â‰ˆsqrt(78.4)â‰ˆ8.85. Label 1. [1.541,9.85]: sqrt(2.37+97.0)â‰ˆsqrt(99.37)â‰ˆ9.97. Label 0. So maybe points within a certain radius from the origin are 1, and outside are 0? But 10.01 is 0, and 9.01 is 1, but 9.97 is 0 and 8.85 is 1. So perhaps the threshold is around 9.5? Let's check another point. [4.632,7.653] is 1. Its distance is sqrt(21.46+58.57)=sqrt(80)â‰ˆ8.94. So that's inside 9.5, label 1. Then [8.409,2.986], distance sqrt(70.7+8.92)=sqrt(79.6)=8.92, so label 1. [-7.937,-4.357], distance sqrt(63+19)=sqrt(82)=9.06, which is over 9, but label is 1. So that contradicts. Maybe not a circle. Alternatively, maybe a combination of x1 and x2. Let's look for other patterns. Looking at some 0 labels: [-4.078, -8.878] â†’ both negative. Label 0. [5.137, -8.616] â†’ x1 positive, x2 negative. Label 0. [-7.024,7.181] â†’ x1 negative, x2 positive. Label 0. [1.929,-9.611] â†’ x1 positive, x2 negative. Label 0. [3.526,-9.428] â†’ same. Label 0. [8.131,5.733] â†’ both positive. Label 0. [-9.732,-1.864] â†’ x1 very negative, x2 negative. Label 0. [ -3.345,-9.385] â†’ x1 negative, x2 very negative. Label 0. [ -6.520,-7.357] â†’ label 0. But then some other points with similar positions are labeled 1. For example: [-7.937, -4.357] â†’ label 1. But [-4.078, -8.878] is 0. So even in the same quadrant, labels differ. \"},\n",
       "  {'order': 2,\n",
       "   'model': 'Classification based on whether x1 + x2 is above a threshold',\n",
       "   'accuracy': 54.0,\n",
       "   'correct_count': 27,\n",
       "   'total_count': 50,\n",
       "   'details': '27 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    # Threshold not defined, illustrative example using 0\\n    if x + y > 0:\\n        return 1\\n    return 0',\n",
       "   'model_family': 'sklearn.linear_model.LogisticRegression',\n",
       "   'model_family_best_accuracy': 62.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"Wait, maybe there's a diagonal line. For example, perhaps points where x1 + x2 is above a certain value are 0 or 1. Let's test: For [3.358,8.360], x1 +x2 â‰ˆ11.7 â†’ label 1. [-0.048,10.016], sum â‰ˆ10 â†’ label 0. [-7.937, -4.357] sumâ‰ˆ-12.3 â†’ label 1. [5.137, -8.616] sumâ‰ˆ-3.48 â†’ label 0. Hmm. Not sure. \"},\n",
       "  {'order': 3,\n",
       "   'model': 'Classification based on whether x1 - x2 is above a threshold',\n",
       "   'accuracy': 46.0,\n",
       "   'correct_count': 23,\n",
       "   'total_count': 50,\n",
       "   'details': '23 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    # Threshold not defined, illustrative example using 0\\n    if x - y > 0:\\n        return 1\\n    return 0',\n",
       "   'model_family': 'sklearn.linear_model.LogisticRegression',\n",
       "   'model_family_best_accuracy': 62.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"What about x1 - x2: [3.358 -8.360 = -5 â†’ label 1. [-0.048 -10.016 â‰ˆ-10 â†’ label 0. [-7.937 - (-4.357) = -3.58 â†’ label1. Not obvious. Maybe another approach. Let's look for regions where certain conditions hold. \"},\n",
       "  {'order': 4,\n",
       "   'model': 'Points with positive x1 and negative x2 are Class 0',\n",
       "   'accuracy': 56.00000000000001,\n",
       "   'correct_count': 28,\n",
       "   'total_count': 50,\n",
       "   'details': '28 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if x > 0 and y < 0:\\n        return 0\\n    return 1',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True}],\n",
       "   'text': \"For example, maybe if x1 is positive and x2 is negative, then label 0. But wait, [5.137,-8.616] is 0, [7.104,-5.168] is 1. So that can't be the case. Similarly, [7.667,-4.609] is 1. So same quadrant (x1 positive, x2 negative) but different labels. So that's not a rule. Another idea: perhaps if x2 is greater than a certain function of x1. Let's see. Looking at points where x2 is high. Let's see if there's a line that separates them. For example, in positive x2 region: [3.358,8.36] (label1) vs [4.828,8.829] (label0). So higher x1 but same x2 gives a different label. What's the difference here? Maybe x1 in a certain range. Wait, 3.358 is less than 4.828. So maybe when x1 is below a certain value and x2 is high, it's 1, but if x1 is above, 0? Not sure. For example, [1.260,8.763] is 1, [1.541,9.85] is 0. Hmm, but 1.541 is higher x1. Maybe not. Alternatively, check if x1 is positive or negative. For example, for high x2 (like over 8), if x1 is negative, maybe label 0. But [-7.024,7.181] is x2=7.18, which is not as high. Wait, but [-3.008,9.430] is label0. So x1 is negative, x2 high (9.43). So label0. Then the [1.260,8.763], which is x1 positive, x2 high (8.76), label1. \"},\n",
       "  {'order': 5,\n",
       "   'model': 'For x2 > 8: if x1 > 0 -> Class 1, if x1 <= 0 -> Class 0. Otherwise Class 0.',\n",
       "   'accuracy': 48.0,\n",
       "   'correct_count': 24,\n",
       "   'total_count': 50,\n",
       "   'details': '24 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if y > 8:\\n        if x > 0:\\n            return 1\\n        else: # x <= 0\\n            return 0\\n    return 0 # Defaulting unspecified else to 0',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"So maybe for x2 high (above say 8), x1 positive is 1, x1 negative is 0? Let's check: [-3.008,9.43] â†’ x1 negative â†’ label0. [1.260,8.763] â†’ x1 positive â†’ label1. [3.358,8.36] â†’ positive x1 â†’ label1. [4.828,8.829] â†’ positive x1 â†’ label0. Wait, that breaks the pattern. So there's an exception here. So maybe that's not the case. Another approach: perhaps use a decision tree-like approach. Let's look for splits. For example, maybe split on x2. Let's see if x2 > some value. Looking at points with x2 >8: [3.358,8.36] â†’1 [-0.048,10.016] â†’0 [-3.008,9.43] â†’0 [1.260,8.763] â†’1 [1.995,8.663] â†’1 [4.828,8.829] â†’0 [1.541,9.85] â†’0 So for x2 >8, labels are 1 and 0. How to distinguish? Maybe x1 > something. For x2>8, when x1 is positive, sometimes 1, sometimes 0. For example, [3.358,8.36] â†’x1=3.358â†’1, [4.828,8.829]â†’x1=4.828â†’0. Hmm. So maybe there's a threshold around x1=4 in x2>8 area. Let's see: if x1>4, then 0? But [8.409,2.986] which is x2=2.986, x1=8.4 â†’ label1. So maybe not. This seems complicated. Looking at points where x1 is positive and x2 is negative: [5.137,-8.616] â†’0 [7.104,-5.168] â†’1 [3.526,-9.428] â†’0 [1.929,-9.611] â†’0 [0.561,-8.882] â†’1 [2.236,-8.584] â†’1 [6.077,-7.597] â†’0 [7.667,-4.609] â†’1 [8.115,-3.849] â†’1 Hmm, so when x1 is positive and x2 negative, it's a mix of 0 and 1. So perhaps x1 and x2 follow a certain relationship here. Maybe if x1 + x2 > something? Let's calculate for these points: 5.137 + (-8.616) = -3.48 â†’0 7.104 + (-5.168)=1.936 â†’1 3.526 + (-9.428)= -5.9 â†’0 1.929 + (-9.611)= -7.68 â†’0 0.561 + (-8.882)= -8.32 â†’1 (wait, 0.561, -8.882 is labeled 1?) Yes, the example says: Features: [0.561, -8.882], Label:1. So that sum is -8.32, which is lower than the other 0 cases. So sum isn't the key. \"},\n",
       "  {'order': 6,\n",
       "   'model': 'For x1 > 0 and x2 < 0: if x1 > |x2| -> Class 1, else Class 0. Otherwise Class 0.',\n",
       "   'accuracy': 50.0,\n",
       "   'correct_count': 25,\n",
       "   'total_count': 50,\n",
       "   'details': '25 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'import math\\n\\ndef model(x, y, data):\\n    if x > 0 and y < 0:\\n        if x > abs(y):\\n            return 1\\n        else:\\n            return 0\\n    return 0',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"Alternatively, x1 vs |x2|. For example, in positive x1, negative x2: x1=5.137, |x2|=8.616. x1 < |x2| â†’0. x1=7.104, |x2|=5.168. x1 > |x2| â†’1. x1=3.526, |x2|=9.428 â†’x1 < |x2| â†’0. x1=1.929 < 9.611 â†’0. x1=0.561 <8.882 â†’1. Hmm, that breaks the pattern. Because 0.561 <8.882 but label is 1. So maybe that's not the rule. Alternatively, maybe when x1 > |x2| - some value. For example, 7.104 >5.168 â†’ yes, label 1. 5.137 <8.616 â†’0. But 0.561 <8.882 â†’ label1. So that contradicts. Hmm. Maybe another angle. Let's look for points that are near the edges. Let's think about the given test points. For example, the first test point is [5.079, -8.708]. Looking at similar points in the training data: [5.137, -8.616] is label 0. So very close. So maybe this is 0. But wait, [5.137 is -8.616] â†’0. The test point is [5.079, -8.708], which is almost the same. So maybe label 0. But wait, there's also [2.236, -8.584] which is label1. So why is 5.137 labeled 0 and 2.236 labeled1? Let me check the x1 and x2. Wait, maybe for positive x1 and negative x2, if x1 is greater than a certain value and x2 is less than a certain value, it's 1. For example, 7.104 is x1=7.1, x2=-5.1. Label1. 8.115, -3.849 â†’ label1. So higher x1 and less negative x2. But then [5.137,-8.6] is x1=5.1, x2=-8.6 â†’0, while [7.104,-5.1] â†’1. So maybe when x1 is high enough compared to |x2|, it's 1. For example, if x1 > |x2|/something. Let's compute for these points: 7.104 /5.168â‰ˆ1.37. 5.137/8.616â‰ˆ0.6. 2.236/8.584â‰ˆ0.26. 0.561/8.882â‰ˆ0.063. 7.667/4.609â‰ˆ1.66. 8.115/3.849â‰ˆ2.1. Hmm, in the cases where the ratio (x1/|x2|) is higher, the label is 1. For example, 7.1/5.1â‰ˆ1.37 â†’1. 8.115/3.849â‰ˆ2.1 â†’1. 5.1/8.6â‰ˆ0.6 â†’0. 2.236/8.584â‰ˆ0.26 â†’1. But that's inconsistent. For 2.236/8.584 is 0.26, which is lower than 0.6, but the label is 1. So that doesn't hold. Maybe another pattern. Looking at the points with x1 positive and x2 negative: Label1 when x1 is high (like 7.1, 7.6, 8.1, 8.4) but sometimes lower x1 (like 2.236) is label1. Hmm. Maybe it's based on x1 being above a certain threshold, but the threshold varies. Alternatively, maybe the product of x1 and x2. Let's compute: For [5.079, -8.708] â†’5.079 * (-8.708) â‰ˆ-44.3. The similar point [5.137,-8.616] product is ~-44.3, which is 0. So maybe negative product. But many points have negative products. Not helpful. Alternative approach: let's try to see if there's a linear decision boundary. Maybe using a support vector machine or logistic regression approach. But since this is a thought process, let's try to find a line that separates most of the points. Looking at the positive labels (1): They seem to be in areas where either: - High positive x1 with moderate to low x2 (positive or negative). - High negative x1 with x2 not too high. Wait, but some points like [-7.937,-4.357] (x1=-7.9, x2=-4.3) are 1. While [-4.078,-8.878] (x1=-4.07, x2=-8.87) is 0. So what's the difference? The x1 is more negative in the first case, but x2 is less negative. Maybe the sum? For [-7.937, -4.357], sum is -12.29. For [-4.078, -8.878], sum is -12.956. The first is slightly higher sum, but label is 1. Not sure. Alternatively, maybe if x1 is more negative than x2. For [-7.937, -4.357], x1=-7.9, x2=-4.3 â†’x1 is more negative (since -7.9 < -4.3). So |x1| > |x2|. For [-4.078, -8.878], |x1| is 4.07, |x2|=8.87 â†’ |x1| < |x2|. So label 0. \"},\n",
       "  {'order': 7,\n",
       "   'model': 'For x1 < 0 and x2 < 0: if |x1| > |x2| -> Class 1, else Class 0. Otherwise Class 0.',\n",
       "   'accuracy': 46.0,\n",
       "   'correct_count': 23,\n",
       "   'total_count': 50,\n",
       "   'details': '23 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'import math\\n\\ndef model(x, y, data):\\n    if x < 0 and y < 0:\\n        if abs(x) > abs(y):\\n            return 1\\n        else:\\n            return 0\\n    return 0',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"So maybe in the negative x1 and x2 region, if |x1| > |x2|, label 1, else 0. Let's check: [-7.937,-4.357] â†’|x1|>|x2| â†’1. [-4.078,-8.878] â†’|x1|<|x2| â†’0. [-9.732,-1.864] â†’|x1|>|x2| â†’ label0. Wait, this is conflicting. This point is x1=-9.732, x2=-1.864. |x1|>|x2| â†’9.73>1.864. But label is 0. So that breaks the pattern. But in the examples, there's [-9.129,-0.411] â†’ label1. Here, x1 is very negative, x2 slightly negative. |x1|>|x2| â†’ yes. Label1. So why is [-9.732,-1.864] label0? That also has |x1|>|x2|. Hmm. So that contradicts the previous idea. So maybe there's another factor. Let's look at these two points: [-9.129, -0.411] â†’ label1. [-9.732,-1.864] â†’ label0. What's different? The x2 values are -0.411 vs -1.864. Also, x1 is -9.129 vs -9.732. Maybe x1 is past a certain threshold. For example, if x1 < -9, then label0. But [-9.129 is -9.129, which is less than -9, and it's label1. So that's not it. Alternatively, the sum of x1 and x2. For [-9.129, -0.411], sum is -9.54. For [-9.732,-1.864], sum is -11.596. \"},\n",
       "  {'order': 8,\n",
       "   'model': 'For x1 < 0 and x2 < 0: if x1 + x2 < -10 -> Class 0, else Class 1. Otherwise Class 0.',\n",
       "   'accuracy': 52.0,\n",
       "   'correct_count': 26,\n",
       "   'total_count': 50,\n",
       "   'details': '26 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if x < 0 and y < 0:\\n        if x + y < -10:\\n            return 0\\n        else:\\n            return 1\\n    return 0',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"Maybe sum is less than -10 â†’ label0. The first sum is -9.54 (above -10), label1. Second is -11.596 (below -10), label0. Let's check other points. [-8.701,-2.135] sum is -10.836 â†’ label1. But according to the sum threshold, this would be below -10, so label0. But the actual label is1. So that's a problem. Hmm. This is getting complicated. Maybe I should look for another pattern. Let's consider the following: Positive labels (1) appear in regions where: - x1 is positive and x2 is negative with x1 high enough (like 7.104, 7.667, 8.115, etc.) - x1 is negative and x2 is positive but not too high (maybe?) Wait, [-7.129,5.457] is label1, while [-7.024,7.181] is label0. \"},\n",
       "  {'order': 9,\n",
       "   'model': 'For x1 < 0 and x2 > 0: if x2 < 6 -> Class 1, else Class 0. Otherwise Class 0.',\n",
       "   'accuracy': 56.00000000000001,\n",
       "   'correct_count': 28,\n",
       "   'total_count': 50,\n",
       "   'details': '28 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if x < 0 and y > 0:\\n        if y < 6:\\n            return 1\\n        else:\\n            return 0\\n    return 0',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True}],\n",
       "   'text': \"So for negative x1 and positive x2, perhaps if x2 is below a certain value, it's 1. For example, x2 <6. Then [-7.129,5.457] is 5.457 <6 â†’1. [-7.024,7.181] is 7.18>6 â†’0. Let's check other points. [-8.384,3.167] â†’3.167 <6 â†’1. Label1. [-8.652,2.220] â†’2.22 <6 â†’1. Label1. [-8.787,1.588] â†’1.588 <6 â†’1. Label1. Yes, those are all label1. Then [-7.024,7.181] is x2=7.18 â†’ label0. So maybe in the negative x1 and positive x2 region, if x2 <6 â†’1, else 0. Similarly, in the positive x1 and positive x2 region, maybe there's a different rule. For example, [3.358,8.36] is label1, but [4.828,8.829] is 0. So what's the difference? Maybe x1 <4.8 â†’1, else 0? But [8.409,2.986] is x1=8.4, x2=2.986 â†’ label1. So maybe in this region, different rules. Alternatively, in positive x1 and positive x2, if x1 <5 and x2>8 â†’1, else 0. Let's see: [3.358,8.36] â†’ x1<5, x2>8 â†’1. [4.828,8.829] â†’x1<5? No, 4.828 is less than 5. x2>8. So why label0? Hmm. That breaks the pattern. Wait, [4.632,7.653] is x1=4.6, x2=7.65 â†’ both positive. Label1. So maybe x2>7.65 â†’1? But 4.828,8.829 has x2=8.82>7.65, but label0. So that's not it. This is getting too time-consuming. Maybe there's a better approach. Let me try to see if the labels are determined by the sign of (x1 + x2) or something similar. Let's test: For [3.358,8.36] â†’ x1+x2=11.718 â†’ positive. Label1. [-0.048,10.016] â†’ sumâ‰ˆ10 â†’ positive. Label0. [-7.937,-4.357] â†’ sumâ‰ˆ-12.3 â†’ negative. Label1. [5.137,-8.616] â†’ sumâ‰ˆ-3.48 â†’ negative. Label0. Hmm, inconsistent. So maybe not sum. Another idea: maybe the labels are based on whether the point is inside or outside of certain polygons or regions. For example, a region in the upper left (negative x1, positive x2) where x2 <6 â†’ label1, and others in that area are 0. In the lower right (positive x1, negative x2) where x1 > some value â†’1, else 0. In the lower left (negative x1, negative x2) where |x1|>|x2| â†’1, else 0. And upper right (positive x1, positive x2) where x1 < some value and x2 > some other value â†’1, else 0. Let's try this: 1. Upper left quadrant (x1 <0, x2>0): - If x2 <6 â†’ label1. - Else â†’0. Examples: [-7.129,5.457] â†’5.457<6 â†’1. Correct. [-7.024,7.181] â†’7.18>6 â†’0. Correct. [-8.384,3.167] â†’3.167<6 â†’1. Correct. [-3.008,9.43] â†’x2=9.43>6 â†’0. Correct. [-8.652,2.22] â†’2.22<6 â†’1. Correct. Yes, this seems to fit. 2. Lower right quadrant (x1>0, x2<0): - If x1 >6 â†’ label1. - Else â†’ check if x2 >-5 â†’ maybe, but examples are mixed. Wait, let's check examples: [7.104,-5.168] â†’x1=7.1>6 â†’ label1. [5.137,-8.616] â†’x1=5.1<6 â†’ label0. [1.929,-9.611] â†’x1=1.9<6 â†’0. [0.561,-8.882] â†’x1=0.56<6 â†’1. Hmm, but this breaks the rule. So this point is x1=0.56<6, x2=-8.88, label1. So the rule would fail here. Alternatively, maybe for x1>0 and x2<0, if x1 + x2 > some value. For example: 7.104 + (-5.168) =1.936 â†’1.936>? Let's say >0 â†’1. 5.137 + (-8.616) =-3.48 â†’-3.48 <0 â†’0. 0.561 + (-8.882) =-8.32 â†’<0 â†’ but label is1. So that's not working. Another approach: for x1>0 and x2<0, label1 if x1 > |x2|. Let's check: 7.104 >5.168 â†’ yes â†’1. 5.137 <8.616 â†’ no â†’0. 0.561 <8.882 â†’ no â†’ but label1. So no. Hmm. What about x1 > something like 5 and x2 >-6? Let's see: [7.104, -5.168] â†’x2=-5.168. Is x2 >-6? Yes. So x1>5 and x2> -6 â†’ label1. [5.137, -8.616] â†’x1=5.137>5, x2=-8.616 < -6 â†’ label0. [0.561,-8.882] â†’x1<5 â†’ label1 (doesn't fit). [2.236,-8.584] â†’x1=2.236<5 â†’ label1. Doesn't fit. This is tricky. Maybe in this quadrant, there's another rule. Alternatively, perhaps if x1 is greater than a certain value (like 6) and x2 is greater than a certain value (like -6), it's label1. Otherwise, label0. Let's check: 7.104 >6, x2=-5.168 >-6 â†’1. Correct. 5.137 <6 â†’0. Correct. 7.667>6, x2=-4.609 >-6 â†’1. Correct. 8.115>6, x2=-3.849>-6 â†’1. Correct. 6.077>6? 6.077 is just over 6. x2=-7.597 < -6 â†’0. Which matches the example: Features: [6.077, -7.597], Label:0. But then there's [0.561,-8.882], x1=0.561<6, so label0 according to this rule, but actual label is1. So this rule would miss that point. So maybe there's another pattern for points with x1<6 but x2< -something. \"},\n",
       "  {'order': 10,\n",
       "   'model': 'For x1 > 0 and x2 < 0: if x1 > 6 -> Class 1, else Class 0. Otherwise Class 0.',\n",
       "   'accuracy': 48.0,\n",
       "   'correct_count': 24,\n",
       "   'total_count': 50,\n",
       "   'details': '24 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if x > 0 and y < 0:\\n        if x > 6:\\n            return 1\\n        else:\\n            return 0\\n    return 0',\n",
       "   'model_family': 'sklearn.tree.DecisionTreeClassifier',\n",
       "   'model_family_best_accuracy': 72.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"Alternatively, the points in lower right (x1>0, x2<0) are label1 if x1 is greater than a certain value, regardless of x2. Let's see: Points with x1>6: [7.104,7.667,8.115,8.409,8.859, etc.] all label1. Points with x1 between 5 and 6: [5.137,5.514,5.079 (test point), etc.] â†’label0. But [5.514,-7.015] â†’ x1=5.514<6 â†’ but label1. Wait, the example says Features: [5.514, -7.015], Label:1. So this is a problem for the rule. Because x1=5.514 is less than 6, but label is1. Hmm. So the rule that x1>6 â†’1, else0 doesn't hold here. So maybe there's a different threshold. Let's see: Looking at x1 values for positive labels in this quadrant: 7.104,7.667,8.115,8.409,8.859, etc. â†’ all >7. But [5.514,-7.015] is x1=5.514 â†’ label1. So this is an exception. So the rule isn't straightforward. \"},\n",
       "  {'order': 11,\n",
       "   'model': 'For x1 > 0 and x2 < 0: if x2 < -x1 - 1.5 -> Class 1, else Class 0. Otherwise Class 0.',\n",
       "   'accuracy': 40.0,\n",
       "   'correct_count': 20,\n",
       "   'total_count': 50,\n",
       "   'details': '20 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if x > 0 and y < 0:\\n        if y < -x - 1.5:\\n            return 1\\n        else:\\n            return 0\\n    return 0',\n",
       "   'model_family': 'sklearn.linear_model.LogisticRegression',\n",
       "   'model_family_best_accuracy': 62.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"Maybe it's a diagonal line. For example, x2 = -x1 + c. Let's see for [5.514,-7.015]: x2 = -7.015, x1=5.514. So -x1 + c = -5.514 +c = -7.015 â†’ c =-7.015 +5.514 â‰ˆ-1.5. So maybe x2 < -x1 -1.5 â†’ label1. Let's test this: For [5.514,-7.015]: x2=-7.015 < -5.514 -1.5= -7.014 â†’ yes, so label1. For [7.104,-5.168]: x2=-5.168 < -7.104 -1.5= -8.604 â†’ no â†’ so label0. But actual label is1. So this doesn't work. \"},\n",
       "  {'order': 12,\n",
       "   'model': 'For x1 > 0 and x2 < 0: if x1 + x2 > 0 -> Class 1, else Class 0. Otherwise Class 0.',\n",
       "   'accuracy': 50.0,\n",
       "   'correct_count': 25,\n",
       "   'total_count': 50,\n",
       "   'details': '25 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'def model(x, y, data):\\n    if x > 0 and y < 0:\\n        if x + y > 0:\\n            return 1\\n        else:\\n            return 0\\n    return 0',\n",
       "   'model_family': 'sklearn.linear_model.LogisticRegression',\n",
       "   'model_family_best_accuracy': 62.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False}],\n",
       "   'text': \"Another idea: maybe in the lower right quadrant, label1 if x1 +x2 >0. Let's check: [7.104, -5.168] â†’7.104-5.168=1.936>0 â†’1. Correct. [5.514, -7.015] â†’5.514-7.015=-1.5<0 â†’ label1. Doesn't fit. [5.137,-8.616] â†’-3.48<0 â†’0. Correct. [0.561,-8.882] â†’-8.32<0 â†’ label1. Doesn't fit. So no. This is getting too time-consuming. \"},\n",
       "  {'order': 13,\n",
       "   'model': 'k-NN classification using majority label of k=3 nearest neighbors',\n",
       "   'accuracy': 56.00000000000001,\n",
       "   'correct_count': 28,\n",
       "   'total_count': 50,\n",
       "   'details': '28 of 50 correct',\n",
       "   'has_error': False,\n",
       "   'model_code': 'import math\\nfrom collections import Counter\\n\\ndef model(x, y, data):\\n    distances = []\\n    for xi, yi, label in data:\\n        dist = math.sqrt((x - xi)**2 + (y - yi)**2)\\n        distances.append((dist, label))\\n    \\n    distances.sort(key=lambda item: item[0])\\n    \\n    k = 3\\n    if len(distances) < k:\\n        k = len(distances) # Adjust k if less than k points available\\n        \\n    if k == 0:\\n         return 0 # Default for no neighbors\\n\\n    top_k_labels = [label for _, label in distances[:k]]\\n    \\n    label_counts = Counter(top_k_labels)\\n    \\n    # Handle ties: Default ties to 0 for reproducibility.\\n    if label_counts[1] > label_counts[0]:\\n        return 1\\n    elif label_counts[0] > label_counts[1]:\\n        return 0\\n    else:\\n         # Tie-breaking: Default to 0\\n         return 0',\n",
       "   'model_family': 'sklearn.neighbors.KNeighborsClassifier',\n",
       "   'model_family_best_accuracy': 62.0,\n",
       "   'predictions': [{'features': [3.357846747376106, 8.36049582088344],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [-0.047947512631297, 10.016010094955334],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-7.937190310846499, -4.357482667640288],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-7.024464131167623, 7.180928947521026],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-4.078232576882307, -8.878474274246535],\n",
       "     'true_label': 0,\n",
       "     'predicted': 1,\n",
       "     'correct': False},\n",
       "    {'features': [-8.70054234682747, -2.1354582383817893],\n",
       "     'true_label': 1,\n",
       "     'predicted': 0,\n",
       "     'correct': False},\n",
       "    {'features': [-5.647349772419439, -7.9493493775796145],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-9.128781695558267, -0.41135899184015534],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True},\n",
       "    {'features': [5.137223842410715, -8.615503549221469],\n",
       "     'true_label': 0,\n",
       "     'predicted': 0,\n",
       "     'correct': True},\n",
       "    {'features': [-8.786777159863409, 1.5882715964470204],\n",
       "     'true_label': 1,\n",
       "     'predicted': 1,\n",
       "     'correct': True}],\n",
       "   'text': \"So maybe for x>8, if y <3 â†’1, else 0? Let's check: [8.529,5.21] â†’y=5.21>3 â†’0. [9.035,1.186] â†’y<3 â†’1. [9.716,2.782] â†’y=2.782<3 â†’0. But according to the rule, it should be 1. But [9.716,2.782] is labeled 0. So conflicting. \"}]}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_funcs[\"samples\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text[\"llm_analysis_extracted_json\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
