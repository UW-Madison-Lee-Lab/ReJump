{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7806caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import root_dir\n",
    "from constants import get_result_dir, supported_llms\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a5211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_ids = [0, 1]\n",
    "model_name = \"xai/grok-3-mini-beta\"\n",
    "# model_name = \"openrouter-microsoft/phi-4-reasoning-plus\"\n",
    "dataset_name = \"zebralogic\"\n",
    "n_samples = 100\n",
    "# data_mode = \"instructiond\"\n",
    "data_mode = \"default\"\n",
    "\n",
    "result_dirs = []\n",
    "for replicate_id in replicate_ids:\n",
    "    result_dir = get_result_dir(\n",
    "        dataset_name,\n",
    "        model_name,\n",
    "        shot = 0,\n",
    "        template_type = supported_llms[model_name][\"template_type\"],\n",
    "        response_length = 404,\n",
    "        num_samples = 100,\n",
    "        feature_noise = None,\n",
    "        label_noise = 0.0,\n",
    "        data_mode = data_mode,\n",
    "        n_query = 1,\n",
    "        temperature = 1.0,\n",
    "        replicate_id = replicate_id,\n",
    "    )\n",
    "    result_dirs.append(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble result:\n",
      "accuracy:  0.290 ± 0.454\n",
      "filtered_ajd:  17.805 ± 10.242\n",
      "forgetting_rates:  0.000 ± 0.000\n",
      "average_solution_count:  3.800 ± 2.098\n",
      "success_rates:  0.174 ± 0.244\n",
      "overthinking_rates:  0.005 ± 0.050\n",
      "average_verification_rates:  0.065 ± 0.042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result_dfs = []\n",
    "for result_dir in result_dirs:\n",
    "    result_df = pd.read_csv(os.path.join(result_dir, \"tree_vis_google/gemini-2.5-pro-preview-03-25\", \"metric_df.csv\"))\n",
    "    result_df.rename(columns={result_df.columns[0]: \"index\"}, inplace=True)\n",
    "    result_dfs.append(result_df)\n",
    "\n",
    "corrs_list = []\n",
    "filtered_ajd_list = []\n",
    "forgetting_rates_list = []\n",
    "average_solution_count_list = []\n",
    "success_rates_list = []\n",
    "overthinking_rates_list = []\n",
    "average_verification_rates_list = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    selected_replicate_id = None\n",
    "    selected_filtered_ajd = 100\n",
    "    \n",
    "    for idx, df in enumerate(result_dfs):\n",
    "        filtered_ajd_value = df[df.index == i][\"filtered_ajd\"]\n",
    "        if filtered_ajd_value.empty: continue\n",
    "        if filtered_ajd_value.values[0] < selected_filtered_ajd:\n",
    "            selected_replicate_id = idx\n",
    "            selected_filtered_ajd = filtered_ajd_value.values[0]\n",
    "    \n",
    "    if selected_replicate_id is None: continue\n",
    "    selected_result_df = result_dfs[selected_replicate_id]\n",
    "    \n",
    "    corrs_list.append(selected_result_df[selected_result_df.index == i][\"corrs\"].values[0])\n",
    "    filtered_ajd_list.append(selected_result_df[selected_result_df.index == i][\"filtered_ajd\"].values[0])\n",
    "    forgetting_rates_list.append(selected_result_df[selected_result_df.index == i][\"forgetting_rates\"].values[0])\n",
    "    average_solution_count_list.append(selected_result_df[selected_result_df.index == i][\"average_solution_count\"].values[0])\n",
    "    success_rates_list.append(selected_result_df[selected_result_df.index == i][\"success_rates\"].values[0])\n",
    "    overthinking_rates_list.append(selected_result_df[selected_result_df.index == i][\"overthinking_rates\"].values[0])\n",
    "    average_verification_rates_list.append(selected_result_df[selected_result_df.index == i][\"average_verification_rates\"].values[0])\n",
    "    \n",
    "print(\"ensemble result:\")\n",
    "print(\"accuracy: \", f\"{np.mean(corrs_list):.3f}\", \"±\", f\"{np.std(corrs_list):.3f}\")\n",
    "print(\"filtered_ajd: \", f\"{np.mean(filtered_ajd_list):.3f}\", \"±\", f\"{np.std(filtered_ajd_list):.3f}\")\n",
    "print(\"forgetting_rates: \", f\"{np.mean(forgetting_rates_list):.3f}\", \"±\", f\"{np.std(forgetting_rates_list):.3f}\")\n",
    "print(\"average_solution_count: \", f\"{np.mean(average_solution_count_list):.3f}\", \"±\", f\"{np.std(average_solution_count_list):.3f}\")\n",
    "print(\"success_rates: \", f\"{np.mean(success_rates_list):.3f}\", \"±\", f\"{np.std(success_rates_list):.3f}\")\n",
    "print(\"overthinking_rates: \", f\"{np.mean(overthinking_rates_list):.3f}\", \"±\", f\"{np.std(overthinking_rates_list):.3f}\")\n",
    "print(\"average_verification_rates: \", f\"{np.mean(average_verification_rates_list):.3f}\", \"±\", f\"{np.std(average_verification_rates_list):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928d21a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average with std\n",
      "accuracy:  0.330 ± 0.318\n",
      "filtered_ajd:  11.679 ± 7.302\n",
      "forgetting_rates:  0.000 ± 0.000\n",
      "average_solution_count:  3.745 ± 2.322\n",
      "success_rates:  0.322 ± 0.271\n",
      "overthinking_rates:  0.003 ± 0.025\n",
      "average_verification_rates:  0.059 ± 0.034\n"
     ]
    }
   ],
   "source": [
    "result_dfs = []\n",
    "for result_dir in result_dirs:\n",
    "    result_df = pd.read_csv(os.path.join(result_dir, \"tree_vis_google/gemini-2.5-pro-preview-03-25\", \"metric_df.csv\"))\n",
    "    result_df.rename(columns={result_df.columns[0]: \"index\"}, inplace=True)\n",
    "    result_dfs.append(result_df)\n",
    "\n",
    "# Initialize lists to store metrics for each sample\n",
    "sample_corrs_list = []\n",
    "sample_filtered_ajd_list = []\n",
    "sample_forgetting_rates_list = []\n",
    "sample_average_solution_count_list = []\n",
    "sample_success_rates_list = []\n",
    "sample_overthinking_rates_list = []\n",
    "sample_average_verification_rates_list = []\n",
    "\n",
    "# Loop through each sample index\n",
    "for i in range(n_samples):\n",
    "    sample_corrs = 0\n",
    "    sample_filtered_ajd = 0\n",
    "    sample_forgetting_rates = 0\n",
    "    sample_average_solution_count = 0\n",
    "    sample_success_rates = 0\n",
    "    sample_overthinking_rates = 0\n",
    "    sample_average_verification_rates = 0\n",
    "    valid_replicates = 0\n",
    "    \n",
    "    # Collect data from each replicate (result_df) for the current sample\n",
    "    for df in result_dfs:\n",
    "        if i in df['index'].values:\n",
    "            valid_replicates += 1\n",
    "            sample_corrs += df[df['index'] == i][\"corrs\"].values[0]\n",
    "            sample_filtered_ajd += df[df['index'] == i][\"filtered_ajd\"].values[0]\n",
    "            sample_forgetting_rates += df[df['index'] == i][\"forgetting_rates\"].values[0]\n",
    "            sample_average_solution_count += df[df['index'] == i][\"average_solution_count\"].values[0]\n",
    "            sample_success_rates += df[df['index'] == i][\"success_rates\"].values[0]\n",
    "            sample_overthinking_rates += df[df['index'] == i][\"overthinking_rates\"].values[0]\n",
    "            sample_average_verification_rates += df[df['index'] == i][\"average_verification_rates\"].values[0]\n",
    "    \n",
    "    # If there are valid replicates for this sample, compute the average and add to lists\n",
    "    if valid_replicates > 0:\n",
    "        sample_corrs_list.append(sample_corrs / valid_replicates)\n",
    "        sample_filtered_ajd_list.append(sample_filtered_ajd / valid_replicates)\n",
    "        sample_forgetting_rates_list.append(sample_forgetting_rates / valid_replicates)\n",
    "        sample_average_solution_count_list.append(sample_average_solution_count / valid_replicates)\n",
    "        sample_success_rates_list.append(sample_success_rates / valid_replicates)\n",
    "        sample_overthinking_rates_list.append(sample_overthinking_rates / valid_replicates)\n",
    "        sample_average_verification_rates_list.append(sample_average_verification_rates / valid_replicates)\n",
    "\n",
    "print(\"Average with std\")\n",
    "# Compute and print the overall averages and standard deviations across all samples\n",
    "if len(sample_corrs_list) > 0:\n",
    "    print(\"accuracy: \", f\"{np.mean(sample_corrs_list):.3f}\", \"±\", f\"{np.std(sample_corrs_list):.3f}\")\n",
    "    print(\"filtered_ajd: \", f\"{np.mean(sample_filtered_ajd_list):.3f}\", \"±\", f\"{np.std(sample_filtered_ajd_list):.3f}\")\n",
    "    print(\"forgetting_rates: \", f\"{np.mean(sample_forgetting_rates_list):.3f}\", \"±\", f\"{np.std(sample_forgetting_rates_list):.3f}\")\n",
    "    print(\"average_solution_count: \", f\"{np.mean(sample_average_solution_count_list):.3f}\", \"±\", f\"{np.std(sample_average_solution_count_list):.3f}\")\n",
    "    print(\"success_rates: \", f\"{np.mean(sample_success_rates_list):.3f}\", \"±\", f\"{np.std(sample_success_rates_list):.3f}\")\n",
    "    print(\"overthinking_rates: \", f\"{np.mean(sample_overthinking_rates_list):.3f}\", \"±\", f\"{np.std(sample_overthinking_rates_list):.3f}\")\n",
    "    print(\"average_verification_rates: \", f\"{np.mean(sample_average_verification_rates_list):.3f}\", \"±\", f\"{np.std(sample_average_verification_rates_list):.3f}\")\n",
    "else:\n",
    "    print(\"No valid samples found for averaging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afeaee4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average with std\n",
      "accuracy:  0.330 ± 0.318\n",
      "filtered_ajd:  11.679 ± 7.302\n",
      "forgetting_rates:  0.000 ± 0.000\n",
      "average_solution_count:  3.745 ± 2.322\n",
      "success_rates:  0.322 ± 0.271\n",
      "overthinking_rates:  0.003 ± 0.025\n",
      "average_verification_rates:  0.059 ± 0.034\n",
      "\n",
      "Majority Vote Ensemble\n",
      "accuracy:  0.320 ± 0.466\n",
      "filtered_ajd:  12.727 ± 10.949\n",
      "forgetting_rates:  0.000 ± 0.000\n",
      "average_solution_count:  3.510 ± 2.820\n",
      "success_rates:  0.308 ± 0.380\n",
      "overthinking_rates:  0.005 ± 0.050\n",
      "average_verification_rates:  0.056 ± 0.044\n"
     ]
    }
   ],
   "source": [
    "result_dfs = []\n",
    "for result_dir in result_dirs:\n",
    "    result_df = pd.read_csv(os.path.join(result_dir, \"tree_vis_google/gemini-2.5-pro-preview-03-25\", \"metric_df.csv\"))\n",
    "    result_df.rename(columns={result_df.columns[0]: \"index\"}, inplace=True)\n",
    "    result_dfs.append(result_df)\n",
    "\n",
    "# Initialize lists to store metrics for each sample\n",
    "sample_corrs_list = []\n",
    "sample_filtered_ajd_list = []\n",
    "sample_forgetting_rates_list = []\n",
    "sample_average_solution_count_list = []\n",
    "sample_success_rates_list = []\n",
    "sample_overthinking_rates_list = []\n",
    "sample_average_verification_rates_list = []\n",
    "\n",
    "# Initialize lists for majority vote ensemble\n",
    "majority_vote_corrs_list = []\n",
    "majority_vote_filtered_ajd_list = []\n",
    "majority_vote_forgetting_rates_list = []\n",
    "majority_vote_average_solution_count_list = []\n",
    "majority_vote_success_rates_list = []\n",
    "majority_vote_overthinking_rates_list = []\n",
    "majority_vote_average_verification_rates_list = []\n",
    "\n",
    "# Loop through each sample index\n",
    "for i in range(n_samples):\n",
    "    sample_corrs = 0\n",
    "    sample_filtered_ajd = 0\n",
    "    sample_forgetting_rates = 0\n",
    "    sample_average_solution_count = 0\n",
    "    sample_success_rates = 0\n",
    "    sample_overthinking_rates = 0\n",
    "    sample_average_verification_rates = 0\n",
    "    valid_replicates = 0\n",
    "    \n",
    "    # For majority vote ensemble\n",
    "    answers_for_sample = []\n",
    "    corrs_for_sample = []\n",
    "    filtered_ajd_for_sample = []\n",
    "    forgetting_rates_for_sample = []\n",
    "    average_solution_count_for_sample = []\n",
    "    success_rates_for_sample = []\n",
    "    overthinking_rates_for_sample = []\n",
    "    average_verification_rates_for_sample = []\n",
    "    \n",
    "    # Collect data from each replicate (result_df) for the current sample\n",
    "    for df in result_dfs:\n",
    "        if i in df['index'].values:\n",
    "            valid_replicates += 1\n",
    "            sample_corrs += df[df['index'] == i][\"corrs\"].values[0]\n",
    "            sample_filtered_ajd += df[df['index'] == i][\"filtered_ajd\"].values[0]\n",
    "            sample_forgetting_rates += df[df['index'] == i][\"forgetting_rates\"].values[0]\n",
    "            sample_average_solution_count += df[df['index'] == i][\"average_solution_count\"].values[0]\n",
    "            sample_success_rates += df[df['index'] == i][\"success_rates\"].values[0]\n",
    "            sample_overthinking_rates += df[df['index'] == i][\"overthinking_rates\"].values[0]\n",
    "            sample_average_verification_rates += df[df['index'] == i][\"average_verification_rates\"].values[0]\n",
    "            \n",
    "            # Collect answers and all metrics for majority vote\n",
    "            answer = df[df['index'] == i][\"answers\"].values[0]\n",
    "            corr = df[df['index'] == i][\"corrs\"].values[0]\n",
    "            filtered_ajd = df[df['index'] == i][\"filtered_ajd\"].values[0]\n",
    "            forgetting_rates = df[df['index'] == i][\"forgetting_rates\"].values[0]\n",
    "            average_solution_count = df[df['index'] == i][\"average_solution_count\"].values[0]\n",
    "            success_rates = df[df['index'] == i][\"success_rates\"].values[0]\n",
    "            overthinking_rates = df[df['index'] == i][\"overthinking_rates\"].values[0]\n",
    "            average_verification_rates = df[df['index'] == i][\"average_verification_rates\"].values[0]\n",
    "            \n",
    "            answers_for_sample.append(answer)\n",
    "            corrs_for_sample.append(corr)\n",
    "            filtered_ajd_for_sample.append(filtered_ajd)\n",
    "            forgetting_rates_for_sample.append(forgetting_rates)\n",
    "            average_solution_count_for_sample.append(average_solution_count)\n",
    "            success_rates_for_sample.append(success_rates)\n",
    "            overthinking_rates_for_sample.append(overthinking_rates)\n",
    "            average_verification_rates_for_sample.append(average_verification_rates)\n",
    "    \n",
    "    # If there are valid replicates for this sample, compute the average and add to lists\n",
    "    if valid_replicates > 0:\n",
    "        sample_corrs_list.append(sample_corrs / valid_replicates)\n",
    "        sample_filtered_ajd_list.append(sample_filtered_ajd / valid_replicates)\n",
    "        sample_forgetting_rates_list.append(sample_forgetting_rates / valid_replicates)\n",
    "        sample_average_solution_count_list.append(sample_average_solution_count / valid_replicates)\n",
    "        sample_success_rates_list.append(sample_success_rates / valid_replicates)\n",
    "        sample_overthinking_rates_list.append(sample_overthinking_rates / valid_replicates)\n",
    "        sample_average_verification_rates_list.append(sample_average_verification_rates / valid_replicates)\n",
    "        \n",
    "        # Majority vote ensemble\n",
    "        from collections import Counter\n",
    "        answer_counts = Counter(answers_for_sample)\n",
    "        most_common_answer, max_count = answer_counts.most_common(1)[0]\n",
    "        \n",
    "        # If there are at least 2 of the same answer, use that answer's metrics\n",
    "        if max_count >= 2:\n",
    "            # Find the metrics corresponding to the most common answer\n",
    "            for j, answer in enumerate(answers_for_sample):\n",
    "                if answer == most_common_answer:\n",
    "                    majority_vote_corrs_list.append(corrs_for_sample[j])\n",
    "                    majority_vote_filtered_ajd_list.append(filtered_ajd_for_sample[j])\n",
    "                    majority_vote_forgetting_rates_list.append(forgetting_rates_for_sample[j])\n",
    "                    majority_vote_average_solution_count_list.append(average_solution_count_for_sample[j])\n",
    "                    majority_vote_success_rates_list.append(success_rates_for_sample[j])\n",
    "                    majority_vote_overthinking_rates_list.append(overthinking_rates_for_sample[j])\n",
    "                    majority_vote_average_verification_rates_list.append(average_verification_rates_for_sample[j])\n",
    "                    break\n",
    "        else:\n",
    "            # If no majority, use the first answer's metrics\n",
    "            majority_vote_corrs_list.append(corrs_for_sample[0])\n",
    "            majority_vote_filtered_ajd_list.append(filtered_ajd_for_sample[0])\n",
    "            majority_vote_forgetting_rates_list.append(forgetting_rates_for_sample[0])\n",
    "            majority_vote_average_solution_count_list.append(average_solution_count_for_sample[0])\n",
    "            majority_vote_success_rates_list.append(success_rates_for_sample[0])\n",
    "            majority_vote_overthinking_rates_list.append(overthinking_rates_for_sample[0])\n",
    "            majority_vote_average_verification_rates_list.append(average_verification_rates_for_sample[0])\n",
    "\n",
    "print(\"Average with std\")\n",
    "# Compute and print the overall averages and standard deviations across all samples\n",
    "if len(sample_corrs_list) > 0:\n",
    "    print(\"accuracy: \", f\"{np.mean(sample_corrs_list):.3f}\", \"±\", f\"{np.std(sample_corrs_list):.3f}\")\n",
    "    print(\"filtered_ajd: \", f\"{np.mean(sample_filtered_ajd_list):.3f}\", \"±\", f\"{np.std(sample_filtered_ajd_list):.3f}\")\n",
    "    print(\"forgetting_rates: \", f\"{np.mean(sample_forgetting_rates_list):.3f}\", \"±\", f\"{np.std(sample_forgetting_rates_list):.3f}\")\n",
    "    print(\"average_solution_count: \", f\"{np.mean(sample_average_solution_count_list):.3f}\", \"±\", f\"{np.std(sample_average_solution_count_list):.3f}\")\n",
    "    print(\"success_rates: \", f\"{np.mean(sample_success_rates_list):.3f}\", \"±\", f\"{np.std(sample_success_rates_list):.3f}\")\n",
    "    print(\"overthinking_rates: \", f\"{np.mean(sample_overthinking_rates_list):.3f}\", \"±\", f\"{np.std(sample_overthinking_rates_list):.3f}\")\n",
    "    print(\"average_verification_rates: \", f\"{np.mean(sample_average_verification_rates_list):.3f}\", \"±\", f\"{np.std(sample_average_verification_rates_list):.3f}\")\n",
    "else:\n",
    "    print(\"No valid samples found for averaging.\")\n",
    "\n",
    "print(\"\\nMajority Vote Ensemble\")\n",
    "if len(majority_vote_corrs_list) > 0:\n",
    "    print(\"accuracy: \", f\"{np.mean(majority_vote_corrs_list):.3f}\", \"±\", f\"{np.std(majority_vote_corrs_list):.3f}\")\n",
    "    print(\"filtered_ajd: \", f\"{np.mean(majority_vote_filtered_ajd_list):.3f}\", \"±\", f\"{np.std(majority_vote_filtered_ajd_list):.3f}\")\n",
    "    print(\"forgetting_rates: \", f\"{np.mean(majority_vote_forgetting_rates_list):.3f}\", \"±\", f\"{np.std(majority_vote_forgetting_rates_list):.3f}\")\n",
    "    print(\"average_solution_count: \", f\"{np.mean(majority_vote_average_solution_count_list):.3f}\", \"±\", f\"{np.std(majority_vote_average_solution_count_list):.3f}\")\n",
    "    print(\"success_rates: \", f\"{np.mean(majority_vote_success_rates_list):.3f}\", \"±\", f\"{np.std(majority_vote_success_rates_list):.3f}\")\n",
    "    print(\"overthinking_rates: \", f\"{np.mean(majority_vote_overthinking_rates_list):.3f}\", \"±\", f\"{np.std(majority_vote_overthinking_rates_list):.3f}\")\n",
    "    print(\"average_verification_rates: \", f\"{np.mean(majority_vote_average_verification_rates_list):.3f}\", \"±\", f\"{np.std(majority_vote_average_verification_rates_list):.3f}\")\n",
    "else:\n",
    "    print(\"No valid samples found for majority vote ensemble.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea401a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d930ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5ec37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
